{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Through lifting others we rise </p>"},{"location":"#network-automations-fabric","title":"Network Automations Fabric","text":"<p>Hi , thank you for getting here.</p>"},{"location":"#why-the-story","title":"Why - The Story","text":"<p>In a world devoid of network automations, the streets were silent  and grey. Without network automations, network engineers' lives  became a grueling cycle of manual configurations and endless  troubleshooting. They spent hours accessing each and every device,  manually configuring and patching systems. Nights were sleepless,  filled with frantic calls to resolve outages that could no longer  be preemptively detected or resolved. Overwhelmed and exhausted,  their innovative spirit was stifled by the sheer volume of  repetitive tasks...</p> <p>Let us introduce you to the world of Network Automations Fabric.</p>"},{"location":"#what-the-idea","title":"What - The Idea","text":"<p>NorFab is a task execution framework focused on network automations.</p> <p>NorFab purpose is to augment network engineers capabilities with  automation superpowers i.e. Iron Man Suite.</p> <p>Most of the solutions to manage networks falls into one of the two  categories: </p> <ul> <li>heavyweight platforms running on dedicated infrastructure</li> <li>lightweight scripts or tools developed and run locally</li> </ul> <p>NorFab can be both - software you can run equally well from your laptop or on a server, centralized or fully distributed,  lightweight and feature reach. Capable of doing any use cases  without the need to throw unreasonable amounts of dollars and  man hours at it. Always ready to serve the purpose of unlocking  engineers superpowers managing modern networks and making  engineers life better.</p>"},{"location":"#how-the-vision","title":"How - The Vision","text":"<ul> <li>Run Anywhere - locally on Windows, MAC or Linux, in a container, on a VM, in the cloud, centralized or distributed</li> <li>Extend Anything - extendability is in the core of NorFab</li> <li>Integrate with Everything - Python API, REST API, CLI northbound interfaces</li> <li>Manage Anything - develop your own services or use built-in to manage your network infrastructure</li> <li>Model and data driven - Pydantic models for API, validation and documentation</li> <li>Automate Anything - we mean it, sky is the limit on what you can do with NorFab automating your networks</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>Key actors of the system include</p> <ul> <li>CLIENTS - consume services, processes that run on client machine and connect to broker</li> <li>BROKER - provides access to services for clients</li> <li>SERVICES - a collection of workers and resources they manage</li> <li>WORKERS - form services, processes that run anywhere and act as resource proxy agents</li> <li>RESOURCES - entities managed by workers, e.g. network devices, databases, file systems</li> </ul> <p>Clients communicate with broker to submit jobs, broker distributes  jobs across workers comprising the service, workers run jobs producing  results retrieved by clients. In other words, Services  hosted by Workers and expose functionality consumed by Clients  via Broker.</p> <p></p>"},{"location":"api_reference_clients_nfcli_client/","title":"NFCLI Client API","text":"","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client--picle-shell-client","title":"PICLE Shell CLient","text":"<p>Client that implements interactive shell to work with NorFab.</p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands","title":"<code>FileServiceCommands</code>","text":"<p>               Bases: <code>BaseModel</code></p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands--sample-usage","title":"Sample Usage","text":"","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands--copy","title":"copy","text":"<p>Copy to client's fetched files directory:</p> <p><code>file copy_ url nf://cli/commands.txt</code></p> <p>Copy file to destination relative to current directory</p> <p><code>file copy_ url nf://cli/commands.txt destination commands.txt</code></p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands--list","title":"list","text":"<p>List files at broker root directory:</p> <p><code>file list file list url nf://</code></p> <p>List files details:</p> <pre><code>file details\nfile details url nf://\n</code></pre>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.NorFabShell","title":"<code>NorFabShell</code>","text":"<p>               Bases: <code>BaseModel</code></p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.NorFabShell.cmd_preloop_override","title":"<code>cmd_preloop_override()</code>  <code>classmethod</code>","text":"<p>This method called before CMD loop starts</p> Source code in <code>norfab\\clients\\picle_shell_client.py</code> <pre><code>@classmethod\ndef cmd_preloop_override(self):\n    \"\"\"This method called before CMD loop starts\"\"\"\n    pass\n</code></pre>","tags":["nfcli"]},{"location":"api_reference_clients_robot_client/","title":"ROBOT Client API","text":"Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>def __init__(\n    self,\n    inventory=\"./inventory.yaml\",\n    log_level=\"WARNING\",\n):\n    self.ROBOT_LIBRARY_LISTENER = self\n\n    # initiate NorFab\n    self.nf = NorFab(inventory=inventory, log_level=log_level)\n    self.nf.start()\n    self.client = self.nf.make_client()\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.workers","title":"<code>workers(*args, **kwargs)</code>","text":"<p>Collect workers to target</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"Workers\")\ndef workers(self, *args, **kwargs):\n    \"\"\"Collect workers to target\"\"\"\n    if args:\n        DATA[\"workers\"] = args\n    else:\n        DATA[\"workers\"] = kwargs.pop(\"workers\", \"all\")\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.hosts","title":"<code>hosts(*args, **kwargs)</code>","text":"<p>Collect hosts to target</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"Hosts\")\ndef hosts(self, *args, **kwargs):\n    \"\"\"Collect hosts to target\"\"\"\n    if args:\n        DATA[\"hosts\"] = {\"FB\": \", \".join(args), **kwargs}\n    else:\n        DATA[\"hosts\"] = kwargs\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.nr_test","title":"<code>nr_test(*args, **kwargs)</code>","text":"<p>Run nr.test  task</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"nr.test\")\ndef nr_test(self, *args, **kwargs):\n    \"\"\"Run nr.test  task\"\"\"\n    tests_pass = 0\n    tests_fail = 0\n    tests_results = []\n    commands_output = {}\n    if args:\n        kwargs[\"suite\"] = args[0]\n    kwargs = {\n        **DATA.pop(\"hosts\", {\"FB\": \"*\"}),\n        **kwargs,\n        \"remove_tasks\": False,\n        \"add_details\": True,\n        \"return_tests_suite\": True,\n        \"to_dict\": False,\n    }\n    logger.info(f\"Running nr.test with kwargs '{kwargs}', global DATA '{DATA}'\")\n    has_errors = False\n    # run this function\n    ret = self.client.run_job(\n        service=\"nornir\",\n        task=\"test\",\n        workers=DATA.get(\"workers\", \"all\"),\n        kwargs=kwargs,\n    )\n    # iterate over results and log tests and task statuses\n    for worker, worker_results in ret.items():\n        for result in worker_results[\"result\"][\"test_results\"]:\n            host = result[\"host\"]\n            # evaluate and log test result\n            if \"success\" in result:\n                if (\n                    result[\"failed\"]\n                    or result[\"exception\"]\n                    or not result[\"success\"]\n                    or \"traceback\" in str(result[\"result\"]).lower()\n                ):\n                    tests_fail += 1\n                    has_errors = True\n                    logger.error(\n                        (\n                            f'{worker} worker, {host} test \"{result[\"name\"]}\" - '\n                            f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"]}\"&lt;/span&gt;'\n                        ),\n                        html=True,\n                    )\n                else:\n                    tests_pass += 1\n                    logger.info(\n                        (\n                            f'{worker} worker, {host} test \"{result[\"name\"]}\" - '\n                            f'&lt;span style=\"background-color: #97BD61\"&gt;success&lt;/span&gt;'\n                        ),\n                        html=True,\n                    )\n                # save test results to log them later\n                tests_results.append({\"worker\": worker, **result})\n            # evaluate and log task result\n            else:\n                # log exception for task\n                if result[\"failed\"] or result[\"exception\"]:\n                    has_errors = True\n                    logger.error(\n                        (\n                            f'{worker} worker, {host} task \"{result[\"name\"]}\" - '\n                            f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"].strip()}\"&lt;/span&gt;'\n                        ),\n                        html=True,\n                    )\n                # save device commands output to log it later\n                commands_output.setdefault(host, {})\n                commands_output[host][result[\"name\"]] = result[\"result\"]\n    # clear global state to prep for next test\n    clean_global_data()\n\n    tests_results_html_table = TabulateFormatter(\n        tests_results,\n        tabulate={\"tablefmt\": \"html\"},\n        headers=[\n            \"worker\",\n            \"host\",\n            \"name\",\n            \"result\",\n            \"failed\",\n            \"task\",\n            \"test\",\n            \"criteria\",\n            \"exception\",\n        ],\n    )\n\n    tests_results_csv_table = [\n        f'''\"{i['worker']}\",\"{i['host']}\",\"{i['name']}\",\"{i['result']}\",\"{i['failed']}\",\"{i['task']}\",\"{i['test']}\",\"{i['criteria']}\",\"{i['exception']}\"'''\n        for i in tests_results\n    ]\n    tests_results_csv_table.insert(\n        0,\n        '\"worker\",\"host\",\"name\",\"result\",\"failed\",\"task\",\"test\",\"criteria\",\"exception\"',\n    )\n    tests_results_csv_table = \"\\n\".join(tests_results_csv_table)\n\n    # form nested HTML of commands output\n    devices_output_html = []\n    for host in sorted(commands_output.keys()):\n        commands = commands_output[host]\n        commands_output_html = []\n        for command, result in commands.items():\n            commands_output_html.append(\n                f'&lt;p&gt;&lt;details style=\"margin-left:20px;\"&gt;&lt;summary&gt;{command}&lt;/summary&gt;&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result}&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;&lt;/p&gt;'\n            )\n        devices_output_html.append(\n            f'&lt;p&gt;&lt;details&gt;&lt;summary&gt;{host} ({len(commands_output_html)} commands)&lt;/summary&gt;&lt;p&gt;{\"\".join(commands_output_html)}&lt;/p&gt;&lt;/details&gt;&lt;/p&gt;'\n        )\n\n    # form nested HTML for devices tes suite\n    devices_test_suite = []\n    for worker, worker_results in ret.items():\n        for host in sorted(worker_results[\"result\"][\"suite\"].keys()):\n            suite_content = worker_results[\"result\"][\"suite\"][host]\n            devices_test_suite.append(\n                f'&lt;p&gt;&lt;details&gt;&lt;summary&gt;{host} ({len(suite_content)} tests)&lt;/summary&gt;&lt;p style=\"margin-left:20px;\"&gt;{yaml.dump(suite_content, default_flow_style=False)}&lt;/p&gt;&lt;/details&gt;&lt;/p&gt;'\n            )\n\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Workers results&lt;/summary&gt;{pprint.pformat(ret)}&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Test suite results details&lt;/summary&gt;&lt;p&gt;{tests_results_html_table}&lt;/p&gt;&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Test suite results CSV table&lt;/summary&gt;&lt;p&gt;{tests_results_csv_table}&lt;/p&gt;&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Devices tests suites content&lt;/summary&gt;{''.join(devices_test_suite)}&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Collected devices output&lt;/summary&gt;{''.join(devices_output_html)}&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        (\n            f\"Tests completed - {tests_pass + tests_fail}, \"\n            f'&lt;span style=\"background-color: #97BD61\"&gt;success - {tests_pass}&lt;/span&gt;, '\n            f'&lt;span style=\"background-color: #CE3E01\"&gt;failed - {tests_fail}&lt;/span&gt;'\n        ),\n        html=True,\n    )\n\n    # raise if has errors\n    if has_errors:\n        raise ContinuableFailure(\"Tests failed\")\n    # return test results with no errors in structured format\n    return ret\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.nr_cli","title":"<code>nr_cli(*args, **kwargs)</code>","text":"<p>Run Nornir service cli task</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"nr.cli\")\ndef nr_cli(self, *args, **kwargs):\n    \"\"\"Run Nornir service cli task\"\"\"\n    log.info(\n        f\"Running nr.cli with args '{args}', kwargs '{kwargs}', global DATA '{DATA}'\"\n    )\n    has_errors = False\n    if args:\n        kwargs[\"commands\"] = args\n    kwargs = {\n        **DATA.pop(\"hosts\", {\"FB\": \"*\"}),\n        **kwargs,\n        \"add_details\": True,\n        \"to_dict\": False,\n    }\n    # run this function\n    ret = self.client.run_job(\n        service=\"nornir\",\n        task=\"cli\",\n        workers=DATA.get(\"workers\", \"all\"),\n        kwargs=kwargs,\n    )\n    # extract results for the host\n    for worker, worker_results in ret.items():\n        for result in worker_results[\"result\"]:\n            host = result[\"host\"]\n            # evaluate and log results\n            if (\n                result[\"failed\"]\n                or result[\"exception\"]\n                or \"traceback\" in str(result[\"result\"]).lower()\n            ):\n                has_errors = True\n                logger.error(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, comand \"{result[\"name\"]}\" failed - '\n                        f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"]}\"&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n            else:\n                logger.info(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, command \"{result[\"name\"]}\" - '\n                        f'&lt;span style=\"background-color: #97BD61\"&gt;success&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Workers results&lt;/summary&gt;{pprint.pformat(ret)}&lt;/details&gt;\",\n        html=True,\n    )\n    # clean global state to prep for next test\n    clean_global_data()\n    # raise exception if cli command failed\n    if has_errors:\n        raise ContinuableFailure(ret)\n    # return ret with no errors in structured format\n    return ret\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.nr_cfg","title":"<code>nr_cfg(*args, **kwargs)</code>","text":"<p>Run Nornir service cfg task</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"nr.cfg\")\ndef nr_cfg(self, *args, **kwargs):\n    \"\"\"Run Nornir service cfg task\"\"\"\n    log.info(\n        f\"Running nr.cfg with args '{args}', kwargs '{kwargs}', global DATA '{DATA}'\"\n    )\n    if args:\n        kwargs[\"config\"] = args\n    kwargs = {\n        **DATA.pop(\"hosts\", {\"FB\": \"*\"}),\n        **kwargs,\n        \"add_details\": True,\n        \"to_dict\": False,\n    }\n    has_errors = False\n    # run this function\n    ret = self.client.run_job(\n        service=\"nornir\",\n        task=\"cfg\",\n        workers=DATA.get(\"workers\", \"all\"),\n        kwargs=kwargs,\n    )\n    # extract results for the host\n    for worker, worker_results in ret.items():\n        for result in worker_results[\"result\"]:\n            host = result[\"host\"]\n            # evaluate and log results\n            if (\n                result[\"failed\"]\n                or result[\"exception\"]\n                or \"traceback\" in str(result[\"result\"]).lower()\n            ):\n                has_errors = True\n                logger.error(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, \"{result[\"name\"]}\" failed - '\n                        f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"]}\"&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n            else:\n                logger.info(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, \"{result[\"name\"]}\" - '\n                        f'&lt;span style=\"background-color: #97BD61\"&gt;success&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Workers results&lt;/summary&gt;{pprint.pformat(ret)}&lt;/details&gt;\",\n        html=True,\n    )\n    # clean global state to prep for next test\n    clean_global_data()\n    # raise exception if cli command failed\n    if has_errors:\n        raise ContinuableFailure(ret)\n    # return ret with no errors in structured format\n    return ret\n</code></pre>","tags":["robot"]},{"location":"api_reference_core_norfab_broker/","title":"Broker","text":"<p>Majordomo Protocol broker A minimal implementation of http:#rfc.zeromq.org/spec:7 and spec:8</p> <p>Author: Min RK benjaminrk@gmail.com Based on Java example by Arkadiusz Orzechowski</p>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPService","title":"<code>NFPService(name)</code>","text":"<p>               Bases: <code>object</code></p> <p>A single NFP Service</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def __init__(self, name: str):\n    self.name = name  # Service name\n    self.workers = []  # list of known workers\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPWorker","title":"<code>NFPWorker(address, socket, socket_lock, multiplier, keepalive, service=None, log_level='WARNING')</code>","text":"<p>               Bases: <code>object</code></p> <p>An NFP Worker convenience class</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def __init__(\n    self,\n    address: str,\n    socket,\n    socket_lock,\n    multiplier: int,  # e.g. 6 times\n    keepalive: int,  # e.g. 5000 ms\n    service: NFPService = None,\n    log_level: str = \"WARNING\",\n):\n    self.address = address  # Address to route to\n    self.service = service\n    self.ready = False\n    self.socket = socket\n    self.exit_event = threading.Event()\n    self.keepalive = keepalive\n    self.multiplier = multiplier\n    self.socket_lock = socket_lock\n    self.log_level = log_level\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPWorker.is_ready","title":"<code>is_ready()</code>","text":"<p>True if worker signaled W.READY</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def is_ready(self):\n    \"\"\"True if worker signaled W.READY\"\"\"\n    return self.service is not None and self.ready is True\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPWorker.destroy","title":"<code>destroy(disconnect=False)</code>","text":"<p>Clean up routine</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def destroy(self, disconnect=False):\n    \"\"\"Clean up routine\"\"\"\n    self.exit_event.set()\n    self.keepaliver.stop()\n    self.service.workers.remove(self)\n\n    if disconnect is True:\n        msg = [self.address, b\"\", NFP.WORKER, self.service.name, NFP.DISCONNECT]\n        with self.socket_lock:\n            self.socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker","title":"<code>NFPBroker(endpoint, exit_event, inventory, log_level='WARNING', log_queue=None, multiplier=6, keepalive=2500)</code>","text":"<p>NORFAB Protocol broker</p> <p>Initialize broker state.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def __init__(\n    self,\n    endpoint: str,\n    exit_event: Event,\n    inventory: NorFabInventory,\n    log_level: str = \"WARNING\",\n    log_queue: object = None,\n    multiplier: int = 6,\n    keepalive: int = 2500,\n):\n    \"\"\"Initialize broker state.\"\"\"\n    setup_logging(queue=log_queue, log_level=log_level)\n    self.log_level = log_level\n    self.keepalive = keepalive\n    self.multiplier = multiplier\n\n    self.services = {}\n    self.workers = {}\n    self.exit_event = exit_event\n    self.inventory = inventory\n\n    self.base_dir = os.getcwd()\n    self.broker_base_dir = f\"{self.base_dir}/__norfab__/files/broker/\"\n    os.makedirs(self.base_dir, exist_ok=True)\n    os.makedirs(self.broker_base_dir, exist_ok=True)\n\n    # generate certificates, create directories and load certs\n    generate_certificates(self.broker_base_dir, cert_name=\"broker\")\n    secret_keys_dir = os.path.join(self.broker_base_dir, \"private_keys\")\n    server_secret_file = os.path.join(secret_keys_dir, \"broker.key_secret\")\n    server_public, server_secret = zmq.auth.load_certificate(server_secret_file)\n\n    self.ctx = zmq.Context()\n\n    # Start an authenticator for this context.\n    self.auth = ThreadAuthenticator(self.ctx)\n    self.auth.start()\n    self.auth.allow(\"127.0.0.1\")\n    # Tell the authenticator how to handle CURVE requests\n    self.auth.configure_curve(domain=\"*\", location=zmq.auth.CURVE_ALLOW_ANY)\n\n    self.socket = self.ctx.socket(zmq.ROUTER)\n    self.socket.curve_secretkey = server_secret\n    self.socket.curve_publickey = server_public\n    self.socket.curve_server = True  # must come before bind\n    self.socket.linger = 0\n    self.poller = zmq.Poller()\n    self.poller.register(self.socket, zmq.POLLIN)\n    self.socket.bind(endpoint)\n    self.socket_lock = (\n        threading.Lock()\n    )  # used for keepalives to protect socket object\n\n    log.debug(f\"NFPBroker - is read and listening on {endpoint}\")\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.mediate","title":"<code>mediate()</code>","text":"<p>Main broker work happens here</p> <p>Client send messages of this frame format:</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def mediate(self):\n    \"\"\"\n    Main broker work happens here\n\n    Client send messages of this frame format:\n\n\n    \"\"\"\n    while True:\n        try:\n            items = self.poller.poll(self.keepalive)\n        except KeyboardInterrupt:\n            break  # Interrupted\n\n        if items:\n            msg = self.socket.recv_multipart()\n            log.debug(f\"NFPBroker - received '{msg}'\")\n\n            sender = msg.pop(0)\n            empty = msg.pop(0)\n            header = msg.pop(0)\n\n            if header == NFP.CLIENT:\n                self.process_client(sender, msg)\n            elif header == NFP.WORKER:\n                self.process_worker(sender, msg)\n\n        self.purge_workers()\n\n        # check if need to stop\n        if self.exit_event.is_set():\n            self.destroy()\n            break\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.destroy","title":"<code>destroy()</code>","text":"<p>Disconnect all workers, destroy context.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def destroy(self):\n    \"\"\"Disconnect all workers, destroy context.\"\"\"\n    log.info(f\"NFPBroker - interrupt received, killing broker\")\n    for name in list(self.workers.keys()):\n        # in case worker self destroyed while we iterating\n        if self.workers.get(name):\n            self.delete_worker(self.workers[name], True)\n    self.auth.stop()\n    self.ctx.destroy(0)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.delete_worker","title":"<code>delete_worker(worker, disconnect)</code>","text":"<p>Deletes worker from all data structures, and deletes worker.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def delete_worker(self, worker, disconnect):\n    \"\"\"Deletes worker from all data structures, and deletes worker.\"\"\"\n    worker.destroy(disconnect)\n    self.workers.pop(worker.address, None)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.purge_workers","title":"<code>purge_workers()</code>","text":"<p>Look for &amp; delete expired workers.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def purge_workers(self):\n    \"\"\"Look for &amp; delete expired workers.\"\"\"\n    for name in list(self.workers.keys()):\n        # in case worker self destroyed while we iterating\n        if self.workers.get(name):\n            w = self.workers[name]\n        if not w.keepaliver.is_alive():\n            self.delete_worker(w, False)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.send_to_worker","title":"<code>send_to_worker(worker, command, sender, uuid, data)</code>","text":"<p>Send message to worker. If message is provided, sends that message.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def send_to_worker(\n    self, worker: NFPWorker, command: bytes, sender: bytes, uuid: bytes, data: bytes\n):\n    \"\"\"Send message to worker. If message is provided, sends that message.\"\"\"\n    # Stack routing and protocol envelopes to start of message\n    if command == NFP.POST:\n        msg = [worker.address, b\"\", NFP.WORKER, NFP.POST, sender, b\"\", uuid, data]\n    elif command == NFP.GET:\n        msg = [worker.address, b\"\", NFP.WORKER, NFP.GET, sender, b\"\", uuid, data]\n    else:\n        log.error(f\"NFPBroker - invalid worker command: {command}\")\n        return\n    with self.socket_lock:\n        log.debug(f\"NFPBroker - sending to worker '{msg}'\")\n        self.socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.send_to_client","title":"<code>send_to_client(client, command, service, message)</code>","text":"<p>Send message to client.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def send_to_client(self, client: str, command: str, service: str, message: list):\n    \"\"\"Send message to client.\"\"\"\n    # Stack routing and protocol envelopes to start of message\n    if command == NFP.RESPONSE:\n        msg = [client, b\"\", NFP.CLIENT, NFP.RESPONSE, service] + message\n    elif command == NFP.EVENT:\n        msg = [client, b\"\", NFP.CLIENT, NFP.EVENT, service] + message\n    else:\n        log.error(f\"NFPBroker - invalid client command: {command}\")\n        return\n    with self.socket_lock:\n        log.debug(f\"NFPBroker - sending to client '{msg}'\")\n        self.socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.process_worker","title":"<code>process_worker(sender, msg)</code>","text":"<p>Process message received from worker.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def process_worker(self, sender, msg):\n    \"\"\"Process message received from worker.\"\"\"\n    command = msg.pop(0)\n    worker = self.require_worker(sender)\n\n    if NFP.READY == command and not worker.is_ready():\n        service = msg.pop(0)\n        worker.service = self.require_service(service)\n        worker.ready = True\n        worker.start_keepalives()\n        worker.service.workers.append(worker)\n    elif NFP.RESPONSE == command and worker.is_ready():\n        client = msg.pop(0)\n        empty = msg.pop(0)\n        self.send_to_client(client, NFP.RESPONSE, worker.service.name, msg)\n    elif NFP.KEEPALIVE == command:\n        worker.keepaliver.received_heartbeat([worker.address] + msg)\n    elif NFP.DISCONNECT == command and worker.is_ready():\n        self.delete_worker(worker, False)\n    elif NFP.EVENT == command and worker.is_ready():\n        client = msg.pop(0)\n        empty = msg.pop(0)\n        self.send_to_client(client, NFP.EVENT, worker.service.name, msg)\n    elif not worker.is_ready():\n        self.delete_worker(worker, disconnect=True)\n    else:\n        log.error(f\"NFPBroker - invalid message: {msg}\")\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.require_worker","title":"<code>require_worker(address)</code>","text":"<p>Finds the worker, creates if necessary.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def require_worker(self, address):\n    \"\"\"Finds the worker, creates if necessary.\"\"\"\n    if not self.workers.get(address):\n        self.workers[address] = NFPWorker(\n            address=address,\n            socket=self.socket,\n            multiplier=self.multiplier,\n            keepalive=self.keepalive,\n            socket_lock=self.socket_lock,\n            log_level=self.log_level,\n        )\n        log.info(f\"NFPBroker - registered new worker {address}\")\n\n    return self.workers[address]\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.require_service","title":"<code>require_service(name)</code>","text":"<p>Locates the service (creates if necessary).</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def require_service(self, name):\n    \"\"\"Locates the service (creates if necessary).\"\"\"\n    if not self.services.get(name):\n        service = NFPService(name)\n        self.services[name] = service\n        log.debug(f\"NFPBroker - registered new service {name}\")\n\n    return self.services[name]\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.process_client","title":"<code>process_client(sender, msg)</code>","text":"<p>Process a request coming from a client.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def process_client(self, sender, msg):\n    \"\"\"Process a request coming from a client.\"\"\"\n    command = msg.pop(0)\n    service = msg.pop(0)\n    target = msg.pop(0)\n    uuid = msg.pop(0)\n    data = msg.pop(0)\n\n    # check if valid command from client\n    if command not in NFP.client_commands:\n        message = f\"NFPBroker - Unsupported client command '{command}'\"\n        log.error(message)\n        self.send_to_client(\n            sender, NFP.RESPONSE, service, [message.encode(\"utf-8\")]\n        )\n    # Management Interface\n    elif service == b\"mmi.service.broker\":\n        self.mmi_service(sender, command, target, uuid, data)\n    elif service == b\"sid.service.broker\":\n        self.inventory_service(sender, command, target, uuid, data)\n    elif service == b\"fss.service.broker\":\n        self.file_sharing_service(sender, command, target, uuid, data)\n    else:\n        self.dispatch(\n            sender, command, self.require_service(service), target, uuid, data\n        )\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.filter_workers","title":"<code>filter_workers(target, service)</code>","text":"<p>Helper function to filter workers</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>bytes</code> <p>bytest string, workers target</p> required <code>service</code> <code>NFPService</code> <p>NFPService object</p> required Source code in <code>norfab\\core\\broker.py</code> <pre><code>def filter_workers(self, target: bytes, service: NFPService) -&gt; list:\n    \"\"\"\n    Helper function to filter workers\n\n    :param target: bytest string, workers target\n    :param service: NFPService object\n    \"\"\"\n    ret = []\n    if not service.workers:\n        log.warning(\n            f\"NFPBroker - '{service.name}' has no active workers registered, try later\"\n        )\n        ret = []\n    elif target == b\"any\":\n        ret = [service.workers[random.randint(0, len(service.workers) - 1)]]\n    elif target == b\"all\":\n        ret = service.workers\n    elif target in self.workers:  # single worker\n        ret = [self.workers[target]]\n    else:  # target list of workers\n        try:\n            target = json.loads(target)\n            if isinstance(target, list):\n                for w in target:\n                    w = w.encode(\"utf-8\")\n                    if w in self.workers:\n                        ret.append(self.workers[w])\n                ret = list(set(ret))  # dedup workers\n        except Exception as e:\n            log.error(\n                f\"NFPBroker - Failed to load target '{target}' with error '{e}'\"\n            )\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.dispatch","title":"<code>dispatch(sender, command, service, target, uuid, data)</code>","text":"<p>Dispatch requests to waiting workers as possible</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <p>service object</p> required <code>target</code> <p>string indicating workers addresses to dispatch to</p> required <code>msg</code> <p>string with work request content</p> required Source code in <code>norfab\\core\\broker.py</code> <pre><code>def dispatch(self, sender, command, service, target, uuid, data):\n    \"\"\"\n    Dispatch requests to waiting workers as possible\n\n    :param service: service object\n    :param target: string indicating workers addresses to dispatch to\n    :param msg: string with work request content\n    \"\"\"\n    log.debug(\n        f\"NFPBroker - dispatching request to workers: sender '{sender}', \"\n        f\"command '{command}', service '{service.name}', target '{target}'\"\n        f\"data '{data}', uuid '{uuid}'\"\n    )\n    self.purge_workers()\n    workers = self.filter_workers(target, service)\n\n    # handle case when service has no workers registered\n    if not workers:\n        message = f\"NFPBroker - {service.name} service failed to target workers '{target}'\"\n        log.error(message)\n        self.send_to_client(\n            sender,\n            NFP.RESPONSE,\n            service.name,\n            [uuid, b\"400\", message.encode(\"utf-8\")],\n        )\n    else:\n        # inform client that JOB dispatched\n        w_addresses = [w.address.decode(\"utf-8\") for w in workers]\n        self.send_to_client(\n            sender,\n            NFP.RESPONSE,\n            service.name,\n            [\n                uuid,\n                b\"202\",\n                json.dumps(\n                    {\n                        \"workers\": w_addresses,\n                        \"uuid\": uuid.decode(\"utf-8\"),\n                        \"target\": target.decode(\"utf-8\"),\n                        \"status\": \"DISPATCHED\",\n                        \"service\": service.name.decode(\"utf-8\"),\n                    }\n                ).encode(\"utf-8\"),\n            ],\n        )\n        # send job to workers\n        for worker in workers:\n            self.send_to_worker(worker, command, sender, uuid, data)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.mmi_service","title":"<code>mmi_service(sender, command, target, uuid, data)</code>","text":"<p>Handle internal service according to 8/MMI specification</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def mmi_service(self, sender, command, target, uuid, data):\n    \"\"\"Handle internal service according to 8/MMI specification\"\"\"\n    log.debug(\n        f\"mmi.service.broker - processing request: sender '{sender}', \"\n        f\"command '{command}', target '{target}'\"\n        f\"data '{data}', uuid '{uuid}'\"\n    )\n    data = json.loads(data)\n    task = data.get(\"task\")\n    args = data.get(\"args\", [])\n    kwargs = data.get(\"kwargs\", {})\n    ret = f\"Unsupported task '{task}'\"\n    if task == \"show_workers\":\n        if self.workers:\n            ret = [\n                {\n                    \"name\": w.address.decode(\"utf-8\"),\n                    \"service\": w.service.name.decode(\"utf-8\"),\n                    \"status\": \"alive\" if w.keepaliver.is_alive() else \"dead\",\n                    \"holdtime\": str(w.keepaliver.show_holdtime()),\n                    \"keepalives tx/rx\": f\"{w.keepaliver.keepalives_send} / {w.keepaliver.keepalives_received}\",\n                    \"alive (s)\": str(w.keepaliver.show_alive_for()),\n                }\n                for k, w in self.workers.items()\n            ]\n            # filter reply\n            service = kwargs.get(\"service\")\n            status = kwargs.get(\"status\")\n            if service and service != \"all\":\n                ret = [w for w in ret if w[\"service\"] == service]\n            if status in [\"alive\", \"dead\"]:\n                ret = [w for w in ret if w[\"status\"] == status]\n            if not ret:\n                ret = [{\"name\": \"\", \"service\": \"\", \"status\": \"\"}]\n        else:\n            ret = [{\"name\": \"\", \"service\": \"\", \"status\": \"\"}]\n    elif task == \"show_broker\":\n        ret = {\n            \"address\": self.socket.getsockopt_string(zmq.LAST_ENDPOINT),\n            \"status\": \"active\",\n            \"multiplier\": self.multiplier,\n            \"keepalive\": self.keepalive,\n            \"workers count\": len(self.workers),\n            \"services count\": len(self.services),\n            \"base_dir\": self.base_dir,\n        }\n    reply = json.dumps(ret).encode(\"utf-8\")\n    self.send_to_client(\n        sender, NFP.RESPONSE, b\"mmi.service.broker\", [uuid, b\"200\", reply]\n    )\n</code></pre>"},{"location":"api_reference_core_norfab_client/","title":"Client","text":""},{"location":"api_reference_core_norfab_client/#norfab.core.client--cudos","title":"CUDOS","text":"<p>Inspired by Majordomo Protocol Client API, ZeroMQ, Python version.</p> <p>Original MDP/Client spec</p> <p>Location: http://rfc.zeromq.org/spec:7.</p> <p>Author: Min RK benjaminrk@gmail.com</p> <p>Based on Java example by Arkadiusz Orzechowski</p>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient","title":"<code>NFPClient(broker, name, log_level='WARNING', exit_event=None, event_queue=None)</code>","text":"<p>               Bases: <code>object</code></p> <p>NORFAB Protocol Client API.</p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <p>str, broker endpoint e.g. tcp://127.0.0.1:5555</p> required <code>name</code> <p>str, client name, default is <code>NFPClient</code></p> required Source code in <code>norfab\\core\\client.py</code> <pre><code>def __init__(\n    self, broker, name, log_level=\"WARNING\", exit_event=None, event_queue=None\n):\n    log.setLevel(log_level.upper())\n    self.name = name\n    self.zmq_name = f\"{self.name}-{uuid4().hex}\"\n    self.broker = broker\n    self.base_dir = os.path.join(\n        os.getcwd(), \"__norfab__\", \"files\", \"client\", self.name\n    )\n    self.base_dir_jobs = os.path.join(self.base_dir, \"jobs\")\n    self.events_dir = os.path.join(self.base_dir, \"events\")\n\n    # create base directories\n    os.makedirs(self.base_dir, exist_ok=True)\n    os.makedirs(self.base_dir_jobs, exist_ok=True)\n    os.makedirs(self.events_dir, exist_ok=True)\n\n    # generate certificates and create directories\n    generate_certificates(\n        self.base_dir,\n        cert_name=self.name,\n        broker_keys_dir=os.path.join(\n            os.getcwd(), \"__norfab__\", \"files\", \"broker\", \"public_keys\"\n        ),\n    )\n    self.public_keys_dir = os.path.join(self.base_dir, \"public_keys\")\n    self.secret_keys_dir = os.path.join(self.base_dir, \"private_keys\")\n\n    self.ctx = zmq.Context()\n    self.poller = zmq.Poller()\n    self.reconnect_to_broker()\n\n    # create queue file\n    self.queue_filename = os.path.join(\n        self.base_dir_jobs, f\"{self.name}.jobsqueue.txt\"\n    )\n    if not os.path.exists(self.queue_filename):\n        with open(self.queue_filename, \"w\") as f:\n            pass\n\n    self.exit_event = exit_event or threading.Event()\n    self.recv_queue = queue.Queue(maxsize=0)\n    self.event_queue = event_queue or queue.Queue(maxsize=1000)\n\n    # start receive thread\n    self.recv_thread = threading.Thread(\n        target=recv, daemon=True, name=f\"{self.name}_recv_thread\", args=(self,)\n    ).start()\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.reconnect_to_broker","title":"<code>reconnect_to_broker()</code>","text":"<p>Connect or reconnect to broker</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def reconnect_to_broker(self):\n    \"\"\"Connect or reconnect to broker\"\"\"\n    if self.broker_socket:\n        self.poller.unregister(self.broker_socket)\n        self.broker_socket.close()\n\n    self.broker_socket = self.ctx.socket(zmq.DEALER)\n\n    # We need two certificates, one for the client and one for\n    # the server. The client must know the server's public key\n    # to make a CURVE connection.\n    client_secret_file = os.path.join(\n        self.secret_keys_dir, f\"{self.name}.key_secret\"\n    )\n    client_public, client_secret = zmq.auth.load_certificate(client_secret_file)\n    self.broker_socket.curve_secretkey = client_secret\n    self.broker_socket.curve_publickey = client_public\n\n    # The client must know the server's public key to make a CURVE connection.\n    server_public_file = os.path.join(self.public_keys_dir, \"broker.key\")\n    server_public, _ = zmq.auth.load_certificate(server_public_file)\n    self.broker_socket.curve_serverkey = server_public\n\n    self.broker_socket.setsockopt_unicode(zmq.IDENTITY, self.zmq_name, \"utf8\")\n    self.broker_socket.linger = 0\n    self.broker_socket.connect(self.broker)\n    self.poller.register(self.broker_socket, zmq.POLLIN)\n    log.debug(f\"{self.name} - client connected to broker at '{self.broker}'\")\n    self.stats_reconnect_to_broker += 1\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.send_to_broker","title":"<code>send_to_broker(command, service, workers, uuid, request)</code>","text":"<p>Send message to broker.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def send_to_broker(self, command, service, workers, uuid, request):\n    \"\"\"Send message to broker.\"\"\"\n    if command == NFP.POST:\n        msg = [b\"\", NFP.CLIENT, command, service, workers, uuid, request]\n    elif command == NFP.GET:\n        msg = [b\"\", NFP.CLIENT, command, service, workers, uuid, request]\n    else:\n        log.error(\n            f\"{self.name} - cannot send '{command}' to broker, command unsupported\"\n        )\n        return\n\n    log.debug(f\"{self.name} - sending '{msg}'\")\n\n    self.broker_socket.send_multipart(msg)\n    self.stats_send_to_broker += 1\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.rcv_from_broker","title":"<code>rcv_from_broker(command, service, uuid)</code>","text":"<p>Wait for response from broker.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def rcv_from_broker(self, command, service, uuid):\n    \"\"\"Wait for response from broker.\"\"\"\n    retries = 3\n    while retries &gt; 0:\n        # check if need to stop\n        if self.exit_event.is_set():\n            break\n        try:\n            msg = self.recv_queue.get(block=True, timeout=3)\n            self.recv_queue.task_done()\n        except queue.Empty:\n            if retries:\n                log.warning(\n                    f\"{self.name} - '{uuid}:{service}:{command}' job, \"\n                    f\"no reply from broker '{self.broker}', reconnecting\"\n                )\n                self.reconnect_to_broker()\n            retries -= 1\n            continue\n\n        (\n            empty,\n            reply_header,\n            reply_command,\n            reply_service,\n            reply_uuid,\n            reply_status,\n            reply_task_result,\n        ) = msg\n\n        # find message from recv queue for given uuid\n        if reply_uuid == uuid:\n            assert (\n                reply_header == NFP.CLIENT\n            ), f\"Was expecting client header '{NFP.CLIENT}' received '{reply_header}'\"\n            assert (\n                reply_command == command\n            ), f\"Was expecting reply command '{command}' received '{reply_command}'\"\n            assert (\n                reply_service == service\n            ), f\"Was expecting reply from '{service}' but received reply from '{reply_service}' service\"\n\n            return reply_status, reply_task_result\n        else:\n            self.recv_queue.put(msg)\n    else:\n        log.error(\n            f\"{self.name} - '{uuid}:{service}:{command}' job, \"\n            f\"client {retries} retries attempts exceeded\"\n        )\n        return b\"408\", b'{\"status\": \"Request Timeout\"}'\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.post","title":"<code>post(service, task, args=None, kwargs=None, workers='all', uuid=None, timeout=600)</code>","text":"<p>Send job request to broker.</p> <p>Return dictionary with <code>status</code>, <code>workers</code>, <code>errors</code> keys containing list of workers acknowledged POST request.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def post(\n    self,\n    service: str,\n    task: str,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    uuid: hex = None,\n    timeout: int = 600,\n):\n    \"\"\"\n    Send job request to broker.\n\n    Return dictionary with ``status``, ``workers``, ``errors`` keys\n    containing list of workers acknowledged POST request.\n    \"\"\"\n    uuid = uuid or uuid4().hex\n    args = args or []\n    kwargs = kwargs or {}\n    ret = {\"status\": b\"200\", \"workers\": [], \"errors\": []}\n\n    if not isinstance(service, bytes):\n        service = service.encode(\"utf-8\")\n\n    if not isinstance(uuid, bytes):\n        uuid = uuid.encode(\"utf-8\")\n\n    workers = self._make_workers(workers)\n\n    request = json.dumps(\n        {\"task\": task, \"kwargs\": kwargs or {}, \"args\": args or []}\n    ).encode(\"utf-8\")\n\n    # run POST response loop\n    start_time = time.time()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set():\n            return ret\n        self.send_to_broker(\n            NFP.POST, service, workers, uuid, request\n        )  # 1 send POST to broker\n        status, post_response = self.rcv_from_broker(\n            NFP.RESPONSE, service, uuid\n        )  # 2 receive RESPONSE from broker\n        if status == b\"202\":  # 3 go over RESPONSE status and decide what to do\n            break\n        else:\n            msg = f\"{self.name} - '{uuid}' job, POST Request not accepted by broker '{post_response}'\"\n            log.error(msg)\n            ret[\"errors\"].append(msg)\n            ret[\"status\"] = status\n            return ret\n    else:\n        msg = f\"{self.name} - '{uuid}' job, broker POST Request Timeout\"\n        log.error(msg)\n        ret[\"errors\"].append(msg)\n        ret[\"status\"] = b\"408\"\n        return ret\n\n    # get a list of workers where job was dispatched to\n    post_response = json.loads(post_response)\n    workers_dispatched = set(post_response[\"workers\"])\n    log.debug(\n        f\"{self.name} - broker dispatched job '{uuid}' POST request to workers {workers_dispatched}\"\n    )\n\n    # wait workers to ACK POSTed job\n    start_time = time.time()\n    workers_acked = set()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set():\n            return ret\n        status, response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n        response = json.loads(response)\n        if status == b\"202\":  # ACCEPTED\n            log.debug(\n                f\"{self.name} - '{uuid}' job, acknowledged by worker '{response}'\"\n            )\n            workers_acked.add(response[\"worker\"])\n            if workers_acked == workers_dispatched:\n                break\n        else:\n            msg = (\n                f\"{self.name} - '{uuid}:{service}:{task}' job, \"\n                f\"unexpected POST request status '{status}', response '{response}'\"\n            )\n            log.error(msg)\n            ret[\"errors\"].append(msg)\n    else:\n        msg = (\n            f\"{self.name} - '{uuid}' job, POST request timeout exceeded, these workers did not \"\n            f\"acknowledge the job {workers_dispatched - workers_acked}\"\n        )\n        log.error(msg)\n        ret[\"errors\"].append(msg)\n        ret[\"status\"] = b\"408\"\n\n    ret[\"workers\"] = list(workers_acked)\n    ret[\"status\"] = ret[\"status\"].decode(\"utf-8\")\n\n    log.debug(f\"{self.name} - '{uuid}' job POST request completed '{ret}'\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.get","title":"<code>get(service, task, args=None, kwargs=None, workers='all', uuid=None, timeout=600)</code>","text":"<p>S end job reply message to broker requesting job results.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>mandatory, service name to target</p> required <code>task</code> <code>str</code> <p>mandatory, service task name to run</p> required <code>args</code> <code>list</code> <p>optional, list of position argument for the task</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>optional, dictionary of key-word arguments for the task</p> <code>None</code> <code>workers</code> <code>str</code> <p>optional, workers to target - <code>all</code>, <code>any</code>, or list of workers names</p> <code>'all'</code> <code>uuid</code> <code>hex</code> <p>optional, unique job identifier</p> <code>None</code> <code>timeout</code> <code>int</code> <p>optional, job timeout in seconds, for how long client waits for job result before giving up  Returns dictionary of <code>status</code>, <code>results</code> and <code>errors</code> keys, where <code>results</code> key is a dictionary keyed by workers' names, and <code>errors</code> is a list of error strings.</p> <code>600</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def get(\n    self,\n    service: str,\n    task: str,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    uuid: hex = None,\n    timeout: int = 600,\n):\n    \"\"\"S\n    end job reply message to broker requesting job results.\n\n    :param service: mandatory, service name to target\n    :param task: mandatory, service task name to run\n    :param args: optional, list of position argument for the task\n    :param kwargs: optional, dictionary of key-word arguments for the task\n    :param workers: optional, workers to target - ``all``, ``any``, or\n        list of workers names\n    :param uuid: optional, unique job identifier\n    :param timeout: optional, job timeout in seconds, for how long client\n        waits for job result before giving up\n\n    Returns dictionary of ``status``, ``results`` and ``errors`` keys,\n    where ``results`` key is a dictionary keyed by workers' names, and\n    ``errors`` is a list of error strings.\n    \"\"\"\n    uuid = uuid or uuid4().hex\n    args = args or []\n    kwargs = kwargs or {}\n    wkrs = {\n        \"requested\": workers,\n        \"done\": set(),\n        \"dispatched\": set(),\n        \"pending\": set(),\n    }\n    ret = {\"status\": b\"200\", \"results\": {}, \"errors\": [], \"workers\": wkrs}\n\n    if not isinstance(service, bytes):\n        service = service.encode(\"utf-8\")\n\n    if not isinstance(uuid, bytes):\n        uuid = uuid.encode(\"utf-8\")\n\n    workers = self._make_workers(workers)\n\n    request = json.dumps(\n        {\"task\": task, \"kwargs\": kwargs or {}, \"args\": args or []}\n    ).encode(\"utf-8\")\n\n    # run GET response loop\n    start_time = time.time()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set():\n            return None\n        # dispatch GET request to workers\n        self.send_to_broker(NFP.GET, service, workers, uuid, request)\n        status, get_response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n        ret[\"status\"] = status\n        # received actual GET request results from broker e.g. MMI, SID or FSS services\n        if status == b\"200\":\n            ret[\"results\"] = get_response.decode(\"utf-8\")\n            break\n        # received DISPATCH response from broker\n        if status != b\"202\":\n            msg = f\"{status}, {self.name} job '{uuid}' GET Request not accepted by broker '{get_response}'\"\n            log.error(msg)\n            ret[\"errors\"].append(msg)\n            break\n        get_response = json.loads(get_response)\n        wkrs[\"dispatched\"] = set(get_response[\"workers\"])\n        # collect GET responses from individual workers\n        workers_responded = set()\n        while timeout &gt; time.time() - start_time:\n            # check if need to stop\n            if self.exit_event.is_set():\n                return None\n            status, response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n            log.debug(\n                f\"{self.name} - job '{uuid}' response from worker '{response}'\"\n            )\n            response = json.loads(response)\n            if status == b\"200\":  # OK\n                ret[\"results\"].update(response)\n                log.debug(\n                    f\"{self.name} - job '{uuid}' results returned by worker '{response}'\"\n                )\n                for w in response.keys():\n                    wkrs[\"done\"].add(w)\n                    workers_responded.add(w)\n                    if w in wkrs[\"pending\"]:\n                        wkrs[\"pending\"].remove(w)\n                if wkrs[\"done\"] == wkrs[\"dispatched\"]:\n                    break\n            elif status == b\"300\":  # PENDING\n                # set status to pending if at least one worker is pending\n                ret[\"status\"] = b\"300\"\n                wkrs[\"pending\"].add(response[\"worker\"])\n                workers_responded.add(response[\"worker\"])\n            else:\n                if response.get(\"worker\"):\n                    workers_responded.add(response[\"worker\"])\n                msg = (\n                    f\"{self.name} - '{uuid}:{service}:{task}' job, \"\n                    f\"unexpected GET Response status '{status}', response '{response}'\"\n                )\n                log.error(msg)\n                ret[\"errors\"].append(msg)\n            if workers_responded == wkrs[\"dispatched\"]:\n                break\n        if wkrs[\"done\"] == wkrs[\"dispatched\"]:\n            break\n        time.sleep(0.2)\n    else:\n        msg = f\"{self.name} - '{uuid}' job, broker {timeout}s GET request timeout expired\"\n        log.info(msg)\n        ret[\"errors\"].append(msg)\n        ret[\"status\"] = b\"408\"\n\n    ret[\"status\"] = ret[\"status\"].decode(\"utf-8\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.get_iter","title":"<code>get_iter(service, task, args=None, kwargs=None, workers='all', uuid=None, timeout=600)</code>","text":"<p>Send job reply message to broker requesting job results.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def get_iter(\n    self,\n    service: str,\n    task: str,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    uuid: hex = None,\n    timeout: int = 600,\n):\n    \"\"\"Send job reply message to broker requesting job results.\"\"\"\n    uuid = uuid or uuid4().hex\n    args = args or []\n    kwargs = kwargs or {}\n\n    if not isinstance(service, bytes):\n        service = service.encode(\"utf-8\")\n\n    if not isinstance(uuid, bytes):\n        uuid = uuid.encode(\"utf-8\")\n\n    workers = self._make_workers(workers)\n\n    request = json.dumps(\n        {\"task\": task, \"kwargs\": kwargs or {}, \"args\": args or []}\n    ).encode(\"utf-8\")\n\n    # run GET response loop\n    start_time = time.time()\n    workers_done = set()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set():\n            break\n        # dispatch GET request to workers\n        self.send_to_broker(NFP.GET, service, workers, uuid, request)\n        status, get_response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n        # received DISPATCH response from broker\n        if status != b\"202\":\n            msg = f\"{status}, {self.name} job '{uuid}' GET Request not accepted by broker '{get_response}'\"\n            log.error(msg)\n            break\n        get_response = json.loads(get_response)\n        workers_dispatched = set(get_response[\"workers\"])\n        # collect GET responses from workers\n        workers_responded = set()\n        while timeout &gt; time.time() - start_time:\n            # check if need to stop\n            if self.exit_event.is_set():\n                break\n            status, response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n            log.debug(\n                f\"{self.name} - job '{uuid}' response from worker '{response}'\"\n            )\n            response = json.loads(response)\n            if status == b\"200\":  # OK\n                log.debug(\n                    f\"{self.name} - job '{uuid}' results returned by worker '{response}'\"\n                )\n                yield response\n                for w in response.keys():\n                    workers_done.add(w)\n                    workers_responded.add(w)\n                if workers_done == workers_dispatched:\n                    break\n            elif status == b\"300\":  # PENDING\n                workers_responded.add(response[\"worker\"])\n            else:\n                msg = f\"{self.name} - unexpected GET Response status '{status}', response '{response}'\"\n                log.error(msg)\n                ret[\"errors\"].append(msg)\n            if workers_responded == workers_dispatched:\n                break\n        if workers_done == workers_dispatched:\n            break\n        time.sleep(0.2)\n    else:\n        msg = f\"408, {self.name} job '{uuid}' broker GET Request Timeout\"\n        log.error(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.fetch_file","title":"<code>fetch_file(url, destination=None, chunk_size=250000, pipiline=10, timeout=600, read=False)</code>","text":"<p>Function to download file from Broker File Sharing Service.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>(str), path to file relative to <code>base_dir</code></p> required <code>destination</code> <code>str</code> <p>(str), if provided destination to save file, returns file content otherwise</p> <code>None</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def fetch_file(\n    self,\n    url: str,\n    destination: str = None,\n    chunk_size: int = 250000,\n    pipiline: int = 10,\n    timeout: int = 600,\n    read: bool = False,\n):\n    \"\"\"\n    Function to download file from Broker File Sharing Service.\n\n    :param url: (str), path to file relative to ``base_dir``\n    :param destination: (str), if provided destination to save file,\n        returns file content otherwise\n    \"\"\"\n    uuid = str(uuid4().hex).encode(\"utf-8\")\n    total = 0  # Total bytes received\n    chunks = 0  # Total chunks received\n    offset = 0  # Offset of next chunk request\n    credit = pipiline  # Up to PIPELINE chunks in transit\n    service = b\"fss.service.broker\"\n    workers = b\"any\"\n    reply = \"\"\n    status = \"200\"\n    downloaded = False\n    md5hash = None\n\n    # define file destination\n    if destination is None:\n        destination = os.path.join(\n            self.base_dir, \"fetchedfiles\", *os.path.split(url.replace(\"nf://\", \"\"))\n        )\n\n    # make sure all destination directories exist\n    os.makedirs(os.path.split(destination)[0], exist_ok=True)\n\n    # get file details\n    request = json.dumps({\"task\": \"file_details\", \"kwargs\": {\"url\": url}}).encode(\n        \"utf-8\"\n    )\n    self.send_to_broker(NFP.GET, service, workers, uuid, request)\n    rcv_status, file_details = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n    file_details = json.loads(file_details)\n\n    # check if file already downloaded\n    if os.path.isfile(destination):\n        file_hash = hashlib.md5()\n        with open(destination, \"rb\") as f:\n            chunk = f.read(8192)\n            while chunk:\n                file_hash.update(chunk)\n                chunk = f.read(8192)\n        md5hash = file_hash.hexdigest()\n        downloaded = md5hash == file_details[\"md5hash\"]\n        log.debug(f\"{self.name} - file already downloaded, nothing to do\")\n\n    # fetch file content from broker and save to local file\n    if file_details[\"exists\"] is True and downloaded is False:\n        file_hash = hashlib.md5()\n        with open(destination, \"wb\") as dst_file:\n            start_time = time.time()\n            while timeout &gt; time.time() - start_time:\n                # check if need to stop\n                if self.exit_event.is_set():\n                    return \"400\", \"\"\n                # ask for chunks\n                while credit:\n                    request = json.dumps(\n                        {\n                            \"task\": \"fetch_file\",\n                            \"kwargs\": {\n                                \"offset\": offset,\n                                \"chunk_size\": chunk_size,\n                                \"url\": url,\n                            },\n                        }\n                    ).encode(\"utf-8\")\n                    self.send_to_broker(NFP.GET, service, workers, uuid, request)\n                    offset += chunk_size\n                    credit -= 1\n                # receive chunks from broker\n                status, chunk = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n                log.debug(\n                    f\"{self.name} - status '{status}', chunk '{chunks}', downloaded '{total}'\"\n                )\n                dst_file.write(chunk)\n                file_hash.update(chunk)\n                chunks += 1\n                credit += 1\n                size = len(chunk)\n                total += size\n                if size &lt; chunk_size:\n                    break  # Last chunk received; exit\n            else:\n                reply = \"File download failed - timeout\"\n                status = \"408\"\n        # verify md5hash\n        md5hash = file_hash.hexdigest()\n    elif file_details[\"exists\"] is False:\n        reply = \"File download failed - file not found\"\n        status = \"404\"\n\n    # decide on what to reply and status\n    if file_details[\"exists\"] is not True:\n        reply = reply\n    elif md5hash != file_details[\"md5hash\"]:\n        reply = \"File download failed - MD5 hash mismatch\"\n        status = \"417\"\n    elif read:\n        with open(destination, \"r\", encoding=\"utf-8\") as f:\n            reply = f.read()\n    else:\n        reply = destination\n    # decode status\n    if isinstance(status, bytes):\n        status = status.decode(\"utf-8\")\n\n    return status, reply\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.run_job","title":"<code>run_job(service, task, uuid=None, args=None, kwargs=None, workers='all', timeout=600, retry=10)</code>","text":"<p>Run job and return results produced by workers.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>str, service name to send request to</p> required <code>task</code> <code>str</code> <p>str, task name to run for given service</p> required <code>uuid</code> <code>str</code> <p>(str) Job ID to use</p> <code>None</code> <code>args</code> <code>list</code> <p>list, task arguments</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>dict, task key-word arguments</p> <code>None</code> <code>workers</code> <code>str</code> <p>str or list, worker names to target</p> <code>'all'</code> <code>timeout</code> <code>int</code> <p>overall job timeout in seconds</p> <code>600</code> <code>retry</code> <p>number of times to try and GET job results</p> <code>10</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def run_job(\n    self,\n    service: str,\n    task: str,\n    uuid: str = None,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    timeout: int = 600,\n    retry=10,\n):\n    \"\"\"\n    Run job and return results produced by workers.\n\n    :param service: str, service name to send request to\n    :param task: str, task name to run for given service\n    :param uuid: (str) Job ID to use\n    :param args: list, task arguments\n    :param kwargs: dict, task key-word arguments\n    :param workers: str or list, worker names to target\n    :param timeout: overall job timeout in seconds\n    :param retry: number of times to try and GET job results\n    \"\"\"\n    uuid = uuid or uuid4().hex\n    start_time = int(time.time())\n    ret = None\n\n    # POST job to workers\n    post_result = self.post(service, task, args, kwargs, workers, uuid, timeout)\n    if post_result[\"status\"] != \"200\":\n        log.error(\n            f\"{self.name}:run_job - {service}:{task} POST status \"\n            f\"to '{workers}' workers is not 200 - '{post_result}'\"\n        )\n        return ret\n\n    remaining_timeout = timeout - (time.time() - start_time)\n    get_timeout = remaining_timeout / retry\n\n    # GET job results\n    while retry:\n        get = self.get(\n            service, task, [], {}, post_result[\"workers\"], uuid, get_timeout\n        )\n        if self.exit_event.is_set():\n            break\n        elif get[\"status\"] == \"300\":  # PENDING\n            retry -= 1\n            log.debug(\n                f\"{self.name}:run_job - {service}:{task}:{uuid} GET \"\n                f\"results pending, keep waiting\"\n            )\n            continue\n        elif get[\"status\"] == \"408\":  # TIMEOUT\n            retry -= 1\n            log.debug(\n                f\"{self.name}:run_job - {service}:{task}:{uuid} GET \"\n                f\"results {get_timeout}s timeout expired, keep waiting\"\n            )\n            continue\n        elif get[\"status\"] in [\"200\", \"202\"]:  # OK\n            ret = get[\"results\"]\n            break\n        else:\n            log.error(\n                f\"{self.name}:run_job - {service}:{task}:{uuid} \"\n                f\"stopping, GET returned unexpected results - '{get}'\"\n            )\n            break\n    else:\n        log.error(\n            f\"{self.name}:run_job - {service}:{task}:{uuid} \"\n            f\"retry exceeded, GET returned no results, timeout {timeout}s\"\n        )\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.run_job_iter","title":"<code>run_job_iter(service, task, uuid=None, args=None, kwargs=None, workers='all', timeout=600)</code>","text":"<p>Iter run_job allows to return job results from workers progressively as they are responded, rather than waiting for workers to respond first. This should allow to client an interactive experience for the user where job results would be presented as soon as they are available.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>str, service name to send request to</p> required <code>task</code> <code>str</code> <p>str, task name to run for given service</p> required <code>uuid</code> <code>str</code> <p>(str) Job ID to use</p> <code>None</code> <code>args</code> <code>list</code> <p>list, task arguments</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>dict, task key-word arguments</p> <code>None</code> <code>workers</code> <code>str</code> <p>str or list, worker names to target</p> <code>'all'</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def run_job_iter(\n    self,\n    service: str,\n    task: str,\n    uuid: str = None,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    timeout: int = 600,\n):\n    \"\"\"\n    Iter run_job allows to return job results from workers progressively\n    as they are responded, rather than waiting for workers to respond first.\n    This should allow to client an interactive experience for the user where\n    job results would be presented as soon as they are available.\n\n    :param service: str, service name to send request to\n    :param task: str, task name to run for given service\n    :param uuid: (str) Job ID to use\n    :param args: list, task arguments\n    :param kwargs: dict, task key-word arguments\n    :param workers: str or list, worker names to target\n    \"\"\"\n    uuid = uuid or uuid4().hex\n\n    # POST job to workers\n    post_result = self.post(service, task, args, kwargs, workers, uuid, timeout)\n\n    # GET job results\n    for result in self.get_iter(\n        service, task, [], {}, post_result[\"workers\"], uuid, timeout\n    ):\n        yield result\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.event_filename","title":"<code>event_filename(suuid, events_dir)</code>","text":"<p>Returns freshly allocated event filename for given UUID str</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def event_filename(suuid: str, events_dir: str):\n    \"\"\"Returns freshly allocated event filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(events_dir, f\"{suuid}.json\")\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.recv","title":"<code>recv(client)</code>","text":"<p>Thread to process receive messages from broker.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def recv(client):\n    \"\"\"Thread to process receive messages from broker.\"\"\"\n    while not client.exit_event.is_set():\n        # Poll socket for messages every timeout interval\n        try:\n            items = client.poller.poll(1000)\n        except KeyboardInterrupt:\n            break  # Interrupted\n        except:\n            continue\n        if items:\n            msg = client.broker_socket.recv_multipart()\n            log.debug(f\"{client.name} - received '{msg}'\")\n            if msg[2] == NFP.EVENT:\n                client.event_queue.put(msg)\n                client.stats_recv_event_from_broker += 1\n            else:\n                client.recv_queue.put(msg)\n                client.stats_recv_from_broker += 1\n</code></pre>"},{"location":"api_reference_core_norfab_exceptions/","title":"Exceptions","text":""},{"location":"api_reference_core_norfab_exceptions/#norfab.core.exceptions.UnsupportedPluginError","title":"<code>UnsupportedPluginError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when specified plugin not supported</p>"},{"location":"api_reference_core_norfab_exceptions/#norfab.core.exceptions.UnsupportedServiceError","title":"<code>UnsupportedServiceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when specified service not supported</p>"},{"location":"api_reference_core_norfab_nfapi/","title":"NFAPI (Python API)","text":"<p>Utility class to implement Python API for interfacing with NorFab.</p> <p>NorFab Python API Client initialization class</p> <pre><code>from norfab.core.nfapi import NorFab\n\nnf = NorFab(inventory=inventory)\nnf.start(start_broker=True, workers=[\"my-worker-1\"])\nNFCLIENT = nf.client\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>inventory</code> <code>str</code> <p>OS path to NorFab inventory YAML file</p> <code>'./inventory.yaml'</code> <code>log_level</code> <code>str</code> <p>one or supported logging levels - <code>CRITICAL</code>, <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code></p> <code>'WARNING'</code> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def __init__(\n    self, inventory: str = \"./inventory.yaml\", log_level: str = \"WARNING\"\n) -&gt; None:\n    \"\"\"\n    NorFab Python API Client initialization class\n\n    ```\n    from norfab.core.nfapi import NorFab\n\n    nf = NorFab(inventory=inventory)\n    nf.start(start_broker=True, workers=[\"my-worker-1\"])\n    NFCLIENT = nf.client\n    ```\n\n    :param inventory: OS path to NorFab inventory YAML file\n    :param log_level: one or supported logging levels - `CRITICAL`, `ERROR`, `WARNING`, `INFO`, `DEBUG`\n    \"\"\"\n    setup_logging(log_level=log_level, filename=\"norfab.log\")\n    self.inventory = NorFabInventory(inventory)\n    self.log_level = log_level\n    self.broker_endpoint = self.inventory.get(\"broker\", {}).get(\"endpoint\")\n    self.workers_init_timeout = self.inventory.topology.get(\n        \"workers_init_timeout\", 300\n    )\n    self.broker_exit_event = Event()\n    self.workers_exit_event = Event()\n    self.clients_exit_event = Event()\n\n    # start logger thread to log logs to a file\n    self.log_queue = Queue(-1)\n    self.logger_exit_event = Event()\n    self.logger_thread = threading.Thread(\n        target=logger_thread,\n        daemon=True,\n        name=f\"{__name__}_logger_thread\",\n        args=(\n            self.log_queue,\n            self.logger_exit_event,\n        ),\n    )\n    self.logger_thread.start()\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.start","title":"<code>start(start_broker=True, workers=True)</code>","text":"<p>Main entry method to start NorFab components.</p> <p>Parameters:</p> Name Type Description Default <code>start_broker</code> <code>bool</code> <p>if True, starts broker process as defined in inventory <code>topology</code> section</p> <code>True</code> <code>workers</code> <code>list</code> <p>list of worker names to start processes for or boolean, if True starts all workers defined in inventory <code>topology</code> sections</p> <code>True</code> <code>client</code> <p>If true return and instance of NorFab client</p> required Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def start(\n    self,\n    start_broker: bool = True,\n    workers: list = True,\n):\n    \"\"\"\n    Main entry method to start NorFab components.\n\n    :param start_broker: if True, starts broker process as defined in inventory\n        ``topology`` section\n    :param workers: list of worker names to start processes for or boolean, if True\n        starts all workers defined in inventory ``topology`` sections\n    :param client: If true return and instance of NorFab client\n    \"\"\"\n    # start the broker\n    if start_broker is True and self.inventory.topology.get(\"broker\") is True:\n        self.start_broker()\n\n    # decide on a set of workers to start\n    if workers is False or workers is None:\n        workers = []\n    elif isinstance(workers, list) and workers:\n        workers = workers\n    # start workers defined in inventory\n    elif workers is True:\n        workers = self.inventory.topology.get(\"workers\", [])\n\n    # start worker processes\n    if not workers:\n        return\n\n    # form a list of workers to start\n    workers_to_start = set()\n    for worker_name in workers:\n        if isinstance(worker_name, dict):\n            worker_name = tuple(worker_name)[0]\n        workers_to_start.add(worker_name)\n\n    while workers_to_start != set(self.workers_processes.keys()):\n        for worker in workers:\n            # extract worker name and data/params\n            if isinstance(worker, dict):\n                worker_name = tuple(worker)[0]\n                worker_data = worker[worker_name]\n            else:\n                worker_name = worker\n                worker_data = {}\n            # verify if need to start this worker\n            if worker_name not in workers_to_start:\n                continue\n            # start worker\n            try:\n                self.start_worker(worker_name, worker_data)\n            # if failed to start remove from workers to start\n            except KeyError:\n                workers_to_start.discard(worker_name)\n                log.error(\n                    f\"'{worker_name}' - failed to start worker, no inventory data found\"\n                )\n            except FileNotFoundError as e:\n                workers_to_start.discard(worker_name)\n                log.error(\n                    f\"'{worker_name}' - failed to start worker, inventory file not found '{e}'\"\n                )\n            except Exception as e:\n                workers_to_start.discard(worker_name)\n                log.error(f\"'{worker_name}' - failed to start worker, error '{e}'\")\n\n        time.sleep(0.01)\n\n    # wait for workers to initialize\n    start_time = time.time()\n    while self.workers_init_timeout &gt; time.time() - start_time:\n        if all(w[\"init_done\"].is_set() for w in self.workers_processes.values()):\n            break\n    else:\n        log.error(\n            f\"TimeoutError - {self.workers_init_timeout}s workers init timeout expired\"\n        )\n        self.destroy()\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.run","title":"<code>run()</code>","text":"<p>Helper method to run the loop before CTRL+C called</p> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def run(self):\n    \"\"\"\n    Helper method to run the loop before CTRL+C called\n    \"\"\"\n    try:\n        while True:\n            time.sleep(0.5)\n    except KeyboardInterrupt:\n        print(\"\\nInterrupted by user...\")\n        self.destroy()\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.destroy","title":"<code>destroy()</code>","text":"<p>Stop NORFAB processes.</p> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def destroy(self) -&gt; None:\n    \"\"\"\n    Stop NORFAB processes.\n    \"\"\"\n    # stop client\n    self.clients_exit_event.set()\n    if self.client:\n        self.client.destroy()\n    # stop workers\n    self.workers_exit_event.set()\n    while self.workers_processes:\n        _, w = self.workers_processes.popitem()\n        w[\"process\"].join()\n    # stop broker\n    self.broker_exit_event.set()\n    if self.broker:\n        self.broker.join()\n    # stop logger thread\n    self.logger_exit_event.set()\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.make_client","title":"<code>make_client(broker_endpoint=None)</code>","text":"<p>Make an instance of NorFab client</p> <p>Parameters:</p> Name Type Description Default <code>broker_endpoint</code> <code>str</code> <p>(str), Broker URL to connect with</p> <code>None</code> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def make_client(self, broker_endpoint: str = None) -&gt; NFPClient:\n    \"\"\"\n    Make an instance of NorFab client\n\n    :param broker_endpoint: (str), Broker URL to connect with\n    \"\"\"\n\n    if broker_endpoint or self.broker_endpoint:\n        client = NFPClient(\n            broker_endpoint or self.broker_endpoint,\n            \"NFPClient\",\n            self.log_level,\n            self.clients_exit_event,\n        )\n        if self.client is None:  # own the first client\n            self.client = client\n        return client\n    else:\n        log.error(\"Failed to make client, no broker endpoint defined\")\n        return None\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/","title":"Simple Inventory","text":"<p>Simple Local Inventory is an inventory plugin to load  inventory data from locally stored files.</p> <p>Sample inventory file</p> <pre><code>broker:\n  endpoint: \"tcp://127.0.0.1:5555\"\n\nworkers:\n  nornir-*:\n    - nornir/common.yaml  \n  nornir-worker-1:\n    - nornir/nornir-worker-1.yaml\n\ntopology:\n  broker: True\n  workers:\n    - nornir-worker-1\n</code></pre> <p>where <code>nornir/common.yaml</code> contains</p> <pre><code>service: nornir\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\nrunner:\n  plugin: RetryRunner\n  options: \n    num_workers: 100\n    num_connectors: 10\n    connect_retry: 3\n    connect_backoff: 1000\n    connect_splay: 100\n    task_retry: 3\n    task_backoff: 1000\n    task_splay: 100\n    reconnect_on_fail: True\n    task_timeout: 600\n</code></pre> <p>and <code>nornir/nornir-worker-1.yaml</code> contains</p> <pre><code>hosts: \n  csr1000v-1:\n    hostname: sandbox-1.lab.com\n    platform: cisco_ios\n    username: developer\n    password: secretpassword\n  csr1000v-2:\n    hostname: sandbox-2.lab.com\n    platform: cisco_ios\n    username: developer\n    password: secretpassword\ngroups: {}\ndefaults: {}\n</code></pre> <p>Whenever inventory queried to provide data for worker with name <code>nornir-worker-1</code> Simple Inventory iterates over <code>workers</code> dictionary and recursively merges  data for keys (glob patterns) that matched worker name.</p>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.WorkersInventory","title":"<code>WorkersInventory(path, data)</code>","text":"<p>Class to collect and server NorFab workers inventory data, forming it by recursively merging all data files that associated with the name of worker requesting inventory data.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>OS path to top folder with workers inventory data</p> required <code>data</code> <code>dict</code> <p>dictionary keyed by glob patterns matching workers names and values being a list of OS paths to files with workers inventory data</p> required Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def __init__(self, path: str, data: dict) -&gt; None:\n    \"\"\"\n    Class to collect and server NorFab workers inventory data,\n    forming it by recursively merging all data files that associated\n    with the name of worker requesting inventory data.\n\n    :param path: OS path to top folder with workers inventory data\n    :param data: dictionary keyed by glob patterns matching workers names\n        and values being a list of OS paths to files with workers\n        inventory data\n    \"\"\"\n    self.path, _ = os.path.split(path)\n    self.data = data\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.NorFabInventory","title":"<code>NorFabInventory(path)</code>","text":"<p>NorFabInventory class to instantiate simple inventory.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>OS path to YAML file with inventory data</p> required Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def __init__(self, path: str) -&gt; None:\n    \"\"\"\n    NorFabInventory class to instantiate simple inventory.\n\n    :param path: OS path to YAML file with inventory data\n    \"\"\"\n    self.broker = {}\n    self.workers = {}\n    self.topology = {}\n    path = os.path.abspath(path)\n    self.load(path)\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.merge_recursively","title":"<code>merge_recursively(data, merge)</code>","text":"<p>Function to merge two dictionaries data recursively.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>primary dictionary</p> required <code>merge</code> <code>dict</code> <p>dictionary to merge into primary overriding the content</p> required Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def merge_recursively(data: dict, merge: dict) -&gt; None:\n    \"\"\"\n    Function to merge two dictionaries data recursively.\n\n    :param data: primary dictionary\n    :param merge: dictionary to merge into primary overriding the content\n    \"\"\"\n    assert isinstance(data, dict) and isinstance(\n        merge, dict\n    ), f\"Only supports dictionary/dictionary data merges, not {type(data)}/{type(merge)}\"\n    for k, v in merge.items():\n        if k in data:\n            # merge two lists\n            if isinstance(data[k], list) and isinstance(v, list):\n                for i in v:\n                    if i not in data[k]:\n                        data[k].append(i)\n            # recursively merge dictionaries\n            elif isinstance(data[k], dict) and isinstance(v, dict):\n                merge_recursively(data[k], v)\n            # rewrite existing value with new data\n            else:\n                data[k] = v\n        else:\n            data[k] = v\n</code></pre>"},{"location":"api_reference_core_norfab_worker/","title":"Worker","text":""},{"location":"api_reference_core_norfab_worker/#norfab.core.worker--cudos","title":"CUDOS","text":"<p>Inspired by Majordomo Protocol Worker API, ZeroMQ, Python version.</p> <p>Original MDP/Worker spec </p> <p>Location: http://rfc.zeromq.org/spec:7.</p> <p>Author: Min RK benjaminrk@gmail.com</p> <p>Based on Java example by Arkadiusz Orzechowski</p>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.WorkerWatchDog","title":"<code>WorkerWatchDog(worker)</code>","text":"<p>               Bases: <code>Thread</code></p> <p>Class to monitor worker performance</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def __init__(self, worker):\n    super().__init__()\n    self.worker = worker\n    self.worker_process = psutil.Process(os.getpid())\n\n    # extract inventory attributes\n    self.watchdog_interval = worker.inventory.get(\"watchdog_interval\", 30)\n    self.memory_threshold_mbyte = worker.inventory.get(\n        \"memory_threshold_mbyte\", 1000\n    )\n    self.memory_threshold_action = worker.inventory.get(\n        \"memory_threshold_action\", \"log\"\n    )\n\n    # initiate variables\n    self.runs = 0\n    self.watchdog_tasks = []\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.WorkerWatchDog.get_ram_usage","title":"<code>get_ram_usage()</code>","text":"<p>Return RAM usage in Mbyte</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def get_ram_usage(self):\n    \"\"\"Return RAM usage in Mbyte\"\"\"\n    return self.worker_process.memory_info().rss / 1024000\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.Result","title":"<code>Result(result=None, failed=False, errors=None, task=None, messages=None, juuid=None)</code>","text":"<p>Result of running individual tasks.</p> <p>Attributes/Arguments:</p> <p>Parameters:</p> Name Type Description Default <code>changed</code> <p><code>True</code> if the task is changing the system</p> required <code>result</code> <code>Any</code> <p>Result of the task execution, see task's documentation for details</p> <code>None</code> <code>failed</code> <code>bool</code> <p>Whether the execution failed or not</p> <code>False</code> <code>(logging.LEVEL)</code> <code>severity_level</code> <p>Severity level associated to the result of the execution</p> required <code>errors</code> <code>Optional[List[str]]</code> <p>exception thrown during the execution of the task (if any)</p> <code>None</code> <code>task</code> <code>str</code> <p>Task function name that produced the results</p> <code>None</code> <code>messages</code> <code>Optional[List[str]]</code> <p>List of messages produced by the task</p> <code>None</code> <code>juuid</code> <code>Optional[str]</code> <p>Job UUID associated with the task</p> <code>None</code> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def __init__(\n    self,\n    result: Any = None,\n    failed: bool = False,\n    errors: Optional[List[str]] = None,\n    task: str = None,\n    messages: Optional[List[str]] = None,\n    juuid: Optional[str] = None,\n) -&gt; None:\n    self.task = task\n    self.result = result\n    self.failed = failed\n    self.errors = errors or []\n    self.messages = messages or []\n    self.juuid = juuid\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.Result.dictionary","title":"<code>dictionary()</code>","text":"<p>Method to serialize result as a dictionary</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def dictionary(self):\n    \"\"\"Method to serialize result as a dictionary\"\"\"\n    if not isinstance(self.errors, list):\n        self.errors = [self.errors]\n    if not isinstance(self.messages, list):\n        self.messages = [self.messages]\n\n    return {\n        \"task\": self.task,\n        \"failed\": self.failed,\n        \"errors\": self.errors,\n        \"result\": self.result,\n        \"messages\": self.messages,\n        \"juuid\": self.juuid,\n    }\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker","title":"<code>NFPWorker(broker, service, name, exit_event, log_level='WARNING', log_queue=None, multiplier=6, keepalive=2500)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>broker</code> <code>str</code> <p>str, broker endpoint e.g. tcp://127.0.0.1:5555</p> required <code>service</code> <code>str</code> <p>str, service name</p> required <code>name</code> <code>str</code> <p>str, worker name</p> required <code>exist_event</code> <p>obj, threading event, if set signal worker to stop</p> required <code>multiplier</code> <code>int</code> <p>int, number of keepalives lost before consider other party dead</p> <code>6</code> <code>keepalive</code> <code>int</code> <p>int, keepalive interval in milliseconds</p> <code>2500</code> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def __init__(\n    self,\n    broker: str,\n    service: str,\n    name: str,\n    exit_event,\n    log_level: str = \"WARNING\",\n    log_queue: object = None,\n    multiplier: int = 6,\n    keepalive: int = 2500,\n):\n    setup_logging(queue=log_queue, log_level=log_level)\n    self.log_level = log_level\n    self.broker = broker\n    self.service = service\n    self.name = name\n    self.exit_event = exit_event\n    self.broker_socket = None\n    self.socket_lock = (\n        threading.Lock()\n    )  # used for keepalives to protect socket object\n\n    # create base directories\n    self.base_dir = os.path.join(\n        os.getcwd(), \"__norfab__\", \"files\", \"worker\", self.name\n    )\n    self.base_dir_jobs = os.path.join(self.base_dir, \"jobs\")\n    os.makedirs(self.base_dir, exist_ok=True)\n    os.makedirs(self.base_dir_jobs, exist_ok=True)\n\n    # generate certificates and create directories\n    generate_certificates(\n        self.base_dir,\n        cert_name=self.name,\n        broker_keys_dir=os.path.join(\n            os.getcwd(), \"__norfab__\", \"files\", \"broker\", \"public_keys\"\n        ),\n    )\n    self.public_keys_dir = os.path.join(self.base_dir, \"public_keys\")\n    self.secret_keys_dir = os.path.join(self.base_dir, \"private_keys\")\n\n    self.ctx = zmq.Context()\n    self.poller = zmq.Poller()\n    self.reconnect_to_broker()\n\n    self.destroy_event = threading.Event()\n    self.request_thread = None\n    self.reply_thread = None\n    self.close_thread = None\n    self.recv_thread = None\n    self.event_thread = None\n\n    self.post_queue = queue.Queue(maxsize=0)\n    self.get_queue = queue.Queue(maxsize=0)\n    self.delete_queue = queue.Queue(maxsize=0)\n    self.event_queue = queue.Queue(maxsize=0)\n\n    # create queue file\n    self.queue_filename = os.path.join(self.base_dir_jobs, f\"{self.name}.queue.txt\")\n    if not os.path.exists(self.queue_filename):\n        with open(self.queue_filename, \"w\") as f:\n            pass\n    self.queue_done_filename = os.path.join(\n        self.base_dir_jobs, f\"{self.name}.queue.done.txt\"\n    )\n    if not os.path.exists(self.queue_done_filename):\n        with open(self.queue_done_filename, \"w\") as f:\n            pass\n\n    self.keepaliver = KeepAliver(\n        address=None,\n        socket=self.broker_socket,\n        multiplier=multiplier,\n        keepalive=keepalive,\n        exit_event=self.destroy_event,\n        service=self.service,\n        whoami=NFP.WORKER,\n        name=self.name,\n        socket_lock=self.socket_lock,\n        log_level=self.log_level,\n    )\n    self.keepaliver.start()\n    self.client = NFPClient(\n        self.broker, name=f\"{self.name}-NFPClient\", exit_event=self.exit_event\n    )\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.reconnect_to_broker","title":"<code>reconnect_to_broker()</code>","text":"<p>Connect or reconnect to broker</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def reconnect_to_broker(self):\n    \"\"\"Connect or reconnect to broker\"\"\"\n    if self.broker_socket:\n        self.send_to_broker(NFP.DISCONNECT)\n        self.poller.unregister(self.broker_socket)\n        self.broker_socket.close()\n\n    self.broker_socket = self.ctx.socket(zmq.DEALER)\n\n    # We need two certificates, one for the client and one for\n    # the server. The client must know the server's public key\n    # to make a CURVE connection.\n    client_secret_file = os.path.join(\n        self.secret_keys_dir, f\"{self.name}.key_secret\"\n    )\n    client_public, client_secret = zmq.auth.load_certificate(client_secret_file)\n    self.broker_socket.curve_secretkey = client_secret\n    self.broker_socket.curve_publickey = client_public\n\n    # The client must know the server's public key to make a CURVE connection.\n    server_public_file = os.path.join(self.public_keys_dir, \"broker.key\")\n    server_public, _ = zmq.auth.load_certificate(server_public_file)\n    self.broker_socket.curve_serverkey = server_public\n\n    self.broker_socket.setsockopt_unicode(zmq.IDENTITY, self.name, \"utf8\")\n    self.broker_socket.linger = 0\n    self.broker_socket.connect(self.broker)\n    self.poller.register(self.broker_socket, zmq.POLLIN)\n\n    # Register service with broker\n    self.send_to_broker(NFP.READY)\n\n    log.info(\n        f\"{self.name} - registered to broker at '{self.broker}', service '{self.service}'\"\n    )\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.send_to_broker","title":"<code>send_to_broker(command, msg=None)</code>","text":"<p>Send message to broker.</p> <p>If no msg is provided, creates one internally</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def send_to_broker(self, command, msg: list = None):\n    \"\"\"Send message to broker.\n\n    If no msg is provided, creates one internally\n    \"\"\"\n    if command == NFP.READY:\n        msg = [b\"\", NFP.WORKER, NFP.READY, self.service]\n    elif command == NFP.DISCONNECT:\n        msg = [b\"\", NFP.WORKER, NFP.DISCONNECT, self.service]\n    elif command == NFP.RESPONSE:\n        msg = [b\"\", NFP.WORKER, NFP.RESPONSE] + msg\n    elif command == NFP.EVENT:\n        msg = [b\"\", NFP.WORKER, NFP.EVENT] + msg\n    else:\n        log.error(\n            f\"{self.name} - cannot send '{command}' to broker, command unsupported\"\n        )\n        return\n\n    log.debug(f\"{self.name} - sending '{msg}'\")\n\n    with self.socket_lock:\n        self.broker_socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.load_inventory","title":"<code>load_inventory()</code>","text":"<p>Function to load inventory from broker for this worker name.</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def load_inventory(self):\n    \"\"\"\n    Function to load inventory from broker for this worker name.\n    \"\"\"\n    inventory_data = self.client.get(\n        \"sid.service.broker\", \"get_inventory\", kwargs={\"name\": self.name}\n    )\n\n    log.debug(f\"{self.name} - worker received invenotry data {inventory_data}\")\n\n    if inventory_data[\"results\"]:\n        return json.loads(inventory_data[\"results\"])\n    else:\n        return {}\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.fetch_file","title":"<code>fetch_file(url, raise_on_fail=False, read=True)</code>","text":"<p>Function to download file from broker File Sharing Service</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>file location string in <code>nf://&lt;filepath&gt;</code> format</p> required <code>raise_on_fail</code> <code>bool</code> <p>raise FIleNotFoundError if download fails</p> <code>False</code> <code>read</code> <code>bool</code> <p>if True returns file content, return OS path to saved file otherwise</p> <code>True</code> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def fetch_file(\n    self, url: str, raise_on_fail: bool = False, read: bool = True\n) -&gt; str:\n    \"\"\"\n    Function to download file from broker File Sharing Service\n\n    :param url: file location string in ``nf://&lt;filepath&gt;`` format\n    :param raise_on_fail: raise FIleNotFoundError if download fails\n    :param read: if True returns file content, return OS path to saved file otherwise\n    \"\"\"\n    status, file_content = self.client.fetch_file(url=url, read=read)\n    msg = f\"{self.name} - worker '{url}' fetch file failed with status '{status}'\"\n\n    if status == \"200\":\n        return file_content\n    elif raise_on_fail is True:\n        raise FileNotFoundError(msg)\n    else:\n        log.error(msg)\n        return None\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.fetch_jinja2","title":"<code>fetch_jinja2(url)</code>","text":"<p>Helper function to recursively download Jinja2 template together with other templates referenced using \"include\" statements</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p><code>nf://file/path</code> like URL to download file</p> required Source code in <code>norfab\\core\\worker.py</code> <pre><code>def fetch_jinja2(self, url: str) -&gt; str:\n    \"\"\"\n    Helper function to recursively download Jinja2 template together with\n    other templates referenced using \"include\" statements\n\n    :param url: ``nf://file/path`` like URL to download file\n    \"\"\"\n    filepath = self.fetch_file(url, read=False)\n    if filepath is None:\n        msg = f\"{self.name} - file download failed '{url}'\"\n        raise FileNotFoundError(msg)\n\n    # download Jinja2 template \"include\"-ed files\n    content = self.fetch_file(url, read=True)\n    j2env = Environment(loader=\"BaseLoader\")\n    try:\n        parsed_content = j2env.parse(content)\n    except Exception as e:\n        msg = f\"{self.name} - Jinja2 template parsing failed '{url}', error: '{e}'\"\n        raise Exception(msg)\n\n    # run recursion on include statements\n    for node in parsed_content.find_all(Include):\n        include_file = node.template.value\n        base_path = os.path.split(url)[0]\n        self.fetch_jinja2(os.path.join(base_path, include_file))\n\n    return filepath\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.job_details","title":"<code>job_details(uuid, data=True, result=True, events=True)</code>","text":"<p>Method to get job details by UUID for completed jobs.</p> <p>Parameters:</p> Name Type Description Default <code>uuid</code> <code>str</code> <p>str, job UUID to return details for</p> required <code>data</code> <code>bool</code> <p>bool, if True return job data</p> <code>True</code> <code>result</code> <code>bool</code> <p>bool, if True return job result</p> <code>True</code> <code>events</code> <code>bool</code> <p>bool, if True return job events</p> <code>True</code> <p>Returns:</p> Type Description <code>Result</code> <p>Result object with job details</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def job_details(\n    self, uuid: str, data: bool = True, result: bool = True, events: bool = True\n) -&gt; Result:\n    \"\"\"\n    Method to get job details by UUID for completed jobs.\n\n    :param uuid: str, job UUID to return details for\n    :param data: bool, if True return job data\n    :param result: bool, if True return job result\n    :param events: bool, if True return job events\n    :return: Result object with job details\n    \"\"\"\n    job = None\n    with queue_file_lock:\n        with open(self.queue_done_filename, \"rb+\") as f:\n            for entry in f.readlines():\n                job_data, job_result, job_events = None, None, []\n                job_entry = entry.decode(\"utf-8\").strip()\n                suuid, start, end = job_entry.split(\"--\")  # {suuid}--start--end\n                if suuid != uuid:\n                    continue\n                # load job request details\n                client_address, empty, juuid, job_data_bytes = loader(\n                    request_filename(suuid, self.base_dir_jobs)\n                )\n                if data:\n                    job_data = json.loads(job_data_bytes.decode(\"utf-8\"))\n                # load job result details\n                if result:\n                    rep_filename = reply_filename(suuid, self.base_dir_jobs)\n                    if os.path.exists(rep_filename):\n                        job_result = loader(rep_filename)\n                        job_result = json.loads(job_result[-1].decode(\"utf-8\"))\n                        job_result = job_result[self.name]\n                # load event details\n                if events:\n                    events_filename = event_filename(suuid, self.base_dir_jobs)\n                    if os.path.exists(events_filename):\n                        job_events = loader(events_filename)\n                        job_events = [e[-1] for e in job_events]\n\n                job = {\n                    \"uuid\": suuid,\n                    \"client\": client_address.decode(\"utf-8\"),\n                    \"received_timestamp\": start,\n                    \"done_timestamp\": end,\n                    \"status\": \"COMPLETED\",\n                    \"job_data\": job_data,\n                    \"job_result\": job_result,\n                    \"job_events\": job_events,\n                }\n\n    if job:\n        return Result(\n            task=f\"{self.name}:job_details\",\n            result=job,\n        )\n    else:\n        raise FileNotFoundError(f\"{self.name} - job with UUID '{uuid}' not found\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.job_list","title":"<code>job_list(pending=True, completed=True, task=None, last=None, client=None, uuid=None)</code>","text":"<p>Method to list worker jobs completed and pending.</p> <p>Parameters:</p> Name Type Description Default <code>pending</code> <code>bool</code> <p>bool, if True or None return pending jobs, if False skip pending jobs</p> <code>True</code> <code>completed</code> <code>bool</code> <p>bool, if True or None return completed jobs, if False skip completed jobs</p> <code>True</code> <code>task</code> <code>str</code> <p>str, if provided return only jobs with this task name</p> <code>None</code> <code>last</code> <code>int</code> <p>int, if provided return only last N completed and last N pending jobs</p> <code>None</code> <code>client</code> <code>str</code> <p>str, if provided return only jobs submitted by this client</p> <code>None</code> <code>uuid</code> <code>str</code> <p>str, if provided return only job with this UUID</p> <code>None</code> <p>Returns:</p> Type Description <code>Result</code> <p>Result object with list of jobs</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def job_list(\n    self,\n    pending: bool = True,\n    completed: bool = True,\n    task: str = None,\n    last: int = None,\n    client: str = None,\n    uuid: str = None,\n) -&gt; Result:\n    \"\"\"\n    Method to list worker jobs completed and pending.\n\n    :param pending: bool, if True or None return pending jobs, if\n        False skip pending jobs\n    :param completed: bool, if True or None return completed jobs,\n        if False skip completed jobs\n    :param task: str, if provided return only jobs with this task name\n    :param last: int, if provided return only last N completed and\n        last N pending jobs\n    :param client: str, if provided return only jobs submitted by this client\n    :param uuid: str, if provided return only job with this UUID\n    :return: Result object with list of jobs\n    \"\"\"\n    job_pending = []\n    # load pending jobs\n    if pending is True:\n        with queue_file_lock:\n            with open(self.queue_filename, \"rb+\") as f:\n                for entry in f.readlines():\n                    job_entry = entry.decode(\"utf-8\").strip()\n                    suuid, start = job_entry.split(\"--\")  # {suuid}--start\n                    if uuid and suuid != uuid:\n                        continue\n                    client_address, empty, juuid, data = loader(\n                        request_filename(suuid, self.base_dir_jobs)\n                    )\n                    if client and client_address.decode(\"utf-8\") != client:\n                        continue\n                    job_task = json.loads(data.decode(\"utf-8\"))[\"task\"]\n                    # check if need to skip this job\n                    if task and job_task != task:\n                        continue\n                    job_pending.append(\n                        {\n                            \"uuid\": suuid,\n                            \"client\": client_address.decode(\"utf-8\"),\n                            \"received_timestamp\": start,\n                            \"done_timestamp\": None,\n                            \"task\": job_task,\n                            \"status\": \"PENDING\",\n                            \"worker\": self.name,\n                            \"service\": self.service.decode(\"utf-8\"),\n                        }\n                    )\n    job_completed = []\n    # load done jobs\n    if completed is True:\n        with queue_file_lock:\n            with open(self.queue_done_filename, \"rb+\") as f:\n                for entry in f.readlines():\n                    job_entry = entry.decode(\"utf-8\").strip()\n                    suuid, start, end = job_entry.split(\"--\")  # {suuid}--start--end\n                    if uuid and suuid != uuid:\n                        continue\n                    client_address, empty, juuid, data = loader(\n                        request_filename(suuid, self.base_dir_jobs)\n                    )\n                    if client and client_address.decode(\"utf-8\") != client:\n                        continue\n                    job_task = json.loads(data.decode(\"utf-8\"))[\"task\"]\n                    # check if need to skip this job\n                    if task and job_task != task:\n                        continue\n                    job_completed.append(\n                        {\n                            \"uuid\": suuid,\n                            \"client\": client_address.decode(\"utf-8\"),\n                            \"received_timestamp\": start,\n                            \"done_timestamp\": end,\n                            \"task\": job_task,\n                            \"status\": \"COMPLETED\",\n                            \"worker\": self.name,\n                            \"service\": self.service.decode(\"utf-8\"),\n                        }\n                    )\n    if last:\n        return Result(\n            task=f\"{self.name}:job_list\",\n            result=job_completed[len(job_completed) - last :]\n            + job_pending[len(job_pending) - last :],\n        )\n    else:\n        return Result(\n            task=f\"{self.name}:job_list\",\n            result=job_completed + job_pending,\n        )\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.request_filename","title":"<code>request_filename(suuid, base_dir_jobs)</code>","text":"<p>Returns freshly allocated request filename for given UUID str</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def request_filename(suuid: Union[str, bytes], base_dir_jobs: str):\n    \"\"\"Returns freshly allocated request filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(base_dir_jobs, f\"{suuid}.req\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.reply_filename","title":"<code>reply_filename(suuid, base_dir_jobs)</code>","text":"<p>Returns freshly allocated reply filename for given UUID str</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def reply_filename(suuid: Union[str, bytes], base_dir_jobs: str):\n    \"\"\"Returns freshly allocated reply filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(base_dir_jobs, f\"{suuid}.rep\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.event_filename","title":"<code>event_filename(suuid, base_dir_jobs)</code>","text":"<p>Returns freshly allocated event filename for given UUID str</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def event_filename(suuid: Union[str, bytes], base_dir_jobs: str):\n    \"\"\"Returns freshly allocated event filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(base_dir_jobs, f\"{suuid}.event\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.recv","title":"<code>recv(worker, destroy_event)</code>","text":"<p>Thread to process receive messages from broker.</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def recv(worker, destroy_event):\n    \"\"\"Thread to process receive messages from broker.\"\"\"\n    while not destroy_event.is_set():\n        # Poll socket for messages every second\n        try:\n            items = worker.poller.poll(1000)\n        except KeyboardInterrupt:\n            break  # Interrupted\n        if items:\n            msg = worker.broker_socket.recv_multipart()\n            log.debug(f\"{worker.name} - received '{msg}'\")\n            empty = msg.pop(0)\n            header = msg.pop(0)\n            command = msg.pop(0)\n\n            if command == NFP.POST:\n                worker.post_queue.put(msg)\n            elif command == NFP.DELETE:\n                worker.delete_queue.put(msg)\n            elif command == NFP.GET:\n                worker.get_queue.put(msg)\n            elif command == NFP.KEEPALIVE:\n                worker.keepaliver.received_heartbeat([header] + msg)\n            elif command == NFP.DISCONNECT:\n                worker.reconnect_to_broker()\n            else:\n                log.debug(\n                    f\"{worker.name} - invalid input, header '{header}', command '{command}', message '{msg}'\"\n                )\n\n        if not worker.keepaliver.is_alive():\n            log.warning(f\"{worker.name} - '{worker.broker}' broker keepalive expired\")\n            worker.reconnect_to_broker()\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/","title":"Netbox Worker","text":""},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker--netbox-worker-inventory-reference","title":"Netbox Worker Inventory Reference","text":""},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker--sample-netbox-worker-inventory","title":"Sample Netbox Worker Inventory","text":"<pre><code>service: netbox\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\ninstances:\n  prod:\n    default: True\n    url: \"http://192.168.4.130:8000/\"\n    token: \"0123456789abcdef0123456789abcdef01234567\"\n    ssl_verify: False\n  dev:\n    url: \"http://192.168.4.131:8000/\"\n    token: \"0123456789abcdef0123456789abcdef01234567\"\n    ssl_verify: False\n  preprod:\n    url: \"http://192.168.4.132:8000/\"\n    token: \"0123456789abcdef0123456789abcdef01234567\"\n    ssl_verify: False\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker--sample-nornir-worker-netbox-inventory","title":"Sample Nornir Worker Netbox Inventory","text":"<pre><code>netbox:\n  retry: 3\n  retry_interval: 1\n  instance: prod\n  interfaces:\n    ip_addresses: True\n    inventory_items: True\n  connections:\n    cables: True\n    circuits: True\n  nbdata: True\n  primary_ip: \"ipv4\"\n  devices:\n    - fceos4\n    - fceos5\n    - fceos8\n    - ceos1\n  filters: \n    - q: fceos3\n    - manufacturer: cisco\n      platform: cisco_xr\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker","title":"<code>NetboxWorker(broker, service, worker_name, exit_event=None, init_done_event=None, log_level='WARNING', log_queue=None)</code>","text":"<p>               Bases: <code>NFPWorker</code></p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <p>broker URL to connect to</p> required <code>service</code> <p>name of the service with worker belongs to</p> required <code>worker_name</code> <p>name of this worker</p> required <code>exit_event</code> <p>if set, worker need to stop/exit</p> <code>None</code> <code>init_done_event</code> <p>event to set when worker done initializing</p> <code>None</code> <code>log_keve</code> <p>logging level of this worker</p> required Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def __init__(\n    self,\n    broker,\n    service,\n    worker_name,\n    exit_event=None,\n    init_done_event=None,\n    log_level=\"WARNING\",\n    log_queue: object = None,\n):\n    super().__init__(broker, service, worker_name, exit_event, log_level, log_queue)\n    self.init_done_event = init_done_event\n\n    # get inventory from broker\n    self.inventory = self.load_inventory()\n    if not self.inventory:\n        log.critical(\n            f\"{self.name} - Broker {self.broker} returned no inventory for {self.name}, killing myself...\"\n        )\n        self.destroy()\n\n    assert self.inventory.get(\n        \"instances\"\n    ), f\"{self.name} - inventory has no Netbox instances\"\n\n    # extract parameters\n    self.netbox_connect_timeout = self.inventory.get(\"netbox_connect_timeout\", 10)\n    self.netbox_read_timeout = self.inventory.get(\"netbox_read_timeout\", 300)\n\n    # find default instance\n    for name, params in self.inventory[\"instances\"].items():\n        if params.get(\"default\") is True:\n            self.default_instance = name\n            break\n    else:\n        self.default_instance = name\n\n    # check Netbox compatibility\n    self._verify_compatibility()\n\n    self.init_done_event.set()\n    log.info(f\"{self.name} - Started\")\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.graphql","title":"<code>graphql(instance=None, dry_run=False, obj=None, filters=None, fields=None, queries=None, query_string=None)</code>","text":"<p>Function to query Netbox v4 GraphQL API</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def graphql(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    obj: dict = None,\n    filters: dict = None,\n    fields: list = None,\n    queries: dict = None,\n    query_string: str = None,\n) -&gt; Result:\n    \"\"\"\n    Function to query Netbox v4 GraphQL API\n\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    \"\"\"\n    nb_params = self._get_instance_params(instance)\n    ret = Result(task=f\"{self.name}:graphql\")\n\n    # form graphql query(ies) payload\n    if queries:\n        queries_list = []\n        for alias, query_data in queries.items():\n            query_data[\"alias\"] = alias\n            if self.nb_version[0] == 4:\n                queries_list.append(_form_query_v4(**query_data))\n            elif self.nb_version[0] == 3:\n                queries_list.append(_form_query_v3(**query_data))\n        queries_strings = \"    \".join(queries_list)\n        query = f\"query {{{queries_strings}}}\"\n    elif obj and filters and fields:\n        if self.nb_version[0] == 4:\n            query = _form_query_v4(obj, filters, fields)\n        elif self.nb_version[0] == 3:\n            query = _form_query_v3(obj, filters, fields)\n        query = f\"query {{{query}}}\"\n    elif query_string:\n        query = query_string\n    else:\n        raise RuntimeError(\n            f\"{self.name} - graphql method expects quieries argument or obj, filters, \"\n            f\"fields arguments or query_string argument provided\"\n        )\n    payload = json.dumps({\"query\": query})\n\n    # form and return dry run response\n    if dry_run:\n        ret.result = {\n            \"url\": f\"{nb_params['url']}/graphql/\",\n            \"data\": payload,\n            \"verify\": nb_params.get(\"ssl_verify\", True),\n            \"headers\": {\n                \"Content-Type\": \"application/json\",\n                \"Accept\": \"application/json\",\n                \"Authorization\": f\"Token ...{nb_params['token'][-6:]}\",\n            },\n        }\n        return ret\n\n    # send request to Netbox GraphQL API\n    log.debug(\n        f\"{self.name} - sending GraphQL query '{payload}' to URL '{nb_params['url']}/graphql/'\"\n    )\n    req = requests.post(\n        url=f\"{nb_params['url']}/graphql/\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Token {nb_params['token']}\",\n        },\n        data=payload,\n        verify=nb_params.get(\"ssl_verify\", True),\n        timeout=(self.netbox_connect_timeout, self.netbox_read_timeout),\n    )\n    try:\n        req.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"{self.name} -  Netbox GraphQL query failed, query '{query}', \"\n            f\"URL '{req.url}', status-code '{req.status_code}', reason '{req.reason}', \"\n            f\"response content '{req.text}'\"\n        )\n\n    # return results\n    reply = req.json()\n    if reply.get(\"errors\"):\n        msg = f\"{self.name} - GrapQL query error '{reply['errors']}', query '{payload}'\"\n        log.error(msg)\n        ret.errors.append(msg)\n        if reply.get(\"data\"):\n            ret.result = reply[\"data\"]  # at least return some data\n    elif queries or query_string:\n        ret.result = reply[\"data\"]\n    else:\n        ret.result = reply[\"data\"][obj]\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.rest","title":"<code>rest(instance=None, method='get', api='', **kwargs)</code>","text":"<p>Method to query Netbox REST API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>method</code> <code>str</code> <p>requests method name e.g. get, post, put etc.</p> <code>'get'</code> <code>api</code> <code>str</code> <p>api url to query e.g. \"extras\" or \"dcim/interfaces\" etc.</p> <code>''</code> <code>kwargs</code> <p>any additional requests method's arguments</p> <code>{}</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def rest(\n    self, instance: str = None, method: str = \"get\", api: str = \"\", **kwargs\n) -&gt; dict:\n    \"\"\"\n    Method to query Netbox REST API.\n\n    :param instance: Netbox instance name\n    :param method: requests method name e.g. get, post, put etc.\n    :param api: api url to query e.g. \"extras\" or \"dcim/interfaces\" etc.\n    :param kwargs: any additional requests method's arguments\n    \"\"\"\n    params = self._get_instance_params(instance)\n\n    # send request to Netbox REST API\n    response = getattr(requests, method)(\n        url=f\"{params['url']}/api/{api}/\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Token {params['token']}\",\n        },\n        verify=params.get(\"ssl_verify\", True),\n        **kwargs,\n    )\n\n    response.raise_for_status()\n\n    return response.json()\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_devices","title":"<code>get_devices(filters=None, instance=None, dry_run=False, devices=None)</code>","text":"<p>Function to retrieve devices data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list</code> <p>list of filters dictionaries to filter devices</p> <code>None</code> <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>devices</code> <code>list</code> <p>list of device names to query data for</p> <code>None</code> <p>Returns:</p> Type Description <code>Result</code> <p>dictionary keyed by device name with device data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_devices(\n    self,\n    filters: list = None,\n    instance: str = None,\n    dry_run: bool = False,\n    devices: list = None,\n) -&gt; Result:\n    \"\"\"\n    Function to retrieve devices data from Netbox using GraphQL API.\n\n    :param filters: list of filters dictionaries to filter devices\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param devices: list of device names to query data for\n    :return: dictionary keyed by device name with device data\n    \"\"\"\n    ret = Result(task=f\"{self.name}:get_devices\", result={})\n    instance = instance or self.default_instance\n    filters = filters or []\n\n    device_fields = [\n        \"name\",\n        \"last_updated\",\n        \"custom_field_data\",\n        \"tags {name}\",\n        \"device_type {model}\",\n        \"role {name}\",\n        \"config_context\",\n        \"tenant {name}\",\n        \"platform {name}\",\n        \"serial\",\n        \"asset_tag\",\n        \"site {name tags{name}}\",\n        \"location {name}\",\n        \"rack {name}\",\n        \"status\",\n        \"primary_ip4 {address}\",\n        \"primary_ip6 {address}\",\n        \"airflow\",\n        \"position\",\n    ]\n\n    # form queries dictionary out of filters\n    queries = {\n        f\"devices_by_filter_{index}\": {\n            \"obj\": \"device_list\",\n            \"filters\": filter_item,\n            \"fields\": device_fields,\n        }\n        for index, filter_item in enumerate(filters)\n    }\n\n    # add devices list query\n    if devices:\n        if self.nb_version[0] == 4:\n            dlist = '[\"{dl}\"]'.format(dl='\", \"'.join(devices))\n            filters_dict = {\"name\": f\"{{in_list: {dlist}}}\"}\n        elif self.nb_version[0] == 3:\n            filters_dict = {\"name\": devices}\n        queries[\"devices_by_devices_list\"] = {\n            \"obj\": \"device_list\",\n            \"filters\": filters_dict,\n            \"fields\": device_fields,\n        }\n\n    # send queries\n    query_result = self.graphql(queries=queries, instance=instance, dry_run=dry_run)\n    devices_data = query_result.result\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    # check for errors\n    if query_result.errors:\n        msg = f\"{self.name} - get devices query failed with errors:\\n{query_result.errors}\"\n        raise Exception(msg)\n\n    # process devices\n    for devices_list in devices_data.values():\n        for device in devices_list:\n            if device[\"name\"] not in ret.result:\n                ret.result[device.pop(\"name\")] = device\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_interfaces","title":"<code>get_interfaces(instance=None, devices=None, ip_addresses=False, inventory_items=False, dry_run=False)</code>","text":"<p>Function to retrieve device interfaces from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>devices</code> <code>list</code> <p>list of devices to retrieve interfaces for</p> <code>None</code> <code>ip_addresses</code> <code>bool</code> <p>if True, retrieves interface IPs</p> <code>False</code> <code>inventory_items</code> <code>bool</code> <p>if True, retrieves interface inventory items</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <p>Returns:</p> Type Description <code>Result</code> <p>dictionary keyed by device name with interface details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_interfaces(\n    self,\n    instance: str = None,\n    devices: list = None,\n    ip_addresses: bool = False,\n    inventory_items: bool = False,\n    dry_run: bool = False,\n) -&gt; Result:\n    \"\"\"\n    Function to retrieve device interfaces from Netbox using GraphQL API.\n\n    :param instance: Netbox instance name\n    :param devices: list of devices to retrieve interfaces for\n    :param ip_addresses: if True, retrieves interface IPs\n    :param inventory_items: if True, retrieves interface inventory items\n    :param dry_run: only return query content, do not run it\n    :return: dictionary keyed by device name with interface details\n    \"\"\"\n    # form final result object\n    ret = Result(\n        task=f\"{self.name}:get_interfaces\", result={d: {} for d in devices}\n    )\n    intf_fields = [\n        \"name\",\n        \"enabled\",\n        \"description\",\n        \"mtu\",\n        \"parent {name}\",\n        \"mac_address\",\n        \"mode\",\n        \"untagged_vlan {vid name}\",\n        \"vrf {name}\",\n        \"tagged_vlans {vid name}\",\n        \"tags {name}\",\n        \"custom_fields\",\n        \"last_updated\",\n        \"bridge {name}\",\n        \"child_interfaces {name}\",\n        \"bridge_interfaces {name}\",\n        \"member_interfaces {name}\",\n        \"wwn\",\n        \"duplex\",\n        \"speed\",\n        \"id\",\n        \"device {name}\",\n    ]\n\n    # add IP addresses to interfaces fields\n    if ip_addresses:\n        intf_fields.append(\n            \"ip_addresses {address status role dns_name description custom_fields last_updated tenant {name} tags {name}}\"\n        )\n\n    # form interfaces query dictionary\n    queries = {\n        \"interfaces\": {\n            \"obj\": \"interface_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": intf_fields,\n        }\n    }\n\n    # add query to retrieve inventory items\n    if inventory_items:\n        inv_filters = {\"device\": devices, \"component_type\": \"dcim.interface\"}\n        inv_fields = [\n            \"name\",\n            \"component {... on InterfaceType {id}}\",\n            \"role {name}\",\n            \"manufacturer {name}\",\n            \"custom_fields\",\n            \"label\",\n            \"description\",\n            \"tags {name}\",\n            \"asset_tag\",\n            \"serial\",\n            \"part_id\",\n        ]\n        queries[\"inventor_items\"] = {\n            \"obj\": \"inventory_item_list\",\n            \"filters\": inv_filters,\n            \"fields\": inv_fields,\n        }\n\n    query_result = self.graphql(instance=instance, queries=queries, dry_run=dry_run)\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    interfaces_data = query_result.result\n\n    # exit if no Interfaces returned\n    if not interfaces_data.get(\"interfaces\"):\n        raise Exception(\n            f\"{self.name} - no interfaces data in '{interfaces_data}' returned by '{instance}' \"\n            f\"for devices {', '.join(devices)}\"\n        )\n\n    # process query results\n    interfaces = interfaces_data.pop(\"interfaces\")\n\n    # process inventory items\n    if inventory_items:\n        inventory_items_list = interfaces_data.pop(\"inventor_items\")\n        # transform inventory items list to a dictionary keyed by intf_id\n        inventory_items_dict = {}\n        while inventory_items_list:\n            inv_item = inventory_items_list.pop()\n            # skip inventory items that does not assigned to components\n            if inv_item.get(\"component\") is None:\n                continue\n            intf_id = str(inv_item.pop(\"component\").pop(\"id\"))\n            inventory_items_dict.setdefault(intf_id, [])\n            inventory_items_dict[intf_id].append(inv_item)\n        # iterate over interfaces and add inventory items\n        for intf in interfaces:\n            intf[\"inventory_items\"] = inventory_items_dict.pop(intf[\"id\"], [])\n\n    # transform interfaces list to dictionary keyed by device and interfaces names\n    while interfaces:\n        intf = interfaces.pop()\n        _ = intf.pop(\"id\")\n        device_name = intf.pop(\"device\").pop(\"name\")\n        intf_name = intf.pop(\"name\")\n        if device_name in ret.result:  # Netbox issue #16299\n            ret.result[device_name][intf_name] = intf\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_connections","title":"<code>get_connections(devices, instance=None, dry_run=False, cables=False, circuits=False)</code>","text":"<p>Function to retrieve device connections data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>devices</code> <code>list</code> <p>list of devices to retrieve interface for</p> required <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>cables</code> <code>bool</code> <p>if True includes interfaces' directly attached cables details</p> <code>False</code> <code>circuits</code> <code>bool</code> <p>if True includes interfaces' circuits termination details</p> <code>False</code> <p>Returns:</p> Type Description <code>Result</code> <p>dictionary keyed by device name with connections data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_connections(\n    self,\n    devices: list,\n    instance: str = None,\n    dry_run: bool = False,\n    cables: bool = False,\n    circuits: bool = False,\n) -&gt; Result:\n    \"\"\"\n    Function to retrieve device connections data from Netbox using GraphQL API.\n\n    :param instance: Netbox instance name\n    :param devices: list of devices to retrieve interface for\n    :param dry_run: only return query content, do not run it\n    :param cables: if True includes interfaces' directly attached cables details\n    :param circuits: if True includes interfaces' circuits termination details\n    :return: dictionary keyed by device name with connections data\n    \"\"\"\n    # form final result dictionary\n    ret = Result(\n        task=f\"{self.name}:get_connections\", result={d: {} for d in devices}\n    )\n\n    # form lists of fields to request from netbox\n    cable_fields = \"\"\"\n        cable {\n            type\n            status\n            tenant {name}\n            label\n            tags {name}\n            length\n            length_unit\n            custom_fields\n        }\n    \"\"\"\n    if self.nb_version[0] == 4:\n        interfaces_fields = [\n            \"name\",\n            \"device {name}\",\n            \"\"\"connected_endpoints {\n            __typename \n            ... on InterfaceType {name device {name}}\n            ... on ProviderNetworkType {name}\n            }\"\"\",\n        ]\n    elif self.nb_version[0] == 3:\n        interfaces_fields = [\n            \"name\",\n            \"device {name}\",\n            \"\"\"connected_endpoints {\n            __typename \n            ... on InterfaceType {name device {name}}\n            }\"\"\",\n        ]\n    console_ports_fields = [\n        \"name\",\n        \"device {name}\",\n        \"\"\"connected_endpoints {\n          __typename \n          ... on ConsoleServerPortType {name device {name}}\n        }\"\"\",\n        \"\"\"link_peers {\n          __typename\n          ... on ConsoleServerPortType {name device {name}}\n          ... on FrontPortType {name device {name}}\n          ... on RearPortType {name device {name}}\n        }\"\"\",\n    ]\n    console_server_ports_fields = [\n        \"name\",\n        \"device {name}\",\n        \"\"\"connected_endpoints {\n          __typename \n          ... on ConsolePortType {name device {name}}\n        }\"\"\",\n        \"\"\"link_peers {\n          __typename\n          ... on ConsolePortType {name device {name}}\n          ... on FrontPortType {name device {name}}\n          ... on RearPortType {name device {name}}\n        }\"\"\",\n    ]\n\n    # add circuits info\n    if circuits is True:\n        interfaces_fields.append(\n            \"\"\"\n            link_peers {\n                __typename\n                ... on InterfaceType {name device {name}}\n                ... on FrontPortType {name device {name}}\n                ... on RearPortType {name device {name}}\n                ... on CircuitTerminationType {\n                    circuit{\n                        cid \n                        description \n                        tags{name} \n                        provider{name} \n                        status\n                        custom_fields\n                        commit_rate\n                    }\n                }\n            }\n        \"\"\"\n        )\n    else:\n        interfaces_fields.append(\n            \"\"\"\n            link_peers {\n                __typename\n                ... on InterfaceType {name device {name}}\n                ... on FrontPortType {name device {name}}\n                ... on RearPortType {name device {name}}\n            }\n        \"\"\"\n        )\n\n    # check if need to include cables info\n    if cables is True:\n        interfaces_fields.append(cable_fields)\n        console_ports_fields.append(cable_fields)\n        console_server_ports_fields.append(cable_fields)\n\n    # form query dictionary with aliases to get data from Netbox\n    queries = {\n        \"interface\": {\n            \"obj\": \"interface_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": interfaces_fields,\n        },\n        \"consoleport\": {\n            \"obj\": \"console_port_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": console_ports_fields,\n        },\n        \"consoleserverport\": {\n            \"obj\": \"console_server_port_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": console_server_ports_fields,\n        },\n    }\n\n    # retrieve full list of devices interface with all cables\n    query_result = self.graphql(queries=queries, instance=instance, dry_run=dry_run)\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    all_ports = query_result.result\n\n    # extract interfaces\n    for port_type, ports in all_ports.items():\n        for port in ports:\n            endpoints = port[\"connected_endpoints\"]\n            # skip ports that have no remote device connected\n            if not endpoints or not all(i for i in endpoints):\n                continue\n\n            # extract required parameters\n            cable = port.get(\"cable\", {})\n            device_name = port[\"device\"][\"name\"]\n            port_name = port[\"name\"]\n            link_peers = port[\"link_peers\"]\n            remote_termination_type = endpoints[0][\"__typename\"].lower()\n            remote_termination_type = remote_termination_type.replace(\"type\", \"\")\n\n            # form initial connection dictionary\n            connection = {\n                \"breakout\": len(endpoints) &gt; 1,\n                \"remote_termination_type\": remote_termination_type,\n                \"termination_type\": port_type,\n            }\n\n            # add remote connection details\n            if remote_termination_type == \"providernetwork\":\n                connection[\"remote_device\"] = None\n                connection[\"remote_interface\"] = None\n                connection[\"provider\"] = endpoints[0][\"name\"]\n            else:\n                remote_interface = endpoints[0][\"name\"]\n                if len(endpoints) &gt; 1:\n                    remote_interface = [i[\"name\"] for i in endpoints]\n                connection[\"remote_interface\"] = remote_interface\n                connection[\"remote_device\"] = endpoints[0][\"device\"][\"name\"]\n\n            # handle circuits\n            if (\n                circuits and \"circuit\" in link_peers[0]\n            ):  # add circuit connection details\n                connection[\"circuit\"] = link_peers[0][\"circuit\"]\n\n            # add cable and its peer details\n            if cables:\n                peer_termination_type = link_peers[0][\"__typename\"].lower()\n                peer_termination_type = peer_termination_type.replace(\"type\", \"\")\n                cable[\"peer_termination_type\"] = peer_termination_type\n                cable[\"peer_device\"] = link_peers[0].get(\"device\", {}).get(\"name\")\n                cable[\"peer_interface\"] = link_peers[0].get(\"name\")\n                if len(link_peers) &gt; 1:  # handle breakout cable\n                    cable[\"peer_interface\"] = [i[\"name\"] for i in link_peers]\n                connection[\"cable\"] = cable\n\n            ret.result[device_name][port_name] = connection\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_circuits","title":"<code>get_circuits(devices, instance=None, dry_run=False, cid=None)</code>","text":"<p>Function to retrieve device circuits data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list</code> <p>list of devices to retrieve interface for</p> required <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>cid</code> <code>list</code> <p>list of circuit identifiers to retrieve data for</p> <code>None</code> <p>Returns:</p> Type Description <p>dictionary keyed by device name with circuits data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_circuits(\n    self,\n    devices: list,\n    instance: str = None,\n    dry_run: bool = False,\n    cid: list = None,\n):\n    \"\"\"\n    Function to retrieve device circuits data from Netbox using GraphQL API.\n\n    :param devices: list of devices to retrieve interface for\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param cid: list of circuit identifiers to retrieve data for\n    :return: dictionary keyed by device name with circuits data\n    \"\"\"\n    # form final result object\n    ret = Result(task=f\"{self.name}:get_circuits\", result={d: {} for d in devices})\n\n    device_sites_fields = [\"site {slug}\"]\n    circuit_fields = [\n        \"cid\",\n        \"tags {name}\",\n        \"provider {name}\",\n        \"commit_rate\",\n        \"description\",\n        \"status\",\n        \"type {name}\",\n        \"provider_account {name}\",\n        \"tenant {name}\",\n        \"termination_a {id}\",\n        \"termination_z {id}\",\n        \"custom_fields\",\n        \"comments\",\n    ]\n\n    # retrieve list of hosts' sites\n    if self.nb_version[0] == 4:\n        dlist = '[\"{dl}\"]'.format(dl='\", \"'.join(devices))\n        device_filters_dict = {\"name\": f\"{{in_list: {dlist}}}\"}\n    elif self.nb_version[0] == 3:\n        device_filters_dict = {\"name\": devices}\n    device_sites = self.graphql(\n        obj=\"device_list\",\n        filters=device_filters_dict,\n        fields=device_sites_fields,\n        instance=instance,\n    )\n    sites = list(set([i[\"site\"][\"slug\"] for i in device_sites.result]))\n\n    # retrieve all circuits for devices' sites\n    if self.nb_version[0] == 4:\n        circuits_filters_dict = {\"site\": sites}\n        if cid:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid))\n            circuits_filters_dict[\"cid\"] = f\"{{in_list: {cid_list}}}\"\n    elif self.nb_version[0] == 3:\n        circuits_filters_dict = {\"site\": sites}\n\n    query_result = self.graphql(\n        obj=\"circuit_list\",\n        filters=circuits_filters_dict,\n        fields=circuit_fields,\n        dry_run=dry_run,\n        instance=instance,\n    )\n\n    # return dry run result\n    if dry_run is True:\n        return query_result\n\n    all_circuits = query_result.result\n\n    # iterate over circuits and map them to devices\n    for circuit in all_circuits:\n        cid = circuit.pop(\"cid\")\n        circuit[\"tags\"] = [i[\"name\"] for i in circuit[\"tags\"]]\n        circuit[\"type\"] = circuit[\"type\"][\"name\"]\n        circuit[\"provider\"] = circuit[\"provider\"][\"name\"]\n        circuit[\"tenant\"] = circuit[\"tenant\"][\"name\"] if circuit[\"tenant\"] else None\n        circuit[\"provider_account\"] = (\n            circuit[\"provider_account\"][\"name\"]\n            if circuit[\"provider_account\"]\n            else None\n        )\n        termination_a = circuit.pop(\"termination_a\")\n        termination_z = circuit.pop(\"termination_z\")\n        termination_a = termination_a[\"id\"] if termination_a else None\n        termination_z = termination_z[\"id\"] if termination_z else None\n\n        # retrieve A or Z termination path using Netbox REST API\n        if termination_a is not None:\n            circuit_path = self.rest(\n                instance=instance,\n                method=\"get\",\n                api=f\"/circuits/circuit-terminations/{termination_a}/paths/\",\n            )\n        elif termination_z is not None:\n            circuit_path = self.rest(\n                instance=instance,\n                method=\"get\",\n                api=f\"/circuits/circuit-terminations/{termination_z}/paths/\",\n            )\n        else:\n            continue\n\n        # check if circuit ends connect to device or provider network\n        if (\n            not circuit_path\n            or \"name\" not in circuit_path[0][\"path\"][0][0]\n            or \"name\" not in circuit_path[0][\"path\"][-1][-1]\n        ):\n            continue\n\n        # form A and Z connection endpoints\n        end_a = {\n            \"device\": circuit_path[0][\"path\"][0][0]\n            .get(\"device\", {})\n            .get(\"name\", False),\n            \"provider_network\": \"provider-network\"\n            in circuit_path[0][\"path\"][0][0][\"url\"],\n            \"name\": circuit_path[0][\"path\"][0][0][\"name\"],\n        }\n        end_z = {\n            \"device\": circuit_path[0][\"path\"][-1][-1]\n            .get(\"device\", {})\n            .get(\"name\", False),\n            \"provider_network\": \"provider-network\"\n            in circuit_path[0][\"path\"][-1][-1][\"url\"],\n            \"name\": circuit_path[0][\"path\"][-1][-1][\"name\"],\n        }\n        circuit[\"is_active\"] = circuit_path[0][\"is_active\"]\n\n        # map path ends to devices\n        if end_a[\"device\"] and end_a[\"device\"] in devices:\n            ret.result[end_a[\"device\"]][cid] = copy.deepcopy(circuit)\n            ret.result[end_a[\"device\"]][cid][\"interface\"] = end_a[\"name\"]\n            if end_z[\"device\"]:\n                ret.result[end_a[\"device\"]][cid][\"remote_device\"] = end_z[\"device\"]\n                ret.result[end_a[\"device\"]][cid][\"remote_interface\"] = end_z[\"name\"]\n            elif end_z[\"provider_network\"]:\n                ret.result[end_a[\"device\"]][cid][\"provider_network\"] = end_z[\"name\"]\n        if end_z[\"device\"] and end_z[\"device\"] in devices:\n            ret.result[end_z[\"device\"]][cid] = copy.deepcopy(circuit)\n            ret.result[end_z[\"device\"]][cid][\"interface\"] = end_z[\"name\"]\n            if end_a[\"device\"]:\n                ret.result[end_z[\"device\"]][cid][\"remote_device\"] = end_a[\"device\"]\n                ret.result[end_z[\"device\"]][cid][\"remote_interface\"] = end_a[\"name\"]\n            elif end_a[\"provider_network\"]:\n                ret.result[end_z[\"device\"]][cid][\"provider_network\"] = end_a[\"name\"]\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_nornir_inventory","title":"<code>get_nornir_inventory(filters=None, devices=None, instance=None, interfaces=False, connections=False, circuits=False, nbdata=False, primary_ip='ip4')</code>","text":"<p>Method to query Netbox and return devices data in Nornir inventory format.</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_nornir_inventory(\n    self,\n    filters: list = None,\n    devices: list = None,\n    instance: str = None,\n    interfaces: Union[dict, bool] = False,\n    connections: Union[dict, bool] = False,\n    circuits: Union[dict, bool] = False,\n    nbdata: bool = False,\n    primary_ip: str = \"ip4\",\n) -&gt; Result:\n    \"\"\"\n    Method to query Netbox and return devices data in Nornir inventory format.\n    \"\"\"\n    hosts = {}\n    inventory = {\"hosts\": hosts}\n    ret = Result(task=f\"{self.name}:get_nornir_inventory\", result=inventory)\n\n    # check Netbox status\n    netbox_status = self.get_netbox_status(instance=instance)\n    if netbox_status.result[instance or self.default_instance][\"status\"] is False:\n        return ret\n\n    # retrieve devices data\n    nb_devices = self.get_devices(\n        filters=filters, devices=devices, instance=instance\n    )\n\n    # form Nornir hosts inventory\n    for device_name, device in nb_devices.result.items():\n        host = device[\"config_context\"].pop(\"nornir\", {})\n        host.setdefault(\"data\", {})\n        name = host.pop(\"name\", device_name)\n        hosts[name] = host\n        # add platform if not provided in device config context\n        if not host.get(\"platform\"):\n            if device[\"platform\"]:\n                host[\"platform\"] = device[\"platform\"][\"name\"]\n            else:\n                log.warning(f\"{self.name} - no platform found for '{name}' device\")\n        # add hostname if not provided in config context\n        if not host.get(\"hostname\"):\n            if device[\"primary_ip4\"] and primary_ip in [\"ip4\", \"ipv4\"]:\n                host[\"hostname\"] = device[\"primary_ip4\"][\"address\"].split(\"/\")[0]\n            elif device[\"primary_ip6\"] and primary_ip in [\"ip6\", \"ipv6\"]:\n                host[\"hostname\"] = device[\"primary_ip6\"][\"address\"].split(\"/\")[0]\n            else:\n                host[\"hostname\"] = name\n        # add netbox data to host's data\n        if nbdata is True:\n            host[\"data\"].update(device)\n\n    # return if no hosts found for provided parameters\n    if not hosts:\n        log.warning(f\"{self.name} - no viable hosts returned by Netbox\")\n        return ret\n\n    # add interfaces data\n    if interfaces:\n        # decide on get_interfaces arguments\n        kwargs = interfaces if isinstance(interfaces, dict) else {}\n        # add 'interfaces' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"interfaces\", {})\n        # query interfaces data from netbox\n        nb_interfaces = self.get_interfaces(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save interfaces data to hosts' inventory\n        while nb_interfaces.result:\n            device, device_interfaces = nb_interfaces.result.popitem()\n            hosts[device][\"data\"][\"interfaces\"] = device_interfaces\n\n    # add connections data\n    if connections:\n        # decide on get_interfaces arguments\n        kwargs = connections if isinstance(connections, dict) else {}\n        # add 'connections' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"connections\", {})\n        # query connections data from netbox\n        nb_connections = self.get_connections(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save connections data to hosts' inventory\n        while nb_connections.result:\n            device, device_connections = nb_connections.result.popitem()\n            hosts[device][\"data\"][\"connections\"] = device_connections\n\n    # add circuits data\n    if circuits:\n        # decide on get_interfaces arguments\n        kwargs = circuits if isinstance(circuits, dict) else {}\n        # add 'circuits' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"circuits\", {})\n        # query circuits data from netbox\n        nb_circuits = self.get_circuits(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save circuits data to hosts' inventory\n        while nb_circuits.result:\n            device, device_circuits = nb_circuits.result.popitem()\n            hosts[device][\"data\"][\"circuits\"] = device_circuits\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.update_device_facts","title":"<code>update_device_facts(instance=None, dry_run=False, via='nornir', timeout=60, devices=None, **kwargs)</code>","text":"<p>Function to update device facts in Netbox using information provided by NAPALM get_facts getter:</p> <ul> <li>serial number</li> </ul> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>via</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_facts(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    via: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    **kwargs,\n):\n    \"\"\"\n    Function to update device facts in Netbox using information\n    provided by NAPALM get_facts getter:\n\n    - serial number\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param via: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    \"\"\"\n    result = {}\n    ret = Result(task=f\"{self.name}:update_device_facts\", result=result)\n    nb = self._get_pynetbox(instance)\n    kwargs[\"add_details\"] = True\n\n    if via == \"nornir\":\n        if devices:\n            kwargs[\"FL\"] = devices\n        data = self.client.run_job(\n            \"nornir\",\n            \"parse\",\n            kwargs=kwargs,\n            workers=\"all\",\n            timeout=timeout,\n        )\n        for worker, results in data.items():\n            for host, host_data in results[\"result\"].items():\n                if host_data[\"napalm_get\"][\"failed\"]:\n                    log.error(\n                        f\"{host} - facts update failed: '{host_data['napalm_get']['exception']}'\"\n                    )\n                    self.event(f\"{host} - facts update failed\")\n                    continue\n                nb_device = nb.dcim.devices.get(name=host)\n                if not nb_device:\n                    raise Exception(f\"'{host}' does not exist in Netbox\")\n                facts = host_data[\"napalm_get\"][\"result\"][\"get_facts\"]\n                # update serial number\n                nb_device.serial = facts[\"serial_number\"]\n                if not dry_run:\n                    nb_device.save()\n                result[host] = {\n                    \"update_device_facts_dry_run\"\n                    if dry_run\n                    else \"update_device_facts\": {\n                        \"serial\": facts[\"serial_number\"],\n                    }\n                }\n                self.event(f\"{host} - facts updated\")\n    else:\n        raise UnsupportedServiceError(f\"'{via}' service not supported\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.update_device_interfaces","title":"<code>update_device_interfaces(instance=None, dry_run=False, via='nornir', timeout=60, devices=None, create=True, **kwargs)</code>","text":"<p>Function to update device interfaces in Netbox using information provided by NAPALM get_interfaces getter:</p> <ul> <li>interface name</li> <li>interface description</li> <li>mtu</li> <li>mac address</li> <li>admin status</li> <li>speed</li> </ul> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>via</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>create</code> <code>bool</code> <p>create missing interfaces</p> <code>True</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_interfaces(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    via: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    create: bool = True,\n    **kwargs,\n):\n    \"\"\"\n    Function to update device interfaces in Netbox using information\n    provided by NAPALM get_interfaces getter:\n\n    - interface name\n    - interface description\n    - mtu\n    - mac address\n    - admin status\n    - speed\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param via: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param create: create missing interfaces\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    \"\"\"\n    result = {}\n    ret = Result(task=f\"{self.name}:update_device_interfaces\", result=result)\n    nb = self._get_pynetbox(instance)\n\n    if via == \"nornir\":\n        if devices:\n            kwargs[\"FL\"] = devices\n        kwargs[\"getters\"] = \"get_interfaces\"\n        data = self.client.run_job(\n            \"nornir\",\n            \"parse\",\n            kwargs=kwargs,\n            workers=\"all\",\n            timeout=timeout,\n        )\n        for worker, results in data.items():\n            for host, host_data in results[\"result\"].items():\n                updated = {}\n                result[host] = {\n                    \"update_device_interfaces_dry_run\"\n                    if dry_run\n                    else \"update_device_interfaces\": updated\n                }\n                interfaces = host_data[\"napalm_get\"][\"get_interfaces\"]\n                nb_device = nb.dcim.devices.get(name=host)\n                if not nb_device:\n                    raise Exception(f\"'{host}' does not exist in Netbox\")\n                nb_interfaces = nb.dcim.interfaces.filter(device_id=nb_device.id)\n                # update existing interfaces\n                for nb_interface in nb_interfaces:\n                    if nb_interface.name not in interfaces:\n                        continue\n                    interface = interfaces.pop(nb_interface.name)\n                    nb_interface.description = interface[\"description\"]\n                    nb_interface.mtu = interface[\"mtu\"]\n                    nb_interface.speed = interface[\"speed\"] * 1000\n                    nb_interface.mac_address = interface[\"mac_address\"]\n                    nb_interface.enabled = interface[\"is_enabled\"]\n                    if dry_run is not True:\n                        nb_interface.save()\n                    updated[nb_interface.name] = interface\n                    self.event(f\"{host} - updated interface {nb_interface.name}\")\n                # create new interfaces\n                if create is not True:\n                    continue\n                for interface_name, interface in interfaces.items():\n                    nb_interface = nb.dcim.interfaces.create(\n                        name=interface_name,\n                        device={\"name\": nb_device.name},\n                        type=\"other\",\n                    )\n                    nb_interface.description = interface[\"description\"]\n                    nb_interface.mtu = interface[\"mtu\"]\n                    nb_interface.speed = interface[\"speed\"] * 1000\n                    nb_interface.mac_address = interface[\"mac_address\"]\n                    nb_interface.enabled = interface[\"is_enabled\"]\n                    if dry_run is not True:\n                        nb_interface.save()\n                    updated[interface_name] = interface\n                    self.event(f\"{host} - created interface {nb_interface.name}\")\n    else:\n        raise UnsupportedServiceError(f\"'{via}' service not supported\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_next_ip","title":"<code>get_next_ip(prefix, description=None, device=None, interface=None, vrf=None, interface_create=True, secondary=False, tags=None, dns_name=None, tenant=None, comments=None, instance=None, dry_run=False)</code>","text":"<p>Method to retrieve existing or allocate new IP address in Netbox.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>IPv4 or IPv6 prefix e.g. <code>10.0.0.0/24</code> or prefix description to allocate next available IP Address from</p> required <code>description</code> <code>str</code> <p>IP address description to record in Netbox database</p> <code>None</code> <code>device</code> <code>str</code> <p>device name to find interface for and link IP address with</p> <code>None</code> <code>interface</code> <code>str</code> <p>interface name to link IP address with, <code>device</code> attribute also must be provided</p> <code>None</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_next_ip(\n    self,\n    prefix: str,\n    description: str = None,\n    device: str = None,\n    interface: str = None,\n    vrf: str = None,\n    interface_create: bool = True,\n    secondary: bool = False,\n    tags: list = None,\n    dns_name: str = None,\n    tenant: str = None,\n    comments: str = None,\n    instance: str = None,\n    dry_run: bool = False,\n):\n    \"\"\"\n    Method to retrieve existing or allocate new IP address in Netbox.\n\n    :param prefix: IPv4 or IPv6 prefix e.g. ``10.0.0.0/24`` or prefix description\n        to allocate next available IP Address from\n    :param description: IP address description to record in Netbox database\n    :param device: device name to find interface for and link IP address with\n    :param interface: interface name to link IP address with, ``device`` attribute\n        also must be provided\n\n    \"\"\"\n    print(f\"!!!!!!!!!!!! prefix {prefix}, description {description}\")\n    nb = self._get_pynetbox(instance)\n    nb_prefix = nb.ipam.prefixes.get(prefix=prefix, vrf=vrf)\n    nb_ip = nb_prefix.available_ips.create()\n    if description is not None:\n        nb_ip.description = description\n    nb_ip.save()\n\n    return Result(result=str(nb_ip))\n</code></pre>"},{"location":"clients_nfcli_overview/","title":"NORFAB Shell","text":"<p>NORFAB comes with interactive command line shell interface invoked using <code>nfcli</code> to work with the system.</p> <p>NORFAB CLI designed as a modal operating system. The term modal  describes a system that has various modes of operation, each having its own  domain of operation. The CLI uses a hierarchical structure for the modes.</p> <p>You can access a lower-level mode only from a higher-level mode. For example,  to access the Nornir mode, you must be in the privileged EXEC mode. Each mode  is used to accomplish particular tasks and has a specific set of commands that  are available in this mode. For example, to configure a router interface, you  must be in Nornir configuration mode. All configurations that you enter in  configuration mode apply only to this function.</p> <p>NORFAB CLI build using PICLE package.</p> <p>It is important to remember that in PICLE Shell, when you enter a command, the  command is executed. If you enter an incorrect command in a production environment,  it can negatively impact it.</p>","tags":["nfcli"]},{"location":"clients_python_api_overview/","title":"NORFAB Python API","text":"<p>NorFab python API exists to run the Automations fabric, components that need to be started defined in <code>inventory.yaml</code> file. To start working with NorFab need to import core object and instantiate it.</p> <pre><code>from norfab.core.nfapi import NorFab\n\nnf = NorFab(inventory=\"./inventory.yaml\")\nnf.start()\nnf.destroy()\n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p> <p>All interaction with NorFab happens via client. On NorFab start an  instance of local client created automatically and can be used to  submit the jobs</p> <pre><code>import pprint\nfrom norfab.core.nfapi import NorFab\n\nnf = NorFab(inventory=\"./inventory.yaml\")\nnf.start()\n\nresult = nf.client.run_job(\n    service=\"nornir\",\n    task=\"cli\",\n    kwargs={\"commands\": [\"show version\", \"show clock\"]}\n)\n\npprint.pprint(ret)\n\nnf.destroy()\n</code></pre>"},{"location":"clients_robot_client_overview/","title":"NorFab Robot Client","text":"<p>NORFAB Robot Client integrates with ROBOT framework to interact  with NORFAB, allowing to construct workflows and tasks using  ROBOT domain specific language (DSL).</p> <p>Robot Framework needs to be installed on the client:</p> <pre><code>pip install robotframework\n</code></pre>","tags":["robot"]},{"location":"clients_robot_client_overview/#supported-robot-keywords","title":"Supported ROBOT Keywords","text":"<ul> <li><code>Hosts</code> - <code>Fx</code> filters to target specific hosts, if not      provided targets all hosts</li> <li><code>Workers</code> - names of the workers to target, default is <code>all</code></li> <li><code>nr.test</code> - run Nornir Service <code>test</code> task using      provided Nornir tests suite</li> <li><code>nr.cli</code> - run Nornir Service <code>cli</code> task using      provided show commands and arguments</li> <li><code>nr.cfg</code> - run Nornir Service <code>cfg</code> task using      provided configuration commands and arguments</li> </ul>","tags":["robot"]},{"location":"clients_robot_client_overview/#nornir-tests-examples","title":"Nornir Tests Examples","text":"<p>This ROBOT framework test suite runs two tests using <code>nr.test</code>:</p> /path/to/robot_suite.robot<pre><code>*** Settings ***\nLibrary    norfab.clients.robot_client.NorFabRobot\n\n*** Test Cases ***\nTest NTP\n    nr.test    suite=nf://tests/test_ntp_config.yaml\n\nTest Software Version\n    Hosts      FM=arista_eos\n    nr.test    suite=nf://tests/test_version.yaml\n</code></pre> <p>Run test suite from client using <code>robot</code> command line tool:</p> <pre><code>robot /path/to/robot_suite.robot\n</code></pre>","tags":["robot"]},{"location":"norfab_changelog/","title":"Changelog","text":""},{"location":"norfab_changelog/#001","title":"0.0.1","text":""},{"location":"norfab_changelog/#changes","title":"Changes","text":"<ol> <li>Changes to Nornir service module files structure</li> <li>PICLE dependency updated: 0.7. -&gt; 0.8.</li> <li>Made Nornir Service <code>progress</code> argument set to <code>True</code> by default to emit and display events for all Nornir Jobs</li> <li>Nornir tests changed <code>table</code> argument to be set to <code>True</code> by default</li> </ol>"},{"location":"norfab_changelog/#features","title":"Features","text":"<ol> <li>Added support for Nornir parse task to source TTP template from file with autocompletion</li> <li>Added Nornir File Copy task to copy files to devices using SCP</li> <li>Added support for logs to  be collected into single file from all NorFab local processes</li> <li>Added to NorFab worker <code>job_list</code> and <code>job_details</code> methods</li> <li>Added <code>show jobs summary</code> and <code>show jobs details</code> commands to NorFab shell and to Nornir shell</li> </ol>"},{"location":"norfab_changelog/#bugs","title":"BUGS","text":"<ol> <li>Fixed Nornir Service Watchdog to clean up dead connections from hosts data</li> </ol>"},{"location":"norfab_changelog/#000","title":"0.0.0","text":"<p>Initial Release</p>"},{"location":"norfab_changelog/#notable-features","title":"Notable Features","text":"<ol> <li>NorFAB Broker, Client and Worker base classes</li> <li>Nornir Service</li> <li>Network Service</li> <li>Simple Inventory Datastore Service</li> <li>File service</li> <li>ZeroMQ encryption</li> </ol>"},{"location":"norfab_distributed_deployment/","title":"Distributed Deployment","text":"<p>TBD</p>"},{"location":"norfab_getting_started/","title":"Getting Started","text":"<p>The simplest way to start with NorFab is to do local installation  when broker, workers and client run locally, this is what we going  to demonstrate in this guide.</p> <p>Once NorFab installed, next step is to create a folder that will  hold your environment and start creating inventory files.</p> <p>Create <code>norfab</code> folder and inside of it create <code>inventory.yaml</code>,  file name is important as NORFAB by default searches for  <code>inventory.yaml</code>, file content is:</p> inventory.yaml<pre><code>broker: # (1)!\n  endpoint: \"tcp://127.0.0.1:5555\" # (2)!\n\nworkers: # (3)!\n  nornir-*: # (4)!\n    - nornir/common.yaml   \n  nornir-worker-1: # (5)!\n    - nornir/nornir-worker-1.yaml\n\ntopology: # (6)!\n  broker: True # (7)!\n  workers: # (8)!\n    - nornir-worker-1\n</code></pre> <ol> <li>Broker configuration inventory section</li> <li>URL to listen for connections on - <code>localhost</code> port <code>5555</code> in this case</li> <li>Workers configuration inventory section</li> <li>glob pattern that will match      all workers with <code>nornir-</code> in the name and map <code>common.yaml</code> file content for      each of them</li> <li>Worker definition to map inventory file to a specific worker that has name <code>nornir-worker-1</code></li> <li>Topology section to define what components to run</li> <li>Start broker process</li> <li>List of workers names to start processes for</li> </ol> <p>In this example we are working with Nornir service.</p> <p>Create <code>nornir</code> folder (folder name is arbitrary and can be anything)  and inside of it create two files. First file <code>common.yaml</code> to host  configuration common for all Nornir service workers:</p> common.yaml<pre><code>service: nornir # (1)!\nbroker_endpoint: \"tcp://127.0.0.1:5555\" # (2)!\n\n# next comes Nornir inventory and configuration\nrunner: # (3)!\n  plugin: RetryRunner\ndefault: {} # (4)!\ngroups: {} # (5)!\n</code></pre> <ol> <li>Name of the service this worker hosting</li> <li>Broker URL to initiate connections with</li> <li>Nornir runner plugin configuration</li> <li>Nornir <code>default</code> data section</li> <li>Nornir groups definition section</li> </ol> <p>Second file specific to the worker with name <code>nornir-worker-1</code> which holds Nornir inventory data:</p> nornir-worker-1.yaml<pre><code>hosts: \n  R1:\n    hostname: r1.lab.local\n    platform: cisco_ios\n    username: developer\n    password: secretpassword\n  R2:\n    hostname: 10.0.0.2\n    platform: cisco_ios\n    username: developer\n    password: secretpassword\n</code></pre> <p>This is how files structure will look like:</p> <pre><code>\u2514\u2500\u2500\u2500norfab\n    \u2502   inventory.yaml\n    \u2502\n    \u2514\u2500\u2500\u2500nornir\n            common.yaml\n            nornir-worker-1.yaml\n</code></pre> <p>Now you are ready to start NorFab Interactive Command Line Shell  Client - NFCLI. Open terminal window, navigate to the folder  where <code>inventory.yaml</code> located and start NFCLI:</p> <pre><code>C:\\&gt;cd norfab\nC:\\norfab&gt;nfcli\nnf#\n</code></pre> <p>this will start the NorFab broker process, Nornir worker process, instantiate NFCLI client and drop you into interactive command line shell </p> <pre><code>nf#? # (1)!\n file      File sharing service\n netbox    Netbox service\n nornir    Nornir service\n show      NorFab show commands\n exit      Exit current shell\n help      Print help message\n pwd       Print current shell path\n top       Exit to top shell\nnf#show workers # (2)!\n name             service  status  holdtime  keepalives tx/rx  alive (s)\n nornir-worker-1  nornir   alive   12.8      58 / 58           149\nnf#\nnf#nornir # (3)!\nnf[nornir]#?\n cfg     Configure devices over CLI interface\n cli     Send CLI commands to devices\n show    Show Nornir service parameters\n task    Run Nornir task\n test    Run network tests\n end     Exit application\n exit    Exit current shell\n help    Print help message\n pwd     Print current shell path\n top     Exit to top shell\nnf[nornir]#show hosts\n {\n     \"nornir-worker-1\": [\n         \"R1\",\n         \"R2\"\n     ]\n }\nnf[nornir]# end\nExiting...\n</code></pre> <ol> <li>Question mark plus enter to print commands help</li> <li>Run show command</li> <li>Drop into Nornir Service command shell</li> </ol> <p>NorFab CLI supports Tab completions, question mark help together with sub-shells, read more about NorFab CLI and how to use it here.</p> <p> That's it </p>","tags":["norfab"]},{"location":"norfab_help_with_norfab/","title":"Help with NORFAB","text":""},{"location":"norfab_help_with_norfab/#github","title":"GitHub","text":"<p>For issues and suggestions can reach out us on GitHub</p>"},{"location":"norfab_installation/","title":"Installation","text":""},{"location":"norfab_installation/#install-norfab","title":"Install NorFab","text":"<p>Install NorFab from PyPI</p> <pre><code>pip install norfab\n</code></pre> <p>NorFab core runs equally well on both Windows and Linux. Some  services might work only on one or the other, in that case that will be noted in service deployment details.</p>"},{"location":"norfab_installation/#extras","title":"Extras","text":"<p>Several extra installations supported tailoring certain services dependencies that you want to run on a given node.</p> <p>To install all dependencies for all services can use <code>full</code> extras:</p> <pre><code>pip install norfab[full]\n</code></pre>"},{"location":"norfab_installation/#norfab-cli-dependencies","title":"NORFAB CLI Dependencies","text":"<p>Need to install NorFab Interactive CLI dependencies</p> <pre><code>pip install norfab[nfcli]\n</code></pre>"},{"location":"norfab_installation/#nornir-service-dependencies","title":"Nornir Service Dependencies","text":"<p>Need to install Nornir service dependencies</p> <pre><code>pip install norfab[nornir_service]\n</code></pre>"},{"location":"norfab_installation/#netbox-service-dependencies","title":"Netbox Service Dependencies","text":"<p>Need to install Netbox service dependencies</p> <pre><code>pip install norfab[netbox_service]\n</code></pre>"},{"location":"norfab_installation/#operating-systems-support","title":"Operating Systems Support","text":"Component Windows Linux MacOS NorFab Core Nornir Service Netbox Service"},{"location":"norfab_why_use_norfab/","title":"Why Use NORFAB","text":""},{"location":"norfab_why_use_norfab/#unlock-the-full-potential-of-network-automation","title":"Unlock the Full Potential of Network Automation","text":"<p>In today's fast-paced digital world, network automation is no longer a luxury\u2014it's a necessity. NORFAB (Network Automations Fabric) is designed to empower network engineers with unparalleled automation capabilities, transforming the way you manage and optimize your network infrastructure.</p>"},{"location":"norfab_why_use_norfab/#key-features","title":"Key Features","text":""},{"location":"norfab_why_use_norfab/#1-run-anywhere","title":"1. Run Anywhere","text":"<p>NORFAB is incredibly versatile. Whether you're running on Windows, Mac, Linux, in a container, or a virtual machine, NORFAB adapts to your environment. Deploy it on-premises or in the cloud, centralized or fully distributed\u2014the choice is yours.</p>"},{"location":"norfab_why_use_norfab/#2-extend-anything","title":"2. Extend Anything","text":"<p>Extendability is at the core of NORFAB. With its modular architecture, you can easily integrate new functionalities, customize workflows, and adapt to evolving network requirements. NORFAB grows with your business.</p>"},{"location":"norfab_why_use_norfab/#3-integrate-with-everything","title":"3. Integrate with Everything","text":"<p>NORFAB offers seamless integration with a wide range of interfaces, including Python API, REST API, and CLI. This ensures that NORFAB can fit into any existing workflow or toolchain, making it easier to automate and manage your network.</p>"},{"location":"norfab_why_use_norfab/#4-manage-anything","title":"4. Manage Anything","text":"<p>From network devices to databases, NORFAB can manage a diverse set of resources. Use built-in services or develop your own to meet specific needs. NORFAB's flexibility ensures that you can automate any aspect of your network operations.</p>"},{"location":"norfab_why_use_norfab/#5-model-and-data-driven","title":"5. Model and Data-Driven","text":"<p>NORFAB leverages Pydantic models for API validation and documentation, ensuring that your automation processes are robust and reliable. This model-driven approach simplifies the management of complex network configurations.</p>"},{"location":"norfab_why_use_norfab/#6-automate-anything","title":"6. Automate Anything","text":"<p>With NORFAB, the sky's the limit. Automate routine tasks, complex workflows, and everything in between. NORFAB's powerful automation capabilities free up your time, allowing you to focus on strategic initiatives.</p>"},{"location":"norfab_why_use_norfab/#benefits","title":"Benefits","text":"<ul> <li>Increased Efficiency: Automate repetitive tasks and reduce manual intervention, leading to faster and more efficient network operations.</li> <li>Enhanced Reliability: Minimize human errors and ensure consistent network performance with automated processes.</li> <li>Scalability: Easily scale your network automation efforts as your infrastructure grows, without compromising on performance.</li> <li>Cost Savings: Reduce operational costs by streamlining network management and optimizing resource utilization.</li> <li>Future-Proof: Stay ahead of the curve with a solution that evolves with technological advancements and industry trends.</li> </ul>"},{"location":"norfab_why_use_norfab/#conclusion","title":"Conclusion","text":"<p>NORFAB is more than just a network automation tool\u2014it's a comprehensive solution designed to enhance your network management capabilities. By choosing NORFAB, you're investing in a future where network operations are seamless, efficient, and highly automated. Unlock the full potential of your network with NORFAB today!</p> <p>For more information or to schedule a demo, contact us at info@norfab.com.</p>"},{"location":"reference_architecture_nfp/","title":"NORFAB Protocol","text":"<p>Status: experimental Editor: d.mulyalin@gmail.com Contributors: </p> <p>The NORFAB Protocol (NFP) defines a reliable service-oriented request-reply dialog between a set of client applications, a broker and a set of worker applications representing service managing a set of resources. </p> <p>NFP covers presence, heartbeating, and service-resource-oriented request-reply processing. NFP originated from the MDP pattern defined in Chapter 4 of the ZeroMQ Guide and combined with TSP pattern (developed in same chapter) approach for persistent messaging across a network of arbitrarily connected clients and workers as a design for disk-based reliable messaging. NORFAB allows clients and workers to work without being connected to the network at the same time, and defines handshaking for safe storage of requests, and retrieval of replies.</p>"},{"location":"reference_architecture_nfp/#license","title":"License","text":"<p>Copyright (c) 2024 Denis Mulyalin.</p> <p>This Specification is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.</p> <p>This Specification is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program; if not, see http://www.gnu.org/licenses.</p>"},{"location":"reference_architecture_nfp/#change-process","title":"Change Process","text":"<p>This Specification is a free and open standard (see \u201cDefinition of a Free and Open Standard\") and is governed by the Digital Standards Organization\u2019s Consensus-Oriented Specification System (COSS) (see \u201cConsensus Oriented Specification System\").</p>"},{"location":"reference_architecture_nfp/#language","title":"Language","text":"<p>The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 (see \u201cKey words for use in RFCs to Indicate Requirement Levels\").</p>"},{"location":"reference_architecture_nfp/#goals","title":"Goals","text":"<p>The NORFAB Protocol (NFP) defines a reliable service-resource-oriented request-reply dialog between a set of client applications, a broker and a set of worker applications. NFP covers presence, heartbeating, and service-oriented request-reply processing. </p> <p>NFP uses name-based service resolution, named based resource targeting and structured protocol commands.</p> <p>The goals of NFP are to:</p> <ul> <li>Allow requests to be routed to workers on the basis of abstract service names.</li> <li>Allow broker and workers to detect disconnection of one another, through the use of heartbeating.</li> <li>ALlow task distribution by clients targeting <code>all</code> (broadcast), <code>any</code> (anycast) or <code>unicast</code> certain workers by names within given service.</li> <li>Allow the broker to recover from dead or disconnected workers by re-sending requests to other workers.</li> <li>Allow workers to manage <code>resource</code> entities, where entities can be dynamically distributed across all workers within the service.</li> <li>Allow workers to have access to inventory data hosted by broker</li> </ul>"},{"location":"reference_architecture_nfp/#architecture","title":"Architecture","text":""},{"location":"reference_architecture_nfp/#overall-topology","title":"Overall Topology","text":"<p>NFP connects a set of client applications, a single broker device and a pool of workers applications. Clients connect to the broker, as do workers. Clients and workers do not see each other, and both can come and go arbitrarily. The broker MAY open two sockets (ports), one front-end for clients, and one back-end for workers. However NFP is also designed to work over a single broker socket.</p> <p>We define \u2018client\u2019 applications as those issuing requests, and \u2018worker\u2019 applications as those processing them. NFP makes these assumptions:</p> <ul> <li>Workers are idempotent, i.e. it is safe to execute the same request more than once.</li> <li>Workers will handle at most one request a time, and will issue exactly one reply for each successful request.</li> <li>The NORFAB broker mediates requests one a per service basis. The broker SHOULD serve clients on a fair basis and SHOULD deliver requests to workers on the basis of targeting specified by client - <code>any</code> worker, <code>all</code> workers or <code>unicast</code> worker identified by name.</li> </ul> <p>NFP consists of four sub-protocols:</p> <ul> <li>NFP/Client, which covers how the NFP broker communicates with client applications.</li> <li>NFP/Worker, which covers how the NFP broker communicates with workers applications.</li> <li>NFP/Worker-PUB, which covers how broker subscribes to events published by workers.</li> <li>NFP/Broker-PUB, which covers how broker publishes collected worker events to clients.</li> </ul> <p>The broker SHOULD be an intermediary (a device) application that mediates Client-Workers communication. The broker SHOULD integrate Management Interface (MMI) service directly into it together with simple disk based Inventory service for workers.</p>"},{"location":"reference_architecture_nfp/#router-addressing","title":"ROUTER Addressing","text":"<p>The broker MUST use a ROUTER socket to accept requests from clients, and connections from workers. The broker MAY use a separate socket for each sub-protocol, or MAY use a single socket for both sub-protocols.</p> <p>From the \u00d8MQ Reference Manual:</p> <p>When receiving messages a ROUTER socket shall prepend a message part containing the identity of the originating peer to the message before passing it to the application. When sending messages a ROUTER socket shall remove the first part of the message and use it to determine the identity of the peer the message shall be routed to.</p> <p>This extra frame is not shown in the sub-protocol commands explained below.</p>"},{"location":"reference_architecture_nfp/#nfp-messages","title":"NFP messages","text":""},{"location":"reference_architecture_nfp/#open","title":"OPEN","text":"<p>A OPEN command consists of 4 frames, formatted on the wire as follows:</p> <pre><code>OPEN command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPC01\u201d or \u201cNFPW01\u201d or \u201cNFPB01\u201d (six bytes, representing NFP/Client or NFP/Worker or NFP/Broker v0.1)\nFrame 2: 0x00 (one byte, representing OPEN)\nFrame 3: Open body (opaque binary)\n</code></pre> <p>Worker and client use OPEN message to introduce itself to broker to negotiate connection parameters. Broker sends OPEN message back to client or worker to confirm the connection.</p>"},{"location":"reference_architecture_nfp/#ready","title":"READY","text":"<p>A READY command consists of a multipart message of 4 frames, formatted on the wire as follows:</p> <pre><code>READY command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPW01\u201d (six bytes, representing NFP/Worker v0.1)\nFrame 2: 0x01 (one byte, representing READY)\nFrame 3: Service name (printable string)\n</code></pre> <p>Worker sends READY command to broker, broker accepts ready request and registers worker with a service.</p>"},{"location":"reference_architecture_nfp/#keepalive","title":"KEEPALIVE","text":"<p>A KEEPALIVE command consists of 4 frames, formatted on the wire as follows:</p> <pre><code>KEEPALIVE command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPB01\u201d or \u201cNFPW01\u201d (six bytes, representing NFP/Broker or NFP/Worker v0.1)\nFrame 2: 0x02 (one byte, representing KEEPALIVE)\nFrame 3: Service name (printable string)\n</code></pre> <p>Broker sends KEEPALIVE messages to workers to indicate broker is still alive.</p> <p>Workers send KEEPALIVE messages to broker to indicate worker is still alive.</p>"},{"location":"reference_architecture_nfp/#disconnect","title":"DISCONNECT","text":"<p>A DISCONNECT command consists of 3 frames, formatted on the wire as follows:</p> <pre><code>DISCONNECT command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPB01\u201d or \u201cNFPW01\u201d (six bytes, representing NFP/Broker or NFP/Worker v0.1)\nFrame 2: 0x03 (one byte, representing DISCONNECT)\nFrame 3: Service name (printable string)\nFrame 4: Disconnect body (opaque binary)\n</code></pre> <p>Broker sends DISCONNECT command to workers to signal the request to disconnect. </p> <p>Workers also can send DISCONNECT command to broker to signal the request to disconnect. </p>"},{"location":"reference_architecture_nfp/#post","title":"POST","text":"<p>A POST command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>POST command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPC01\u201d or \"NFPB01\" (six bytes, representing NFP/Client or NFP/Broker v0.1)\nFrame 2: 0x04 (one byte, representing POST)\nFrame 3: Service name (printable string)\nFrame 4: Target (printable string) workers, `all` (default), `any` or comma separated `worker names`\nFrame 5: Job UUID (printable string)\nFrames 6: POST body (opaque binary)\n</code></pre> <p>Client sends POST message to broker to distribute job requests among workers. </p> <p>Broker relays POST message to individual workers to publish job request.</p>"},{"location":"reference_architecture_nfp/#response","title":"RESPONSE","text":"<p>A RESPONSE command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>RESPONSE command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPB01\u201d or \u201cNFPW01\u201d (six bytes, representing NFP/Broker or NFP/Worker v0.1)\nFrame 2: 0x05 (one byte, representing RESPONSE)\nFrame 3: Service name (printable string)\nFrame 4: Job UUID (printable string)\nFrame 5: Status code (explained below)\nFrames 6: Response body (opaque binary)\n</code></pre> <p>Worker sends RESPONSE message to broker with requests status or job results. </p> <p>Broker relays RESPONSE message to client.</p>"},{"location":"reference_architecture_nfp/#get","title":"GET","text":"<p>A GET command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>GET command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPC01\u201d or \"NFPB01\" (six bytes, representing NFP/Client or NFP/Broker v0.1)\nFrame 2: 0x06 (one byte, representing GET)\nFrame 3: Service name (printable string)\nFrame 4: Target (printable string) workers, `all` (default), `any` or comma separated `worker names`\nFrame 5: Job UUID (printable string)\nFrames 6: GET request body (opaque binary)\n</code></pre> <p>Client sends GET message to broker to retrieve job results. </p> <p>Broker relays GET message to individual workers to request job request.</p>"},{"location":"reference_architecture_nfp/#delete","title":"DELETE","text":"<p>A DELETE command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>DELETE command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPC01\u201d or \"NFPB01\" (six bytes, representing NFP/Client or NFP/Broker v0.1)\nFrame 2: 0x07 (one byte, representing POST)\nFrame 3: Service name (printable string)\nFrame 4: Target (printable string) workers, `all` (default), `any` or comma separated `worker names`\nFrame 5: Job UUID (printable string)\nFrames 6: DELETE body (opaque binary)\n</code></pre> <p>Client sends DELETE message to broker to distribute job delete requests to workers. </p> <p>Broker relays DELETE message to individual workers to cancel the job.</p>"},{"location":"reference_architecture_nfp/#event","title":"EVENT","text":"<p>A EVENT command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>EVENT command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPW01\u201d (six bytes, representing NFP/Worker v0.1)\nFrame 2: 0x08 (one byte, representing EVENT)\nFrame 3: Service name (printable string)\nFrame 4: Topic (printable string e.g. Job UUID)\nFrame 5: Status code 200 (explained below)\nFrames 6: Event body (opaque binary)\n</code></pre> <p>Worker sends EVENT message to Broker to supply information about job execution. </p> <p>Broker relays EVENT message to certain Client.</p>"},{"location":"reference_architecture_nfp/#status-frames","title":"Status Frames","text":"<p>Every RESPONSE message contains a status frame followed by zero or more content frames. The status frame contains a string formatted as three digits, optionally followed by a space and descriptive text. A client MUST NOT treat the text as significant in any way. Implementations MAY NOT use status codes that are not defined here:</p> <p>200 - OK. The NORFAB worker executed the request successfully.  202 - ACCEPTED. The NORFAB Broker accepted POST request to dispatch the job. 300 - PENDING. The client SHOULD retry the request at a later time. 400 - UNKNOWN. The client is using an invalid or unknown UUID and SHOULD NOT retry. 408 - REQUEST TIMEOUT. Client did not receive response from broker or worker. 417 - EXPECT FAILED. Client did not receive what it was expecting to receive. 500 - ERROR. The server cannot complete the request due to some internal error. The client SHOULD retry at some later time.</p>"},{"location":"reference_architecture_nfp/#nfpclient","title":"NFP/Client","text":"<p>NFP/Client is a strictly synchronous dialog initiated by the client (where \u2018C\u2019 represents the client, and \u2018B\u2019 represents the broker):</p> <pre><code>C: OPEN\nB: OPEN\n\nRepeat:\n\n    C: POST\n    B: RESPONSE\n    ...\n\n    C: GET\n    B: RESPONSE\n    ...\n</code></pre> <p>Clients SHOULD use a REQ socket when implementing a synchronous request-reply pattern. The REQ socket will silently create frame 0 for outgoing requests, and remove it for replies before passing them to the calling application. </p> <p>Clients MAY use any suitable strategy for recovering from a non-responsive broker. One recommended strategy is:</p> <ul> <li>To use polling instead of blocking receives on the request socket.</li> <li>If there is no reply within some timeout, to close the request socket and open a new socket, and resend the request on that new socket.</li> <li>If there is no reply after several retries, to signal the transaction as failed.</li> <li>The service name is a 0MQ string that matches the service name specified by a worker in its READY command (see NFP/Worker below). The broker SHOULD queue client requests for which service no workers has been registered and SHOULD expire these requests after a reasonable and configurable time if no service's workers has been registered.</li> </ul>"},{"location":"reference_architecture_nfp/#nfpbroker","title":"NFP/Broker","text":"<p>NFP/Broker is a mediator that receives messages from clients and dispatches them out to workers. In return messages from workers routed to clients.</p>"},{"location":"reference_architecture_nfp/#nfpworker","title":"NFP/Worker","text":"<p>NFP/Worker is a mix of a synchronous request-reply dialog, initiated by the service worker, and an asynchronous heartbeat dialog that operates independently in both directions. This is the synchronous dialog (where \u2018W\u2019 represents the service worker, and \u2018B\u2019 represents the broker):</p> <pre><code>W: OPEN\nB: OPEN\nW: READY\n\nRepeat:\n\n    B: POST\n    W: RESPONSE\n    ...\n\n    B: GET\n    W: RESPONSE\n    ... \n</code></pre> <p>The asynchronous heartbeat dialog operates on the same sockets and works thus:</p> <pre><code>Repeat:                 Repeat:\n\n    W: HEARTBEAT            B: HEARTBEAT\n    ...                     ...\n\nW: DISCONNECT           B: DISCONNECT\n</code></pre> <p>NFP/Worker commands all start with an empty frame to allow consistent processing of client and worker frames in a broker, over a single socket. The empty frame has no other significance.</p>"},{"location":"reference_architecture_nfp/#nfpworker-pub","title":"NFP/Worker-PUB","text":"<p>TBD </p>"},{"location":"reference_architecture_nfp/#nfpbroker-pub","title":"NFP/Broker-PUB","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#job-persistence","title":"Job Persistence","text":"<p>Workers SHOULD persistently store job requests and job execution results for a configurable amount of time allowing clients (client submitted job request or any other client) to request job execution results on demand.</p> <p>Clients SHOULD persistently store job requests and MAY store job execution results locally for a configurable amount of time.</p>"},{"location":"reference_architecture_nfp/#opening-and-closing-a-connection","title":"Opening and Closing a Connection","text":"<p>The worker is responsible for opening and closing a logical connection. One worker MUST connect to exactly one broker using a single \u00d8MQ DEALER (XREQ) socket.</p> <p>Since \u00d8MQ automatically reconnects peers after a failure, every NFP command includes the protocol header to allow proper validation of all messages that a peer receives.</p> <p>The worker opens the connection to the broker by creating a new socket, connecting it, and then sending a READY command to register to a service. One worker handles precisely one service, and many workers MAY handle the same service. The worker MUST NOT send a further READY.</p> <p>There is no response to a READY. The worker SHOULD assume the registration succeeded until or unless it receives a DISCONNECT, or it detects a broker failure through heartbeating.</p> <p>The worker MAY send DISCONNECT at any time, including before READY. When the broker receives DISCONNECT from a worker it MUST send no further commands to that worker.</p> <p>The broker MAY send DISCONNECT at any time, by definition after it has received at least one command from the worker.</p> <p>The broker MUST respond to any valid but unexpected command by sending DISCONNECT and then no further commands to that worker. The broker SHOULD respond to invalid messages by dropping them and treating that peer as invalid.</p> <p>When the worker receives DISCONNECT it must send no further commands to the broker; it MUST close its socket, and reconnect to the broker on a new socket. This mechanism allows workers to re-register after a broker failure and recovery.</p>"},{"location":"reference_architecture_nfp/#post-and-response-processing","title":"POST and RESPONSE Processing","text":"<p>The POST and the RESPONSE commands MUST contain precisely one client address frame. This frame MUST be followed by an empty (zero sized) frame.</p> <p>The address of each directly connected client is prepended by the ROUTER socket to all request messages coming from clients. That ROUTER socket also expects a client address to be prepended to each reply message sent to a client.</p>"},{"location":"reference_architecture_nfp/#keepaliving","title":"Keepaliving","text":"<p>KEEPALIVE commands are valid at any time, after a READY command.</p> <p>Any received command except DISCONNECT acts as a keepalive. Peers SHOULD NOT send KEEPALIVE commands while also sending other commands.</p> <p>Both broker and worker MUST send heartbeats at regular and agreed-upon intervals. A peer MUST consider the other peer \u201cdisconnected\u201d if no keepalive arrives within some multiple of that interval (usually 3-5).</p> <p>If the worker detects that the broker has disconnected, it SHOULD restart a new conversation.</p> <p>If the broker detects that the worked has disconnected, it SHOULD stop sending messages of any type to that worker.</p>"},{"location":"reference_architecture_nfp/#broker-management-interface-bmmi","title":"Broker Management Interface (BMMI)","text":"<p>Broker SHOULD implement Management interface as a service endpoint for clients to interact with.</p> <p>Broker should use <code>mmi.service.broker</code> service endpoint to listen to client's requests. </p> <p>These MMI functions SHOULD be implemented:</p> <ul> <li><code>show_broker</code> - to return broker status and statistics</li> <li><code>show_workers</code> - to return worker status and statistics </li> <li><code>show_clients</code> - to return clients statistics</li> <li><code>show_services</code> - to return services status and statistics </li> <li><code>restart</code> - restart broker</li> <li><code>shutdown</code> - shutdown broker completely</li> <li><code>disconnect</code> - to disconnect all workers</li> </ul>"},{"location":"reference_architecture_nfp/#worker-management-interface-wmmi","title":"Worker Management Interface (WMMI)","text":"<p>Worker SHOULD implement Management interface as a service endpoint for clients to interact with.</p> <p>Worker should use <code>mmi.service.worker</code> service endpoint to listen to client's requests. </p> <p>These MMI functions SHOULD be implemented:</p> <ul> <li><code>show_broker</code> - to return broker status and statistics</li> <li><code>show_workers</code> - to return worker status and statistics </li> <li><code>show_clients</code> - to return clients statistics</li> <li><code>restart</code> - restart worker</li> <li><code>shutdown</code> - shutdown worker completely</li> <li><code>disconnect</code> - to disconnect worker from broker and re-establish connection</li> </ul>"},{"location":"reference_architecture_nfp/#broker-simple-inventory-datastore-sid","title":"Broker Simple Inventory Datastore (SID)","text":"<p>Broker should implement Inventory Datastore to store and serve configuration to workers as well as arbitrary workers inventory data.</p> <p>Broker should use <code>sid.service.broker</code> service endpoint to listen to worker's requests. </p> <p>Workers willing to make use of broker's inventory datastore should implement <code>NFP/Client</code> protocol defined above to request inventory data.</p> <p>These SID functions SHOULD be implemented:</p> <ul> <li><code>get_inventory</code> - to return inventory content for given worker</li> </ul>"},{"location":"reference_architecture_nfp/#sid-implementation","title":"SID Implementation","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#broker-file-sharing-service-fss","title":"Broker File Sharing Service (FSS)","text":"<p>Broker implements service to serve files to clients and workers from local file system using <code>nf://&lt;filepath&gt;</code> URL for supported arguments.</p> <p>Broker should use <code>fss.service.broker</code> service endpoint to listen to worker's requests. </p>"},{"location":"reference_architecture_nfp/#fss-implementation","title":"FSS Implementation","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#reliability","title":"Reliability","text":"<p>The NORFAB pattern is designed to extend the basic \u00d8MQ request-reply pattern with the ability to detect and recover from a specific set of failures:</p> <ul> <li>Worker applications which crash, run too slowly, or freeze.</li> <li>Worker applications that are disconnected from the network (temporarily or permanently).</li> <li>Client applications that are temporarily disconnected from the network.</li> <li>A queue broker that crashes and is restarted.</li> <li>A queue broker that suffers a permanent failure.</li> <li>Requests or replies that are lost due to any of these failures.</li> <li>The general approach is to retry and reconnect, using heartbeating when needed. </li> </ul>"},{"location":"reference_architecture_nfp/#scalability-and-performance","title":"Scalability and Performance","text":"<p>NORFAB is designed to be scalable to large numbers (thousands) of workers and clients allowing to manage 10s of thousands resource entities, limited only by system resources on the broker. Partitioning of workers by service allows for multiple applications to share the same broker infrastructure. Workers manage a set of resources defined by system administrator. Same resource can be managed by single or multiple workers, system impose no restrictions on how resource entities distributed across workers.</p> <p>Throughput performance for a single client application will be limited to tens of thousands, not millions, of request-reply transactions per second due to round-trip costs and the extra latency of a broker-based approach. The larger the request and reply messages, the more efficient NORFAB will become. </p> <p>System requirements for the broker are moderate: no more than one outstanding request per client will be queued, and message contents can be switched between clients and workers without copying or processing. A single broker thread can therefore switch several million messages per second.</p>"},{"location":"reference_architecture_nfp/#security","title":"Security","text":""},{"location":"reference_architecture_nfp/#worker-authentication","title":"Worker Authentication","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#worker-authorization","title":"Worker Authorization","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#client-authentication","title":"Client Authentication","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#client-authorization-role-based-access-control-rbac","title":"Client Authorization - Role Based Access Control (RBAC)","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#client-encryption","title":"Client Encryption","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#worker-encryption","title":"Worker Encryption","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#accounting","title":"Accounting","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#known-weaknesses","title":"Known Weaknesses","text":"<ul> <li>The heartbeat rate must be set to similar values in broker and worker, or false disconnections will occur. </li> <li>The use of multiple frames for command formatting has a performance impact.</li> </ul>"},{"location":"reference_architecture_norfab/","title":"NORFAB Architecture","text":""},{"location":"reference_architecture_norfab/#high-level-design","title":"High Level Design","text":""},{"location":"reference_architecture_norfab/#low-level-design","title":"Low Level Design","text":"<p>Low level design revolves around resource oriented services - services that manage resources, where resources could be databases, network devices, file system etc.</p> <p></p>"},{"location":"reference_architecture_norfab/#jobs-execution-flow","title":"Jobs Execution Flow","text":"<p>There are multiple job flows implemented:</p> <ul> <li>JOB POST FLOW - for clients to publish jobs to workers</li> <li>JOB LOOP - job execution performed by workers</li> <li>JOB GET FLOW - for clients to retrieve job execution results</li> </ul> <p>Above flows depicted on the diagram.</p> <p></p>"},{"location":"reference_norfab_inventory/","title":"NorFab Inventory","text":"<p>NorFab comes with Simple Inventory Datastore (SID) hosted by broker.</p>"},{"location":"reference_norfab_inventory/#broker-inventory","title":"Broker Inventory","text":"<p>TBD</p>"},{"location":"reference_norfab_inventory/#workers-inventory","title":"Workers Inventory","text":"<p>To understand how Simple Inventory Datastore serves workers inventory  it is good to know that each worker has a unique name to identify it.</p> <p>With that in mind, the goal is to map inventory data to individual worker by its name.</p> <p>For example, let's pretend that worker name is <code>nornir-worker-1</code> and we have <code>common.yaml</code> and <code>nornir-worker-1.yaml</code> files with inventory data  that we need to provide worker with.</p> <p>To do the mapping between worker name and inventory files we can put this in NorFab inventory (<code>inventory.yaml</code>) file:</p> <pre><code>workers:\n  nornir-*:\n    - nornir/common.yaml  \n  nornir-worker-1:\n    - nornir/nornir-worker-1.yaml\n</code></pre> <p>Where files structure would look like this:</p> <pre><code>\u2514\u2500\u2500\u2500rootfolder\n    \u2502   inventory.yaml\n    \u2502\n    \u2514\u2500\u2500\u2500nornir\n            common.yaml\n            nornir-worker-1.yaml\n</code></pre> <p>As you can see, <code>inventory.yaml</code> file contains <code>workers</code> section with a dictionary keyed by glob patterns to match against workers' names, once worker name matched by the pattern, all items in the list underneaths that pattern being loaded and recursively merged. As such, process continues  until all patterns evaluated. Final output of the process is a combined inventory data of all the matched files.</p> <p>The recursive logic of combining inventory data files is pretty  straightforward - each next data file merged into the previous data file  overriding the overlapping values.</p> <p>The glob pattern matching logic allows be as specific as required and  map specific files to individual workers or to map single data file to  multiple workers or map multiple files to multiple workers, all combinations  supported.</p> <p>For example, we have a group of two workers with names <code>netbox-wroker-1.1</code> and <code>netbox-worker-1.2</code> and we want to map <code>netbox_common.yaml</code> to both of the workers, in that case NorFab inventory (<code>inventory.yaml</code>) file could have this content:</p> <pre><code>workers:\n  netbox-worker-1.*:\n    - nornir/netbox_common.yaml  \n</code></pre> <p>Where files structure would look like this:</p> <pre><code>\u2514\u2500\u2500\u2500rootfolder\n    \u2502   inventory.yaml\n    \u2502\n    \u2514\u2500\u2500\u2500netbox\n            netbox_common.yaml\n</code></pre> <p>Both workers will be served with  <code>netbox_common.yaml</code> file content as an inventory data.</p>"},{"location":"reference_norfab_inventory/#workers-inventory-parameters","title":"Workers Inventory Parameters","text":"<p>Workers inventory can contain these common parameters:</p> <ol> <li><code>service</code> - name of the service this worker belongs to</li> <li><code>broker_endpoint</code> - Broker URL to connect to</li> </ol> <p>Sample worker base inventory:</p> <pre><code>service: nornir\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\n</code></pre> <p>The rest of the inventory data is worker specific.</p>"},{"location":"reference_norfab_inventory/#topology-inventory","title":"Topology Inventory","text":"<p>Topology section of NorFab inventory identifies the components that need to be started on the given node.</p>"},{"location":"services_overview/","title":"Services Overview","text":"<p>Services is where NORFAB value comes from as it is capable of managing diverse set of resources through them.</p>","tags":["services"]},{"location":"workers/nornir/api_reference_workers_nornir_worker/","title":"Nornir Worker","text":""},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker--nornir-worker-inventory-reference","title":"Nornir Worker Inventory Reference","text":"<ul> <li><code>watchdog_interval</code> - watchdog run interval in seconds, default is 30</li> <li><code>connections_idle_timeout</code> - watchdog connection idle timeout,      default is <code>None</code> - no timeout, connection always kept alive,      if set to 0, connections disconnected imminently after task      completed, if positive number, connection disconnected after      not being used for over <code>connections_idle_timeout</code></li> </ul>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog","title":"<code>WatchDog(worker)</code>","text":"<p>               Bases: <code>WorkerWatchDog</code></p> <p>Class to monitor Nornir worker performance</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def __init__(self, worker):\n    super().__init__(worker)\n    self.worker = worker\n    self.connections_idle_timeout = worker.inventory.get(\n        \"connections_idle_timeout\", None\n    )\n    self.connections_data = {}  # store connections use timestamps\n    self.started_at = time.time()\n\n    # stats attributes\n    self.idle_connections_cleaned = 0\n    self.dead_connections_cleaned = 0\n\n    # list of tasks for watchdog to run in given order\n    self.watchdog_tasks = [\n        self.connections_clean,\n        self.connections_keepalive,\n    ]\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog.connections_update","title":"<code>connections_update(nr, plugin)</code>","text":"<p>Function to update connection use timestamps for each host</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <p>Nornir object</p> required <code>plugin</code> <code>str</code> <p>connection plugin name</p> required Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def connections_update(self, nr, plugin: str) -&gt; None:\n    \"\"\"\n    Function to update connection use timestamps for each host\n\n    :param nr: Nornir object\n    :param plugin: connection plugin name\n    \"\"\"\n    conn_stats = {\n        \"last_use\": None,\n        \"last_keepealive\": None,\n        \"keepalive_count\": 0,\n    }\n    for host_name in nr.inventory.hosts:\n        self.connections_data.setdefault(host_name, {})\n        self.connections_data[host_name].setdefault(plugin, conn_stats.copy())\n        self.connections_data[host_name][plugin][\"last_use\"] = time.ctime()\n    log.info(\n        f\"{self.worker.name} - updated connections use timestamps for '{plugin}'\"\n    )\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog.connections_clean","title":"<code>connections_clean()</code>","text":"<p>Check if need to tear down connections that are idle - not being used over connections_idle_timeout</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def connections_clean(self):\n    \"\"\"\n    Check if need to tear down connections that are idle -\n    not being used over connections_idle_timeout\n    \"\"\"\n    # dictionary keyed by plugin name and value as a list of hosts\n    disconnect = {}\n    if not self.worker.connections_lock.acquire(blocking=False):\n        return\n    try:\n        # if idle timeout not set, connections don't age out\n        if self.connections_idle_timeout is None:\n            disconnect = {}\n        # disconnect all connections for all hosts\n        elif self.connections_idle_timeout == 0:\n            disconnect = {\"all\": list(self.connections_data.keys())}\n        # only disconnect aged/idle connections\n        elif self.connections_idle_timeout &gt; 0:\n            for host_name, plugins in self.connections_data.items():\n                for plugin, conn_data in plugins.items():\n                    last_use = time.mktime(time.strptime(conn_data[\"last_use\"]))\n                    age = time.time() - last_use\n                    if age &gt; self.connections_idle_timeout:\n                        disconnect.setdefault(plugin, [])\n                        disconnect[plugin].append(host_name)\n        # run task to disconnect connections for aged hosts\n        for plugin, hosts in disconnect.items():\n            if not hosts:\n                continue\n            aged_hosts = FFun(self.worker.nr, FL=hosts)\n            aged_hosts.run(task=nr_connections, call=\"close\", conn_name=plugin)\n            log.debug(\n                f\"{self.worker.name} watchdog, disconnected '{plugin}' \"\n                f\"connections for '{', '.join(hosts)}'\"\n            )\n            self.idle_connections_cleaned += len(hosts)\n            # wipe out connections data if all connection closed\n            if plugin == \"all\":\n                self.connections_data = {}\n                break\n            # remove disconnected plugin from host's connections_data\n            for host in hosts:\n                self.connections_data[host].pop(plugin)\n                if not self.connections_data[host]:\n                    self.connections_data.pop(host)\n    except Exception as e:\n        msg = f\"{self.worker.name} - watchdog failed to close idle connections, error: {e}\"\n        log.error(msg)\n    finally:\n        self.worker.connections_lock.release()\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog.connections_keepalive","title":"<code>connections_keepalive()</code>","text":"<p>Keepalive connections and clean up dead connections if any</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def connections_keepalive(self):\n    \"\"\"Keepalive connections and clean up dead connections if any\"\"\"\n    if self.connections_idle_timeout == 0:  # do not keepalive if idle is 0\n        return\n    if not self.worker.connections_lock.acquire(blocking=False):\n        return\n    try:\n        log.debug(f\"{self.worker.name} - watchdog running connections keepalive\")\n        stats = HostsKeepalive(self.worker.nr)\n        self.dead_connections_cleaned += stats[\"dead_connections_cleaned\"]\n        # remove connections that are no longer present in Nornir inventory\n        for host_name, host_connections in self.connections_data.items():\n            for connection_name in list(host_connections.keys()):\n                if not self.worker.nr.inventory.hosts[host_name].connections.get(\n                    connection_name\n                ):\n                    self.connections_data[host_name].pop(connection_name)\n        # remove host if no connections left\n        for host_name in list(self.connections_data.keys()):\n            if self.connections_data[host_name] == {}:\n                self.connections_data.pop(host_name)\n        # update connections statistics\n        for plugins in self.connections_data.values():\n            for plugin in plugins.values():\n                plugin[\"last_keepealive\"] = time.ctime()\n                plugin[\"keepalive_count\"] += 1\n    except Exception as e:\n        msg = f\"{self.worker.name} - watchdog HostsKeepalive check error: {e}\"\n        log.error(msg)\n    finally:\n        self.worker.connections_lock.release()\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker","title":"<code>NornirWorker(broker, service, worker_name, exit_event=None, init_done_event=None, log_level='WARNING', log_queue=None)</code>","text":"<p>               Bases: <code>NFPWorker</code></p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <code>str</code> <p>broker URL to connect to</p> required <code>service</code> <code>str</code> <p>name of the service with worker belongs to</p> required <code>worker_name</code> <code>str</code> <p>name of this worker</p> required <code>exit_event</code> <p>if set, worker need to stop/exit</p> <code>None</code> <code>init_done_event</code> <p>event to set when worker done initializing</p> <code>None</code> <code>log_level</code> <code>str</code> <p>logging level of this worker</p> <code>'WARNING'</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def __init__(\n    self,\n    broker: str,\n    service: str,\n    worker_name: str,\n    exit_event=None,\n    init_done_event=None,\n    log_level: str = \"WARNING\",\n    log_queue: object = None,\n):\n    super().__init__(broker, service, worker_name, exit_event, log_level, log_queue)\n    self.init_done_event = init_done_event\n    self.tf_base_path = os.path.join(self.base_dir, \"tf\")\n\n    # misc attributes\n    self.connections_lock = Lock()\n\n    # get inventory from broker\n    self.inventory = self.load_inventory()\n\n    # pull Nornir inventory from Netbox\n    self._pull_netbox_inventory()\n\n    # initiate Nornir\n    self._init_nornir()\n\n    # initiate watchdog\n    self.watchdog = WatchDog(self)\n    self.watchdog.start()\n\n    if self.init_done_event is not None:\n        self.init_done_event.set()\n\n    log.info(f\"{self.name} - Started\")\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.render_jinja2_templates","title":"<code>render_jinja2_templates(templates, context, filters=None)</code>","text":"<p>Helper function to render a list of Jinja2 templates and combine them in a single string.</p> <p>Parameters:</p> Name Type Description Default <code>templates</code> <code>list[str]</code> <p>list of template strings to render</p> required <code>context</code> <code>dict</code> <p>Jinja2 context dictionary</p> required <code>filter</code> <p>custom Jinja2 filters</p> required <p>Returns:</p> Type Description <code>str</code> <p>list of rendered strings</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def render_jinja2_templates(\n    self, templates: list[str], context: dict, filters: dict = None\n) -&gt; str:\n    \"\"\"\n    Helper function to render a list of Jinja2 templates and\n    combine them in a single string.\n\n    :param templates: list of template strings to render\n    :param context: Jinja2 context dictionary\n    :param filter: custom Jinja2 filters\n    :returns: list of rendered strings\n    \"\"\"\n    rendered = []\n    filters = filters or {}\n    for template in templates:\n        if template.startswith(\"nf://\"):\n            filepath = self.fetch_jinja2(template)\n            searchpath, filename = os.path.split(filepath)\n            j2env = Environment(loader=FileSystemLoader(searchpath))\n            j2env.filters.update(filters)  # add custom filters\n            renderer = j2env.get_template(filename)\n        else:\n            j2env = Environment(loader=\"BaseLoader\")\n            j2env.filters.update(filters)  # add custom filters\n            renderer = j2env.from_string(template)\n        rendered.append(renderer.render(**context))\n\n    return \"\\n\".join(rendered)\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.load_job_data","title":"<code>load_job_data(job_data)</code>","text":"<p>Helper function to download job data and load it using YAML</p> <p>Parameters:</p> Name Type Description Default <code>job_data</code> <code>str</code> <p>URL to job data</p> required Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def load_job_data(self, job_data: str):\n    \"\"\"\n    Helper function to download job data and load it using YAML\n\n    :param job_data: URL to job data\n    \"\"\"\n    if self.is_url(job_data):\n        job_data = self.fetch_file(job_data)\n        if job_data is None:\n            msg = f\"{self.name} - '{job_data}' job data file download failed\"\n            raise FileNotFoundError(msg)\n        job_data = yaml.safe_load(job_data)\n\n    return job_data\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.get_nornir_hosts","title":"<code>get_nornir_hosts(details=False, **kwargs)</code>","text":"<p>Produce a list of hosts managed by this worker</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>dictionary of nornir-salt Fx filters</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def get_nornir_hosts(self, details: bool = False, **kwargs: dict) -&gt; list:\n    \"\"\"\n    Produce a list of hosts managed by this worker\n\n    :param kwargs: dictionary of nornir-salt Fx filters\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    filtered_nornir = FFun(self.nr, **filters)\n    if details:\n        return Result(\n            result={\n                host_name: {\n                    \"platform\": str(host.platform),\n                    \"hostname\": str(host.hostname),\n                    \"port\": str(host.port),\n                    \"groups\": [str(g) for g in host.groups],\n                    \"username\": str(host.username),\n                }\n                for host_name, host in filtered_nornir.inventory.hosts.items()\n            }\n        )\n    else:\n        return Result(result=list(filtered_nornir.inventory.hosts))\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.get_nornir_inventory","title":"<code>get_nornir_inventory(**kwargs)</code>","text":"<p>Retrieve running Nornir inventory for requested hosts</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>dictionary of nornir-salt Fx filters</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def get_nornir_inventory(self, **kwargs: dict) -&gt; dict:\n    \"\"\"\n    Retrieve running Nornir inventory for requested hosts\n\n    :param kwargs: dictionary of nornir-salt Fx filters\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    filtered_nornir = FFun(self.nr, **filters)\n    return Result(\n        result=filtered_nornir.inventory.dict(), task=\"get_nornir_inventory\"\n    )\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.get_nornir_version","title":"<code>get_nornir_version()</code>","text":"<p>Produce Python packages version report</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def get_nornir_version(self):\n    \"\"\"\n    Produce Python packages version report\n    \"\"\"\n    libs = {\n        \"scrapli\": \"\",\n        \"scrapli-netconf\": \"\",\n        \"scrapli-community\": \"\",\n        \"paramiko\": \"\",\n        \"netmiko\": \"\",\n        \"napalm\": \"\",\n        \"nornir\": \"\",\n        \"ncclient\": \"\",\n        \"nornir-netmiko\": \"\",\n        \"nornir-napalm\": \"\",\n        \"nornir-scrapli\": \"\",\n        \"nornir-utils\": \"\",\n        \"tabulate\": \"\",\n        \"xmltodict\": \"\",\n        \"puresnmp\": \"\",\n        \"pygnmi\": \"\",\n        \"pyyaml\": \"\",\n        \"jmespath\": \"\",\n        \"jinja2\": \"\",\n        \"ttp\": \"\",\n        \"nornir-salt\": \"\",\n        \"lxml\": \"\",\n        \"ttp-templates\": \"\",\n        \"ntc-templates\": \"\",\n        \"cerberus\": \"\",\n        \"pydantic\": \"\",\n        \"requests\": \"\",\n        \"textfsm\": \"\",\n        \"N2G\": \"\",\n        \"dnspython\": \"\",\n        \"pythonping\": \"\",\n        \"python\": sys.version.split(\" \")[0],\n        \"platform\": sys.platform,\n    }\n    # get version of packages installed\n    for pkg in libs.keys():\n        try:\n            libs[pkg] = importlib.metadata.version(pkg)\n        except importlib.metadata.PackageNotFoundError:\n            pass\n\n    return Result(result=libs)\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.task","title":"<code>task(plugin, **kwargs)</code>","text":"<p>Task to invoke any of supported Nornir task plugins. This function performs dynamic import of requested plugin function and executes <code>nr.run</code> using supplied args and kwargs</p> <p><code>plugin</code> attribute can refer to a file to fetch from file service. File must contain function named <code>task</code> accepting Nornir task object as a first positional argument, for example:</p> <pre><code># define connection name for RetryRunner to properly detect it\nCONNECTION_NAME = \"netmiko\"\n\n# create task function\ndef task(nornir_task_object, **kwargs):\n    pass\n</code></pre> <p>CONNECTION_NAME</p> <p><code>CONNECTION_NAME</code> must be defined within custom task function file if RetryRunner in use, otherwise connection retry logic skipped and connections to all hosts initiated simultaneously up to the number of <code>num_workers</code>.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>(str) <code>path.to.plugin.task_fun</code> to import or <code>nf://path/to/task.py</code> to download custom task</p> required <code>kwargs</code> <p>(dict) arguments to use with specified task plugin</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def task(self, plugin: str, **kwargs) -&gt; Result:\n    \"\"\"\n    Task to invoke any of supported Nornir task plugins. This function\n    performs dynamic import of requested plugin function and executes\n    ``nr.run`` using supplied args and kwargs\n\n    ``plugin`` attribute can refer to a file to fetch from file service. File must contain\n    function named ``task`` accepting Nornir task object as a first positional\n    argument, for example:\n\n    ```python\n    # define connection name for RetryRunner to properly detect it\n    CONNECTION_NAME = \"netmiko\"\n\n    # create task function\n    def task(nornir_task_object, **kwargs):\n        pass\n    ```\n\n    !!! note \"CONNECTION_NAME\"\n\n        ``CONNECTION_NAME`` must be defined within custom task function file if\n        RetryRunner in use, otherwise connection retry logic skipped and connections\n        to all hosts initiated simultaneously up to the number of ``num_workers``.\n\n    :param plugin: (str) ``path.to.plugin.task_fun`` to import or ``nf://path/to/task.py``\n        to download custom task\n    :param kwargs: (dict) arguments to use with specified task plugin\n    \"\"\"\n    # extract attributes\n    add_details = kwargs.pop(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.pop(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:task\", result={} if to_dict else [])\n\n    # download task from broker and load it\n    if plugin.startswith(\"nf://\"):\n        function_text = self.fetch_file(plugin)\n        if function_text is None:\n            raise FileNotFoundError(\n                f\"{self.name} - '{plugin}' task plugin download failed\"\n            )\n\n        # load task function running exec\n        globals_dict = {}\n        exec(function_text, globals_dict, globals_dict)\n        task_function = globals_dict[\"task\"]\n    # import task function\n    else:\n        # below same as \"from nornir.plugins.tasks import task_fun as task_function\"\n        task_fun = plugin.split(\".\")[-1]\n        module = __import__(plugin, fromlist=[\"\"])\n        task_function = getattr(module, task_fun)\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(f\"{self.name} - running Nornir task '{plugin}', kwargs '{kwargs}'\")\n    with self.connections_lock:\n        result = nr.run(task=task_function, **kwargs)\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.cli","title":"<code>cli(commands=None, plugin='netmiko', cli_dry_run=False, run_ttp=None, job_data=None, to_dict=True, add_details=False, **kwargs)</code>","text":"<p>Task to collect show commands output from devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>commands</code> <code>list</code> <p>list of commands to send to devices</p> <code>None</code> <code>plugin</code> <code>str</code> <p>plugin name to use - valid options are <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cli_dry_run</code> <code>bool</code> <p>do not send commands to devices just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>run_ttp</code> <code>str</code> <p>TTP Template to run</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cli(\n    self,\n    commands: list = None,\n    plugin: str = \"netmiko\",\n    cli_dry_run: bool = False,\n    run_ttp: str = None,\n    job_data: str = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to collect show commands output from devices using\n    Command Line Interface (CLI)\n\n    :param commands: list of commands to send to devices\n    :param plugin: plugin name to use - valid options are ``netmiko``, ``scrapli``, ``napalm``\n    :param cli_dry_run: do not send commands to devices just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param run_ttp: TTP Template to run\n    \"\"\"\n    job_data = job_data or {}\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    downloaded_cmds = []\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:cli\", result={} if to_dict else [])\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_commands\n        if kwargs.get(\"use_ps\"):\n            kwargs.setdefault(\"timeout\", timeout)\n        else:\n            kwargs.setdefault(\"read_timeout\", timeout)\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_commands\n        kwargs.setdefault(\"timeout_ops\", timeout)\n    elif plugin == \"napalm\":\n        task_plugin = napalm_send_commands\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    # download TTP template\n    if self.is_url(run_ttp):\n        downloaded = self.fetch_file(run_ttp)\n        kwargs[\"run_ttp\"] = downloaded\n        if downloaded is None:\n            msg = f\"{self.name} - TTP template download failed '{run_ttp}'\"\n            raise FileNotFoundError(msg)\n    # use TTP template as is - inline template or ttp://xyz path\n    elif run_ttp:\n        kwargs[\"run_ttp\"] = run_ttp\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render commands using Jinja2 on a per-host basis\n    if commands:\n        commands = commands if isinstance(commands, list) else [commands]\n        for host in nr.inventory.hosts.values():\n            rendered = self.render_jinja2_templates(\n                templates=commands,\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n            host.data[\"__task__\"] = {\"commands\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - running cli commands '{commands}', kwargs '{kwargs}', is cli dry run - '{cli_dry_run}'\"\n    )\n    if cli_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"commands\", name=\"cli_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.nb_get_next_ip","title":"<code>nb_get_next_ip(*args, **kwargs)</code>","text":"<p>Task to query next available IP address from Netbox service</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def nb_get_next_ip(self, *args, **kwargs):\n    \"\"\"Task to query next available IP address from Netbox service\"\"\"\n    reply = self.client.run_job(\n        \"netbox\",\n        \"get_next_ip\",\n        args=args,\n        kwargs=kwargs,\n        workers=\"any\",\n        timeout=30,\n    )\n    # reply is a dict of {worker_name: results_dict}\n    result = list(reply.values())[0]\n\n    return result[\"result\"]\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.cfg","title":"<code>cfg(config, plugin='netmiko', cfg_dry_run=False, to_dict=True, add_details=False, job_data=None, **kwargs)</code>","text":"<p>Task to send configuration commands to devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>list</code> <p>list of commands to send to devices</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cfg_dry_run</code> <code>bool</code> <p>if True, will not send commands to devices but just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>kwargs</code> <p>additional arguments to pass to the task plugin</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the configuration task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cfg(\n    self,\n    config: list,\n    plugin: str = \"netmiko\",\n    cfg_dry_run: bool = False,\n    to_dict: bool = True,\n    add_details: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to send configuration commands to devices using\n    Command Line Interface (CLI)\n\n    :param config: list of commands to send to devices\n    :param plugin: plugin name to use - ``netmiko``, ``scrapli``, ``napalm``\n    :param cfg_dry_run: if True, will not send commands to devices but just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param kwargs: additional arguments to pass to the task plugin\n    :return: dictionary with the results of the configuration task\n    \"\"\"\n    downloaded_cfg = []\n    config = config if isinstance(config, list) else [config]\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:cfg\", result={} if to_dict else [])\n    timeout = self.current_job[\"timeout\"]\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_config\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_config\n    elif plugin == \"napalm\":\n        task_plugin = napalm_configure\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render config using Jinja2 on a per-host basis\n    for host in nr.inventory.hosts.values():\n        rendered = self.render_jinja2_templates(\n            templates=config,\n            context={\n                \"host\": host,\n                \"norfab\": self.client,\n                \"nornir\": self,\n                \"job_data\": job_data,\n            },\n            filters=self.add_jinja2_filters(),\n        )\n        host.data[\"__task__\"] = {\"config\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - sending config commands '{config}', kwargs '{kwargs}', is cfg_dry_run - '{cfg_dry_run}'\"\n    )\n    if cfg_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"config\", name=\"cfg_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n        ret.changed = True\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.test","title":"<code>test(suite, subset=None, dry_run=False, remove_tasks=True, failed_only=False, return_tests_suite=False, job_data=None, **kwargs)</code>","text":"<p>Function to tests data obtained from devices.</p> <p>Parameters:</p> Name Type Description Default <code>suite</code> <code>Union[list, str]</code> <p>path to YAML file with tests</p> required <code>dry_run</code> <code>bool</code> <p>if True, returns produced per-host tests suite content only</p> <code>False</code> <code>subset</code> <code>str</code> <p>list or string with comma separated non case sensitive glob patterns to filter tests' by name, subset argument ignored by dry run</p> <code>None</code> <code>failed_only</code> <code>bool</code> <p>if True returns test results for failed tests only</p> <code>False</code> <code>remove_tasks</code> <code>bool</code> <p>if False results will include other tasks output</p> <code>True</code> <code>return_tests_suite</code> <code>bool</code> <p>if True returns rendered per-host tests suite content in addition to test results using dictionary with <code>results</code> and <code>suite</code> keys</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>kwargs</code> <p>any additional arguments to pass on to Nornir service task</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def test(\n    self,\n    suite: Union[list, str],\n    subset: str = None,\n    dry_run: bool = False,\n    remove_tasks: bool = True,\n    failed_only: bool = False,\n    return_tests_suite: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to tests data obtained from devices.\n\n    :param suite: path to YAML file with tests\n    :param dry_run: if True, returns produced per-host tests suite content only\n    :param subset: list or string with comma separated non case sensitive glob\n        patterns to filter tests' by name, subset argument ignored by dry run\n    :param failed_only: if True returns test results for failed tests only\n    :param remove_tasks: if False results will include other tasks output\n    :param return_tests_suite: if True returns rendered per-host tests suite\n        content in addition to test results using dictionary with ``results``\n        and ``suite`` keys\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param kwargs: any additional arguments to pass on to Nornir service task\n    \"\"\"\n    tests = {}  # dictionary to hold per-host test suites\n    add_details = kwargs.get(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.get(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:test\", result={} if to_dict else [])\n    suites = {}  # dictionary to hold combined test suites\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        if return_tests_suite is True:\n            ret.result = {\"test_results\": [], \"suite\": {}}\n        return ret\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    # generate per-host test suites\n    for host_name, host in filtered_nornir.inventory.hosts.items():\n        # render suite using Jinja2\n        try:\n            rendered_suite = self.render_jinja2_templates(\n                templates=[suite],\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' Jinja2 rendering failed: '{e}'\"\n            raise RuntimeError(msg)\n        # load suit using YAML\n        try:\n            tests[host_name] = yaml.safe_load(rendered_suite)\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' YAML load failed: '{e}'\"\n            raise RuntimeError(msg)\n\n    # validate tests suite\n    try:\n        _ = modelTestsProcessorSuite(tests=tests)\n    except Exception as e:\n        msg = f\"{self.name} - '{suite}' suite validation failed: '{e}'\"\n        raise RuntimeError(msg)\n\n    # download pattern, schema and custom function files\n    for host_name in tests.keys():\n        for index, item in enumerate(tests[host_name]):\n            for k in [\"pattern\", \"schema\", \"function_file\"]:\n                if self.is_url(item.get(k)):\n                    item[k] = self.fetch_file(\n                        item[k], raise_on_fail=True, read=True\n                    )\n                    if k == \"function_file\":\n                        item[\"function_text\"] = item.pop(k)\n            tests[host_name][index] = item\n\n    # save per-host tests suite content before mutating it\n    if return_tests_suite is True:\n        return_suite = copy.deepcopy(tests)\n\n    log.debug(f\"{self.name} - running test '{suite}', is dry run - '{dry_run}'\")\n    # run dry run task\n    if dry_run is True:\n        result = filtered_nornir.run(\n            task=nr_test, name=\"tests_dry_run\", ret_data_per_host=tests\n        )\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    # combine per-host tests in suites based on task and arguments\n    # Why - to run tests using any nornir service tasks with various arguments\n    else:\n        for host_name, host_tests in tests.items():\n            for test in host_tests:\n                dhash = hashlib.md5()\n                test_args = test.pop(\"norfab\", {})\n                nrtask = test_args.get(\"nrtask\", \"cli\")\n                assert nrtask in [\n                    \"cli\",\n                    \"network\",\n                    \"cfg\",\n                    \"task\",\n                ], f\"{self.name} - unsupported NorFab Nornir Service task '{nrtask}'\"\n                test_json = json.dumps(test_args, sort_keys=True).encode()\n                dhash.update(test_json)\n                test_hash = dhash.hexdigest()\n                suites.setdefault(test_hash, {\"params\": test_args, \"tests\": {}})\n                suites[test_hash][\"tests\"].setdefault(host_name, [])\n                suites[test_hash][\"tests\"][host_name].append(test)\n        log.debug(\n            f\"{self.name} - combined per-host tests suites based on NorFab Nornir Service task and arguments:\\n{suites}\"\n        )\n        # run test suites collecting output from devices\n        for tests_suite in suites.values():\n            nrtask = tests_suite[\"params\"].pop(\"nrtask\", \"cli\")\n            function_kwargs = {\n                **tests_suite[\"params\"],\n                **kwargs,\n                **filters,\n                \"tests\": tests_suite[\"tests\"],\n                \"remove_tasks\": remove_tasks,\n                \"failed_only\": failed_only,\n                \"subset\": subset,\n            }\n            result = getattr(self, nrtask)(\n                **function_kwargs\n            )  # returns Result object\n            # save test results into overall results\n            if to_dict == True:\n                for host_name, host_res in result.result.items():\n                    ret.result.setdefault(host_name, {})\n                    ret.result[host_name].update(host_res)\n            else:\n                ret.result.extend(result.result)\n\n    # check if need to return tests suite content\n    if return_tests_suite is True:\n        ret.result = {\"test_results\": ret.result, \"suite\": return_suite}\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.network","title":"<code>network(fun, **kwargs)</code>","text":"<p>Task to call various network related utility functions.</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <p>(str) utility function name to call</p> required <code>kwargs</code> <p>(dict) function arguments  Available utility functions.  resolve_dns function  resolves hosts' hostname DNS returning IP addresses using <code>nornir_salt.plugins.tasks.network.resolve_dns</code> Nornir-Salt function.  ping function  Function to execute ICMP ping to host using <code>nornir_salt.plugins.tasks.network.ping</code> Nornir-Salt function.</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def network(self, fun, **kwargs) -&gt; dict:\n    \"\"\"\n    Task to call various network related utility functions.\n\n    :param fun: (str) utility function name to call\n    :param kwargs: (dict) function arguments\n\n    Available utility functions.\n\n    **resolve_dns** function\n\n    resolves hosts' hostname DNS returning IP addresses using\n    ``nornir_salt.plugins.tasks.network.resolve_dns`` Nornir-Salt\n    function.\n\n    **ping** function\n\n    Function to execute ICMP ping to host using\n    ``nornir_salt.plugins.tasks.network.ping`` Nornir-Salt\n    function.\n    \"\"\"\n    kwargs[\"call\"] = fun\n    return self.task(\n        plugin=\"nornir_salt.plugins.tasks.network\",\n        **kwargs,\n    )\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.parse","title":"<code>parse(plugin='napalm', getters='get_facts', template=None, commands=None, to_dict=True, add_details=False, **kwargs)</code>","text":"<p>Function to parse network devices show commands output</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>plugin name to use - <code>napalm</code>, <code>textfsm</code>, <code>ttp</code></p> <code>'napalm'</code> <code>getters</code> <code>str</code> <p>NAPALM getters to use</p> <code>'get_facts'</code> <code>commands</code> <code>list</code> <p>commands to send to devices for TextFSM or TTP template</p> <code>None</code> <code>template</code> <code>str</code> <p>TextFSM or TTP parsing template string or path to file  For NAPALM plugin <code>method</code> can refer to a list of getters names.</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def parse(\n    self,\n    plugin: str = \"napalm\",\n    getters: str = \"get_facts\",\n    template: str = None,\n    commands: list = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Function to parse network devices show commands output\n\n    :param plugin: plugin name to use - ``napalm``, ``textfsm``, ``ttp``\n    :param getters: NAPALM getters to use\n    :param commands: commands to send to devices for TextFSM or TTP template\n    :param template: TextFSM or TTP parsing template string or path to file\n\n    For NAPALM plugin ``method`` can refer to a list of getters names.\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:parse\", result={} if to_dict else [])\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    if plugin == \"napalm\":\n        nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n        result = nr.run(task=napalm_get, getters=getters, **kwargs)\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    elif plugin == \"ttp\":\n        result = self.cli(\n            commands=commands or [],\n            run_ttp=template,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    elif plugin == \"textfsm\":\n        result = self.cli(\n            commands=commands,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            use_textfsm=True,\n            textfsm_template=template,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.file_copy","title":"<code>file_copy(source_file, plugin='netmiko', to_dict=True, add_details=False, dry_run=False, **kwargs)</code>","text":"<p>Task to transfer files to and from hosts using SCP</p> <p>Parameters:</p> Name Type Description Default <code>source_file</code> <code>str</code> <p>path to file to copy, support <code>nf://path/to/file</code> URL to copy from broker</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code></p> <code>'netmiko'</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False produces list</p> <code>True</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>if True will not copy files just return what would be copied</p> <code>False</code> <code>kwargs</code> <p>additional arguments to pass to the plugin function</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the file copy task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def file_copy(\n    self,\n    source_file: str,\n    plugin: str = \"netmiko\",\n    to_dict: bool = True,\n    add_details: bool = False,\n    dry_run: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to transfer files to and from hosts using SCP\n\n    :param source_file: path to file to copy, support ``nf://path/to/file`` URL to copy from broker\n    :param plugin: plugin name to use - ``netmiko``\n    :param to_dict: default is True - produces dictionary results, if False produces list\n    :param add_details: if True will add task execution details to the results\n    :param dry_run: if True will not copy files just return what would be copied\n    :param kwargs: additional arguments to pass to the plugin function\n    :return: dictionary with the results of the file copy task\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:file_copy\", result={} if to_dict else [])\n\n    # download file from broker\n    if self.is_url(source_file):\n        source_file_local = self.fetch_file(\n            source_file, raise_on_fail=True, read=False\n        )\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_file_transfer\n        kwargs[\"source_file\"] = source_file_local\n        kwargs.setdefault(\"socket_timeout\", timeout / 5)\n        kwargs.setdefault(\"dest_file\", os.path.split(source_file_local)[-1])\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(\n        f\"{self.name} - running file copy with arguments '{kwargs}', is dry run - '{dry_run}'\"\n    )\n    if dry_run is True:\n        result = nr.run(task=nr_test, name=\"file_copy_dry_run\", **kwargs)\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/services_nornir_service/","title":"Nornir Service","text":"<p>Nornir Service is built using Nornir library - a well adopted open-source tool for automating network devices operations.</p> <p> </p> <p>With each Nornir worker capable of handling multiple devices simultaneously,  Nornir Service offers high scalability, allowing efficient management of  large device fleets. By optimizing compute resources such as CPU, RAM, and  storage, it delivers cost-effective performance.</p> <p>Additionally, Nornir Service supports various interfaces and libraries for  seamless integration. For instance, the <code>cli</code> task can interact with devices  via the SSH Command Line Interface (CLI) using popular libraries like Netmiko,  Scrapli or NAPALM, providing flexibility for diverse network environments.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_jinja2_filters/","title":"Nornir Service Jinja2 Templates Filters","text":"<p>Below listed additional Jinja2 filters that supported by Nornir service for templates rendering by all service tasks such as <code>cfg</code>, <code>cli</code>, <code>tests</code> etc.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_jinja2_filters/#network_hosts","title":"network_hosts","text":"<p>Returns a list of hosts for given network.</p> <p>Arguments:</p> <ul> <li><code>pfxlen</code> - boolean, default is True, if False skips prefix length for IP addresses </li> </ul> <p>Example:</p> <pre><code>{{ '192.168.1.0/30' | network_hosts }}\n\n{{ '192.168.2.0/30' | network_hosts(pfxlen=False) }}\n</code></pre> <p>Returns:</p> <pre><code>[\"192.168.1.1/30\", \"192.168.1.2/30\"]\n\n[\"192.168.2.1\", \"192.168.2.2\"]\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/","title":"Nornir Service CFG Task","text":"<p>Nornir service <code>cfg</code> task designed to send configuration to devices using SSH and Telnet. Nornir <code>cfg</code> can use Netmiko, Scrapli and NAPALM libraries to configure with devices.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#nornir-cfg-sample-usage","title":"Nornir CFG Sample Usage","text":"<p>Example of sending configuration commands to devices.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>Above runs \"show clock\" and \"show hostname\" commands on all Nornir hosts that contain <code>ceos-spine</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter.</p> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"cfg\",\n        kwargs={\n            \"config\": [\"ntp server 10.0.0.1\", \"ntp server 10.0.0.2\"],\n            \"FC\": \"ceos-spine\"              \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_cli.py\n{'nornir-worker-1': {'errors': [],\n                     'failed': False,\n                     'messages': [],\n                     'result': {'ceos-spine-1': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local',\n                                                 'show hostname': 'Hostname: '\n                                                                  'ceos-spine-1\\n'\n                                                                  'FQDN:     '\n                                                                  'ceos-spine-1'},\n                                'ceos-spine-2': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local',\n                                                 'show hostname': 'Hostname: '\n                                                                  'ceos-spine-2\\n'\n                                                                  'FQDN:     '\n                                                                  'ceos-spine-2'}},\n                     'task': 'nornir-worker-1:cli'}}\nC:\\nf&gt;                   \n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#use-different-configuration-plugins","title":"Use Different Configuration Plugins","text":"<p>NorFab supports various configuration plugins such as <code>netmiko</code>, <code>napalm</code> and <code>scrapli</code>. These plugins enable you to push configurations to a wide range of network devices. Each plugin has its own set of capabilities and requirements, so it is essential to ensure that your Nornir inventory is properly configured for the chosen plugin. This includes specifying the necessary connection parameters and device-specific settings. By leveraging these plugins, you can standardize and automate the configuration management process across different network environments.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-dry-run","title":"Using Dry Run","text":"<p>The dry run feature in NorFab allows you to simulate the application of configurations without actually pushing them to the devices. This is particularly useful for testing and validation purposes, as it enables you to verify the correctness of your configurations before making any changes to the network. Additionally, the dry run feature can be used for generating and rendering device configurations, which is beneficial for staging environments where you need to prepare configurations in advance. By using dry run, you can ensure that your configurations are accurate and ready for deployment.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-commit-confirmed","title":"Using Commit Confirmed","text":"<p>The commit confirmed feature provides an added layer of safety when pushing configurations to network devices. With this feature, you can apply a configuration with a rollback timer. If the configuration is not explicitly confirmed within the specified time, it will be automatically rolled back to the previous state. This is particularly useful in scenarios where you need to ensure that a configuration change does not negatively impact the network. By using commit confirmed, you can mitigate the risk of configuration errors and ensure network stability.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#sourcing-configuration-from-files","title":"Sourcing Configuration From Files","text":"<p>NorFab allows you to source configurations from text files stored on the broker. This approach enables you to manage configurations as files, making it easier to version control and maintain them. By storing configurations in files, you can apply them as needed, ensuring consistency and repeatability in your configuration management process. This method is particularly useful for large-scale deployments where configurations need to be applied to multiple devices in a controlled and organized manner.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-jinja2-templates","title":"Using Jinja2 Templates","text":"<p>Jinja2 templates provide a powerful way to create dynamic configurations based on variables defined in your inventory or passed as job data. By using templates, you can generate configurations that are tailored to the specific requirements of each device. This approach allows you to automate the creation of complex configurations and ensures consistency across your network. Jinja2 templates are highly flexible and can be used to incorporate conditional logic, loops, and other advanced features, making them an essential tool for network automation.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#templating-configuration-with-inline-job-data","title":"Templating Configuration with Inline Job Data","text":"","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#parsing-and-generating-configuration-in-templates","title":"Parsing and Generating Configuration in Templates","text":"<p>NorFab supports parsing of device output and the generation of new configurations within same template using parsing results. This capability allows you to create configurations based on the current state of the device, ensuring that your changes are applied accurately and efficiently. By parsing existing configurations, you can extract relevant information and use it to generate new configurations that are consistent with the device's current setup. </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#outputting-text-tables","title":"Outputting Text Tables","text":"<p>The NorFab interactive shell supports the table command, which can be used to format output into text tables. This feature relies on the tabulate module and supports most of its functionalities. By outputting results in table format, you can easily visualize and analyze the data, making it easier to interpret and act upon. This is particularly useful for displaying configuration results in a structured, concise and readable manner.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#formatting-output-results","title":"Formatting Output Results","text":"<p>You can format the output results using various options provided by the Nornir worker. The output of the commands can be formatted using the <code>to_dict</code> parameter. When set to <code>True</code>, the results will be returned as a dictionary. When set to <code>False</code>, the results will be returned as a list. In addition <code>add_details</code> argument can be used to control the verbosity of the output and return additional Nornir result information such as:</p> <ul> <li><code>changed</code> flag</li> <li><code>diff</code> content if supported by plugin</li> <li><code>failed</code> status</li> <li><code>exception</code> details if task execution failed with error</li> <li><code>connection_retry</code> counter to show how many times RetryRunner tried to establish a connection</li> <li><code>task_retry</code> counter to show how many times RetryRunner tried to run this task</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-promptless-mode","title":"Using Promptless Mode","text":"<p>NorFab supports a proprietary promptless mode that can be used with Netmiko. This mode is particularly useful when dealing with devices that do not have a consistent prompt or when the default Netmiko output collection functions are not reliable enough. By enabling promptless mode, you can ensure that configurations are applied accurately and efficiently, even in challenging environments. This feature enhances the robustness of your configuration management process and ensures that your network devices are configured correctly.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#norfab-nornir-cfg-shell-reference","title":"NORFAB Nornir CFG Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>cfg</code> task:</p> <pre><code>nf#man tree nornir.cfg\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 cfg:    Configure devices over CLI interface\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 cfg_dry_run:    Dry run cfg function\n        \u251c\u2500\u2500 *config:    List of configuration commands to send to devices, default 'PydanticUndefined'\n        \u251c\u2500\u2500 plugin:    Configuration plugin parameters\n        \u2502   \u251c\u2500\u2500 netmiko:    Use Netmiko plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 enable:    Attempt to enter enable-mode\n        \u2502   \u2502   \u251c\u2500\u2500 exit_config_mode:    Determines whether or not to exit config mode after complete\n        \u2502   \u2502   \u251c\u2500\u2500 strip_prompt:    Determines whether or not to strip the prompt\n        \u2502   \u2502   \u251c\u2500\u2500 strip_command:    Determines whether or not to strip the command\n        \u2502   \u2502   \u251c\u2500\u2500 read_timeout:    Absolute timer to send to read_channel_timing\n        \u2502   \u2502   \u251c\u2500\u2500 config_mode_command:    The command to enter into config mode\n        \u2502   \u2502   \u251c\u2500\u2500 cmd_verify:    Whether or not to verify command echo for each command in config_set\n        \u2502   \u2502   \u251c\u2500\u2500 enter_config_mode:    Do you enter config mode before sending config commands\n        \u2502   \u2502   \u251c\u2500\u2500 error_pattern:    Regular expression pattern to detect config errors in the output\n        \u2502   \u2502   \u251c\u2500\u2500 terminator:    Regular expression pattern to use as an alternate terminator\n        \u2502   \u2502   \u251c\u2500\u2500 bypass_commands:    Regular expression pattern indicating configuration commands, cmd_verify is automatically disabled\n        \u2502   \u2502   \u251c\u2500\u2500 commit:    Commit configuration or not or dictionary with commit parameters\n        \u2502   \u2502   \u251c\u2500\u2500 commit_final_delay:    Time to wait before doing final commit\n        \u2502   \u251c\u2500\u2500 scrapli:    Use Scrapli plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 dry_run:    Apply changes or not, also tests if possible to enter config mode\n        \u2502   \u2502   \u251c\u2500\u2500 strip_prompt:    Strip prompt from returned output\n        \u2502   \u2502   \u251c\u2500\u2500 failed_when_contains:    String or list of strings indicating failure if found in response\n        \u2502   \u2502   \u251c\u2500\u2500 stop_on_failed:    Stop executing commands if command fails\n        \u2502   \u2502   \u251c\u2500\u2500 privilege_level:    Name of configuration privilege level to acquire\n        \u2502   \u2502   \u251c\u2500\u2500 eager:    Do not read until prompt is seen at each command sent to the channel\n        \u2502   \u2502   \u2514\u2500\u2500 timeout_ops:    Timeout ops value for this operation\n        \u2502   \u2514\u2500\u2500 napalm:    Use NAPALM plugin to configure devices\n        \u2502       \u251c\u2500\u2500 replace:    Whether to replace or merge the configuration\n        \u2502       \u251c\u2500\u2500 dry_run:    Apply changes or not, also tests if possible to enter config mode\n        \u2502       \u2514\u2500\u2500 revert_in:    Amount of time in seconds after which to revert the commit\n        \u2514\u2500\u2500 job_data:    Path to YAML file with job data\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#python-api-reference","title":"Python API Reference","text":"<p>Task to send configuration commands to devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>list</code> <p>list of commands to send to devices</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cfg_dry_run</code> <code>bool</code> <p>if True, will not send commands to devices but just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>kwargs</code> <p>additional arguments to pass to the task plugin</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the configuration task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cfg(\n    self,\n    config: list,\n    plugin: str = \"netmiko\",\n    cfg_dry_run: bool = False,\n    to_dict: bool = True,\n    add_details: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to send configuration commands to devices using\n    Command Line Interface (CLI)\n\n    :param config: list of commands to send to devices\n    :param plugin: plugin name to use - ``netmiko``, ``scrapli``, ``napalm``\n    :param cfg_dry_run: if True, will not send commands to devices but just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param kwargs: additional arguments to pass to the task plugin\n    :return: dictionary with the results of the configuration task\n    \"\"\"\n    downloaded_cfg = []\n    config = config if isinstance(config, list) else [config]\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:cfg\", result={} if to_dict else [])\n    timeout = self.current_job[\"timeout\"]\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_config\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_config\n    elif plugin == \"napalm\":\n        task_plugin = napalm_configure\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render config using Jinja2 on a per-host basis\n    for host in nr.inventory.hosts.values():\n        rendered = self.render_jinja2_templates(\n            templates=config,\n            context={\n                \"host\": host,\n                \"norfab\": self.client,\n                \"nornir\": self,\n                \"job_data\": job_data,\n            },\n            filters=self.add_jinja2_filters(),\n        )\n        host.data[\"__task__\"] = {\"config\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - sending config commands '{config}', kwargs '{kwargs}', is cfg_dry_run - '{cfg_dry_run}'\"\n    )\n    if cfg_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"config\", name=\"cfg_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n        ret.changed = True\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/","title":"Nornir Service CLI Task","text":"<p>Nornir service <code>cli</code> task designed to retrieve show commands output  from devices using SSH and Telnet. Nornir <code>cli</code> uses Netmiko, Scrapli  and NAPALM libraries to communicate with devices.</p> <ul> <li>Netmiko: A multi-vendor library that simplifies SSH connections to network devices.</li> <li>Scrapli: A fast and flexible library for interacting with network devices.</li> <li>NAPALM: A library that provides a unified API to interact with different network device operating systems.</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#nornir-cli-sample-usage","title":"Nornir CLI Sample Usage","text":"<p>Below is an example of how to use the Nornir CLI task to retrieve command outputs from devices.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir]#cli\nnf[nornir-cli]#\nnf[nornir-cli]#commands \"show clock\" \"show hostname\" FC ceos-spine\nceos-spine-1:\n    show clock:\n        Sun Dec  1 10:49:58 2024\n        Timezone: UTC\n        Clock source: local\n    show hostname:\n        Hostname: ceos-spine-1\n        FQDN:     ceos-spine-1\nceos-spine-2:\n    show clock:\n        Sun Dec  1 10:49:58 2024\n        Timezone: UTC\n        Clock source: local\n    show hostname:\n        Hostname: ceos-spine-2\n        FQDN:     ceos-spine-2\nnf[nornir-cli]#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nfcli</code> command starts the NorFab Interactive Shell.</li> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>cli</code> command switches to the CLI task sub-shell.</li> <li><code>commands</code> command retrieves the output of \"show clock\" and \"show hostname\" from the devices  that contain <code>ceos-spine</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter.</li> </ul> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"cli\",\n        kwargs={\n            \"commands\": [\"show clock\", \"show hostname\"],\n            \"FC\": \"ceos-spine\"              \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_cli.py\n{'nornir-worker-1': {'errors': [],\n                     'failed': False,\n                     'messages': [],\n                     'result': {'ceos-spine-1': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local',\n                                                 'show hostname': 'Hostname: '\n                                                                  'ceos-spine-1\\n'\n                                                                  'FQDN:     '\n                                                                  'ceos-spine-1'},\n                                'ceos-spine-2': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local',\n                                                 'show hostname': 'Hostname: '\n                                                                  'ceos-spine-2\\n'\n                                                                  'FQDN:     '\n                                                                  'ceos-spine-2'}},\n                     'task': 'nornir-worker-1:cli'}}\nC:\\nf&gt;                   \n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#use-different-connection-plugins","title":"Use Different Connection Plugins","text":"<p>The Nornir Service CLI Task supports various connection plugins, such as <code>netmiko</code>, <code>napalm</code>, and <code>scrapli</code>, to interact with network devices. These plugins provide the flexibility to choose the most suitable method for connecting to and managing your devices, depending on your specific requirements and preferences.</p> <p>To use a specific connection plugin, ensure that your Nornir inventory is properly configured with the necessary connection parameters and device-specific settings. This includes specifying the plugin type, authentication details, and any additional options required by the plugin.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir cli\nnf[nornir-cli]#commands \"show clock\" FC spine plugin netmiko\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:37:57 5ed5775b183a404181f004753f583f0c job started\n04-Jan-2025 22:37:57.085 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.114 nornir nornir-worker-1 ceos-spine-1 task_instance started - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.114 nornir nornir-worker-1 ceos-spine-2 task_instance started - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.124 nornir nornir-worker-1 ceos-spine-1 subtask started - 'show clock'\n04-Jan-2025 22:37:57.136 nornir nornir-worker-1 ceos-spine-2 subtask started - 'show clock'\n04-Jan-2025 22:37:57.237 nornir nornir-worker-1 ceos-spine-1 subtask completed - 'show clock'\n04-Jan-2025 22:37:57.237 nornir nornir-worker-1 ceos-spine-2 subtask completed - 'show clock'\n04-Jan-2025 22:37:57.244 nornir nornir-worker-1 ceos-spine-2 task_instance completed - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.245 nornir nornir-worker-1 ceos-spine-1 task_instance completed - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.425 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task completed - 'netmiko_send_commands'\n04-Jan-2025 22:37:57 5ed5775b183a404181f004753f583f0c job completed in 0.476 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\nceos-spine-1:\n    show clock:\n        Sat Jan  4 12:37:57 2025\n        Timezone: UTC\n        Clock source: local\nceos-spine-2:\n    show clock:\n        Sat Jan  4 12:37:57 2025\n        Timezone: UTC\n        Clock source: local\nnf[nornir-cli]#commands \"show clock\" FC spine plugin scrapli\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:38:01 c6bd014aac4c42249594a6197175012e job started\n04-Jan-2025 22:38:01.116 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.119 nornir nornir-worker-1 ceos-spine-2 task_instance started - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.128 nornir nornir-worker-1 ceos-spine-2 subtask started - 'show clock'\n04-Jan-2025 22:38:01.141 nornir nornir-worker-1 ceos-spine-2 subtask completed - 'show clock'\n04-Jan-2025 22:38:01.148 nornir nornir-worker-1 ceos-spine-2 task_instance completed - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.192 nornir nornir-worker-1 ceos-spine-1 task_instance started - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.202 nornir nornir-worker-1 ceos-spine-1 subtask started - 'show clock'\n04-Jan-2025 22:38:01.215 nornir nornir-worker-1 ceos-spine-1 subtask completed - 'show clock'\n04-Jan-2025 22:38:01.221 nornir nornir-worker-1 ceos-spine-1 task_instance completed - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.364 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task completed - 'scrapli_send_commands'\n04-Jan-2025 22:38:01 c6bd014aac4c42249594a6197175012e job completed in 0.497 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\nceos-spine-1:\n    show clock:\n        Sat Jan  4 12:38:01 2025\n        Sat Jan  4 12:38:01 2025\n        Timezone: UTC\n        Clock source: local\nceos-spine-2:\n    show clock:\n        Sat Jan  4 12:38:01 2025\n        Timezone: UTC\n        Clock source: local\nnf[nornir-cli]#commands \"show clock\" FC spine plugin napalm\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:43:41 02eed090a7bb4652b27cccec1a49dab6 job started\n04-Jan-2025 22:43:41.360 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'napalm_send_commands'\n04-Jan-2025 22:43:41.382 nornir nornir-worker-1 ceos-spine-2 task_instance started - 'napalm_send_commands'\n04-Jan-2025 22:43:41.382 nornir nornir-worker-1 ceos-spine-1 task_instance started - 'napalm_send_commands'\n04-Jan-2025 22:43:41.388 nornir nornir-worker-1 ceos-spine-1 subtask started - 'napalm_cli'\n04-Jan-2025 22:43:41.389 nornir nornir-worker-1 ceos-spine-2 subtask started - 'napalm_cli'\n04-Jan-2025 22:43:41.419 nornir nornir-worker-1 ceos-spine-1 subtask completed - 'napalm_cli'\n04-Jan-2025 22:43:41.424 nornir nornir-worker-1 ceos-spine-2 subtask completed - 'napalm_cli'\n04-Jan-2025 22:43:41.425 nornir nornir-worker-1 ceos-spine-1 task_instance completed - 'napalm_send_commands'\n04-Jan-2025 22:43:41.432 nornir nornir-worker-1 ceos-spine-2 task_instance completed - 'napalm_send_commands'\n04-Jan-2025 22:43:41.599 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task completed - 'napalm_send_commands'\n04-Jan-2025 22:43:41 02eed090a7bb4652b27cccec1a49dab6 job completed in 0.576 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\nceos-spine-1:\n    show clock:\n        Sat Jan  4 12:43:41 2025\n        Timezone: UTC\n        Clock source: local\nceos-spine-2:\n    show clock:\n        Sat Jan  4 12:43:41 2025\n        Timezone: UTC\n        Clock source: local\nnf[nornir-cli]#\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nfcli</code> command starts the NorFab Interactive Shell.</li> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>cli</code> command switches to the CLI task sub-shell.</li> <li><code>commands</code> command retrieves the output of \"show clock\" from the devices  that contain <code>spine</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter, <code>plugin</code> argument used to inform Nornir service to use <code>netmiko</code>, <code>scrapli</code> or <code>napalm</code> modules to retrieve command output from devices.</li> </ul> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"cli\",\n        kwargs={\n            \"commands\": [\"show clock\"],\n            \"FC\": \"ceos-spine\",\n            \"plugin\": \"scrapli\"              \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_cli.py\n{'nornir-worker-1': {'errors': [],\n                     'failed': False,\n                     'messages': [],\n                     'result': {'ceos-spine-1': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local'},\n                                'ceos-spine-2': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local'}},\n                     'task': 'nornir-worker-1:cli'}}\nC:\\nf&gt;                   \n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#outputting-text-tables","title":"Outputting Text Tables","text":"<p>NorFab interactive shell supports <code>table</code> argument  that can be used to format output into text tables. Internally it relies on tabulate module and most of its features are supported.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#sourcing-commands-from-file","title":"Sourcing Commands From File","text":"<p>Commands can be provided inline in the shell itself, but it is also possible to source commands from text files stored on broker.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-jinja2-templates","title":"Using Jinja2 Templates","text":"<p>Commands can be templated using Jinja2. This allows you to create dynamic commands based on variables defined in your inventory or passed as job data.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#templating-commands-with-inline-job-data","title":"Templating Commands with Inline Job Data","text":"<p>Templating commands with inline job data allows you to dynamically generate command strings based on variables defined directly within the job data. This approach provides flexibility and customization, enabling you to tailor commands to specific devices or scenarios without the need for external sourced of data.</p> <p>When defining a job, you can include variables directly within the <code>job_data</code> argument. These variables can then be referenced within the command strings using Jinja2 templating syntax. The Nornir worker will process these templates, substituting the variables with their corresponding values from the job data.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-dry-run","title":"Using Dry Run","text":"<p>The dry run feature allows you to see the commands that would be executed without actually sending them to the devices. This is useful for testing and validation. When set to <code>True</code>, the commands will not be sent to the devices, but will be returned as part of the result.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#formatting-output-results","title":"Formatting Output Results","text":"<p>You can format the output results using various options provided by the Nornir worker. The output of the commands can be formatted using the <code>to_dict</code> parameter. When set to <code>True</code>, the results will be returned as a dictionary. When set to <code>False</code>, the results will be returned as a list. In addition <code>add_details</code> argument can be used to control the verbosity of the output and return additional Nornir result information such as:</p> <ul> <li><code>changed</code> flag</li> <li><code>diff</code> content if supported by plugin</li> <li><code>failed</code> status</li> <li><code>exception</code> details if task execution failed with error</li> <li><code>connection_retry</code> counter to show how many times RetryRunner tried to establish a connection</li> <li><code>task_retry</code> counter to show how many times RetryRunner tried to run this task</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#running-show-commands-multiple-times","title":"Running Show Commands Multiple Times","text":"<p>You can run show commands multiple times using the <code>repeat</code> parameter. This is useful for monitoring changes over time. The <code>repeat</code> parameter can be used to run the same command multiple times. You can also specify the interval between each repeat using the <code>repeat_interval</code> parameter.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-netmiko-promptless-mode","title":"Using Netmiko Promptless Mode","text":"<p>NorFab support proprietary promptless mode that can be used with Netmiko, it can be useful when dealing with devices that do not have a consistent prompt, or default Netmiko output collection functions are not reliable enough. This mode can be enabled by setting the <code>use_ps</code> parameter to <code>True</code>.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#parsing-commands-output","title":"Parsing Commands Output","text":"<p>When using Netmiko plugin the output of commands can be parsed using various parsers such as <code>textfsm</code>, <code>ttp</code> and <code>genie</code>. This allows you to convert the raw output into structured data. </p> <p>Using TTP parsing templates supported by all Netmiko, Scrapli and NAPALM connection plugins, to invoke TTP can us <code>run_ttp</code> command specifying path to parsing template stored on broker. </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#filtering-commands-output","title":"Filtering Commands Output","text":"<p>The output of commands can be filtered to only include specific information. This can be done using <code>match</code> command with containment patterns.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#sending-new-line-character","title":"Sending New Line Character","text":"<p>You can send a new line character as part of the command to devices. This is useful for commands that require a new line to be executed properly. To send new-line character need to include <code>_br_</code> into command text.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#saving-task-results-to-files","title":"Saving Task Results to Files","text":"<p>The results of tasks can be saved to files for later analysis and record-keeping. This is particularly useful for maintaining logs of command outputs, configuration changes, and other important data. By saving task results to files, you can create a historical record of network operations, which can be invaluable for troubleshooting, auditing, and compliance purposes.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-diff-function-to-compare-results","title":"Using Diff Function to Compare Results","text":"<p>The diff function allows you to compare the results of different task results for same commands. This is useful for identifying changes in configurations or device state, detecting anomalies, and verifying the impact of network modifications. By using the diff function, you can ensure that your network remains consistent and identify any unintended changes that may have occurred.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#norfab-nornir-cli-shell-reference","title":"NORFAB Nornir CLI Shell Reference","text":"<p>The NorFab shell provides a comprehensive set of commands for the Nornir <code>cli</code> task, allowing you to perform various network utility functions. These commands include options for setting job timeouts, specifying connection parameters, and controlling the execution of CLI commands. The shell reference details the available commands and their descriptions, providing you with the flexibility to tailor the behavior of the tasks to meet your specific network management needs.</p> <pre><code>nf#man tree nornir.cli\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 cli:    Send CLI commands to devices\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress, default 'True'\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *commands:    List of commands to collect form devices, default 'PydanticUndefined'\n        \u251c\u2500\u2500 plugin:    Connection plugin parameters\n        \u2502   \u251c\u2500\u2500 netmiko:    Use Netmiko plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 enable:    Attempt to enter enable-mode\n        \u2502   \u2502   \u251c\u2500\u2500 use_timing:    switch to send command timing method\n        \u2502   \u2502   \u251c\u2500\u2500 expect_string:    Regular expression pattern to use for determining end of output\n        \u2502   \u2502   \u251c\u2500\u2500 read_timeout:    Maximum time to wait looking for pattern\n        \u2502   \u2502   \u251c\u2500\u2500 auto_find_prompt:    Use find_prompt() to override base prompt\n        \u2502   \u2502   \u251c\u2500\u2500 strip_prompt:    Remove the trailing router prompt from the output\n        \u2502   \u2502   \u251c\u2500\u2500 strip_command:    Remove the echo of the command from the output\n        \u2502   \u2502   \u251c\u2500\u2500 normalize:    Ensure the proper enter is sent at end of command\n        \u2502   \u2502   \u251c\u2500\u2500 use_textfsm:    Process command output through TextFSM template\n        \u2502   \u2502   \u251c\u2500\u2500 textfsm_template:    Name of template to parse output with\n        \u2502   \u2502   \u251c\u2500\u2500 use_ttp:    Process command output through TTP template\n        \u2502   \u2502   \u251c\u2500\u2500 ttp_template:    Name of template to parse output with\n        \u2502   \u2502   \u251c\u2500\u2500 use_genie:    Process command output through PyATS/Genie parser\n        \u2502   \u2502   \u251c\u2500\u2500 cmd_verify:    Verify command echo before proceeding\n        \u2502   \u2502   \u251c\u2500\u2500 interval:    Interval between sending commands\n        \u2502   \u2502   \u251c\u2500\u2500 use_ps:    Use send command promptless method\n        \u2502   \u2502   \u251c\u2500\u2500 use_ps_timeout:    Promptless mode absolute timeout\n        \u2502   \u2502   \u251c\u2500\u2500 new_line_char:    Character to replace with new line before sending to device, default is _br_\n        \u2502   \u2502   \u251c\u2500\u2500 repeat:    Number of times to repeat the commands\n        \u2502   \u2502   \u251c\u2500\u2500 stop_pattern:    Stop commands repeat if output matches provided glob pattern\n        \u2502   \u2502   \u251c\u2500\u2500 repeat_interval:    Time in seconds to wait between repeating commands\n        \u2502   \u2502   \u2514\u2500\u2500 return_last:    Returns requested last number of commands outputs\n        \u2502   \u251c\u2500\u2500 scrapli:    Use Scrapli plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 failed_when_contains:    String or list of strings indicating failure if found in response\n        \u2502   \u2502   \u251c\u2500\u2500 timeout_ops:    Timeout ops value for this operation\n        \u2502   \u2502   \u251c\u2500\u2500 interval:    Interval between sending commands\n        \u2502   \u2502   \u251c\u2500\u2500 split_lines:    Split multiline string to individual commands\n        \u2502   \u2502   \u251c\u2500\u2500 new_line_char:    Character to replace with new line before sending to device, default is _br_\n        \u2502   \u2502   \u251c\u2500\u2500 repeat:    Number of times to repeat the commands\n        \u2502   \u2502   \u251c\u2500\u2500 stop_pattern:    Stop commands repeat if output matches provided glob pattern\n        \u2502   \u2502   \u251c\u2500\u2500 repeat_interval:    Time in seconds to wait between repeating commands\n        \u2502   \u2502   \u2514\u2500\u2500 return_last:    Returns requested last number of commands outputs\n        \u2502   \u2514\u2500\u2500 napalm:    Use NAPALM plugin to configure devices\n        \u2502       \u251c\u2500\u2500 interval:    Interval between sending commands\n        \u2502       \u251c\u2500\u2500 split_lines:    Split multiline string to individual commands\n        \u2502       \u2514\u2500\u2500 new_line_char:    Character to replace with new line before sending to device, default is _br_\n        \u251c\u2500\u2500 cli_dry_run:    Dry run the commands\n        \u251c\u2500\u2500 enable:    Enter exec mode\n        \u251c\u2500\u2500 run_ttp:    TTP Template to run\n        \u2514\u2500\u2500 job_data:    Path to YAML file with job data\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#python-api-reference","title":"Python API Reference","text":"<p>Task to collect show commands output from devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>commands</code> <code>list</code> <p>list of commands to send to devices</p> <code>None</code> <code>plugin</code> <code>str</code> <p>plugin name to use - valid options are <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cli_dry_run</code> <code>bool</code> <p>do not send commands to devices just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>run_ttp</code> <code>str</code> <p>TTP Template to run</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cli(\n    self,\n    commands: list = None,\n    plugin: str = \"netmiko\",\n    cli_dry_run: bool = False,\n    run_ttp: str = None,\n    job_data: str = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to collect show commands output from devices using\n    Command Line Interface (CLI)\n\n    :param commands: list of commands to send to devices\n    :param plugin: plugin name to use - valid options are ``netmiko``, ``scrapli``, ``napalm``\n    :param cli_dry_run: do not send commands to devices just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param run_ttp: TTP Template to run\n    \"\"\"\n    job_data = job_data or {}\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    downloaded_cmds = []\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:cli\", result={} if to_dict else [])\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_commands\n        if kwargs.get(\"use_ps\"):\n            kwargs.setdefault(\"timeout\", timeout)\n        else:\n            kwargs.setdefault(\"read_timeout\", timeout)\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_commands\n        kwargs.setdefault(\"timeout_ops\", timeout)\n    elif plugin == \"napalm\":\n        task_plugin = napalm_send_commands\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    # download TTP template\n    if self.is_url(run_ttp):\n        downloaded = self.fetch_file(run_ttp)\n        kwargs[\"run_ttp\"] = downloaded\n        if downloaded is None:\n            msg = f\"{self.name} - TTP template download failed '{run_ttp}'\"\n            raise FileNotFoundError(msg)\n    # use TTP template as is - inline template or ttp://xyz path\n    elif run_ttp:\n        kwargs[\"run_ttp\"] = run_ttp\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render commands using Jinja2 on a per-host basis\n    if commands:\n        commands = commands if isinstance(commands, list) else [commands]\n        for host in nr.inventory.hosts.values():\n            rendered = self.render_jinja2_templates(\n                templates=commands,\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n            host.data[\"__task__\"] = {\"commands\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - running cli commands '{commands}', kwargs '{kwargs}', is cli dry run - '{cli_dry_run}'\"\n    )\n    if cli_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"commands\", name=\"cli_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/","title":"Nornir Service Diagram Task","text":"<p>The Nornir Service Diagram Task is a powerful component of NorFab's Nornir service, designed to create detailed network diagrams. By leveraging the N2G (Need to Graph) module, this task enables network engineers and architects to visualize network topologies and configurations, facilitating better network management and planning.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-layer-2-network-diagram","title":"Creating Layer-2 Network Diagram","text":"<p>Layer-2 network diagrams illustrate the data link layer of the OSI model, showing how devices are interconnected within a local area network (LAN) based on the output provided by LLDP and CDP protocols. These diagrams are essential for understanding the physical and logical connections between switches, routers, and other network devices. By creating Layer-2 network diagrams, you can identify potential bottlenecks, optimize traffic flow, and ensure efficient network design. The Nornir Service Diagram Task uses the N2G module to automatically generate these diagrams, providing a clear and accurate representation of your Layer-2 topology.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-layer-3-network-diagram","title":"Creating Layer-3 Network Diagram","text":"<p>Layer-3 network diagrams depict the network layer of the OSI model, highlighting the routing and IP addressing within a network. These diagrams are crucial for understanding how data is routed between different subnets and networks. By creating Layer-3 network diagrams, you can visualize the routing paths, identify potential routing issues, and ensure proper IP address allocation. The Nornir Service Diagram Task leverages the N2G module to construct these diagrams, offering a comprehensive view of your Layer-3 network infrastructure.</p> <p>Example</p> CLI <pre><code>nf#\nnf#\nnf#nornir\nnf[nornir]#diagram\nnf[nornir-diagram]#layer3 FC spine,leaf\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:59:56 85fd42146327446cae3c26ceb2077abf job started\n04-Jan-2025 22:59:56.664 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n&lt;omitted for brevity&gt;\n04-Jan-2025 22:59:58 85fd42146327446cae3c26ceb2077abf job completed in 2.117 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\ndiagram: 'layer3', format: 'yed'\nsaved at: './diagrams\\layer3_2025-01-04_22-59-56.graphml'\nhosts: ceos-leaf-1, ceos-leaf-2, ceos-leaf-3, ceos-spine-1, ceos-spine-2\nnf[nornir-diagram]#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>diagram</code> command switches to the diagram task sub-shell.</li> <li><code>layer3</code> command run commands output collection for devices that have <code>spine</code> or <code>leaf</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter, once output collected N2G parses commands output and constructs L3 Network diagram of subnets and IP addresses saving diagram in yEd compatible format at <code>./diagrams\\layer3_2025-01-04_22-59-56.graphml</code> file.</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-ospf-routing-protocol-network-diagram","title":"Creating OSPF Routing Protocol Network Diagram","text":"<p>OSPF (Open Shortest Path First) is a widely used interior gateway protocol for routing within an autonomous system. Creating OSPF routing protocol network diagrams helps you visualize the OSPF areas, router adjacencies, and link metrics. These diagrams are useful for troubleshooting OSPF-related issues, optimizing OSPF configurations, and ensuring efficient routing. The Nornir Service Diagram Task utilizes the N2G module to generate OSPF network diagrams, providing a detailed view of your OSPF topology and configurations.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-isis-routing-protocol-network-diagram","title":"Creating ISIS Routing Protocol Network Diagram","text":"<p>ISIS (Intermediate System to Intermediate System) is a popular interior gateway protocol used for routing within large networks. Creating ISIS routing protocol network diagrams allows you to visualize the ISIS areas, router adjacencies, and link metrics. These diagrams are vital for understanding the ISIS routing process, identifying potential issues and optimizing the network. The Nornir Service Diagram Task utilizes the N2G module to generate ISIS network diagrams, providing a detailed view of your ISIS topology and configurations.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-drawio-diagrams","title":"Creating draw.io Diagrams","text":"<p>N2G module can produce diagrams in several formats, to create draw.io diagram need to use <code>format</code> argument with <code>drawio</code> value.</p> <p>Example</p> CLI <pre><code>nf#\nnf#\nnf#nornir\nnf[nornir]#diagram\nnf[nornir-diagram]#format drawio layer3 FC spine,leaf\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 23:16:13 a2d39b5b1268488a95805baed96699a1 job started\n04-Jan-2025 23:16:14.277 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n04-Jan-2025 23:16:14.289 nornir nornir-worker-2 ceos-leaf-1, ceos-leaf-2, ceos-leaf-3 task started - 'netmiko_send_commands'\n&lt;omitted for brevity&gt;\n04-Jan-2025 23:16:16 a2d39b5b1268488a95805baed96699a1 job completed in 2.606 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\ndiagram: 'layer3', format: 'drawio'\nsaved at: './diagrams\\layer3_2025-01-04_23-16-13.drawio'\nhosts: ceos-leaf-1, ceos-leaf-2, ceos-leaf-3, ceos-spine-1, ceos-spine-2\nnf[nornir-diagram]#\n</code></pre> <ul> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>diagram</code> command switches to the diagram task sub-shell.</li> <li><code>format</code> argument specifies what diagram format to create, draw.io in this case.</li> <li><code>layer3</code> command run commands output collection for devices that have <code>spine</code> or <code>leaf</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter, once output collected N2G parses commands output and constructs L3 Network diagram of subnets and IP addresses saving diagram in draw.io compatible format at <code>./diagrams\\layer3_2025-01-04_23-16-13.drawio</code> file.</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#norfab-nornir-diagram-shell-reference","title":"NORFAB Nornir Diagram Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>diagram</code> task:</p> <pre><code>nf#man tree nornir.diagram\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 diagram:    Produce network diagrams\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 format:    Diagram application format, default 'yed'\n        \u251c\u2500\u2500 layer3:    Create L3 Network diagram using IP data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 group_links:    Group links between same nodes\n        \u2502   \u251c\u2500\u2500 add_arp:    Add IP nodes from ARP cache parsing results\n        \u2502   \u251c\u2500\u2500 label_interface:    Add interface name to the link\u2019s source and target labels\n        \u2502   \u251c\u2500\u2500 label_vrf:    Add VRF name to the link\u2019s source and target labels\n        \u2502   \u251c\u2500\u2500 collapse_ptp:    Combines links for /31 and /30 IPv4 and /127 IPv6 subnets into a single link\n        \u2502   \u251c\u2500\u2500 add_fhrp:    Add HSRP and VRRP IP addresses to the diagram\n        \u2502   \u251c\u2500\u2500 bottom_label_length:    Length of interface description to use for subnet labels, if 0, label not set\n        \u2502   \u2514\u2500\u2500 lbl_next_to_subnet:    Put link port:vrf:ip label next to subnet node\n        \u251c\u2500\u2500 layer2:    Create L2 Network diagram using CDP/LLDP data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 add_interfaces_data:    Add interfaces configuration and state data to links\n        \u2502   \u251c\u2500\u2500 group_links:    Group links between nodes\n        \u2502   \u251c\u2500\u2500 add_lag:    Add LAG/MLAG links to diagram\n        \u2502   \u251c\u2500\u2500 add_all_connected:    Add all nodes connected to devices based on interfaces state\n        \u2502   \u251c\u2500\u2500 combine_peers:    Combine CDP/LLDP peers behind same interface by adding L2 node\n        \u2502   \u2514\u2500\u2500 skip_lag:    Skip CDP peers for LAG, some platforms send CDP/LLDP PDU from LAG ports\n        \u251c\u2500\u2500 isis:    Create ISIS Network diagram using LSDB data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 ip_lookup_data:    IP Lookup dictionary or OS path to CSV file\n        \u2502   \u251c\u2500\u2500 add_connected:    Add connected subnets as nodes\n        \u2502   \u251c\u2500\u2500 ptp_filter:    List of glob patterns to filter point-to-point links based on link IP\n        \u2502   \u2514\u2500\u2500 add_data:    Add data information to nodes and links\n        \u251c\u2500\u2500 ospf:    Create OSPF Network diagram using LSDB data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 ip_lookup_data:    IP Lookup dictionary or OS path to CSV file\n        \u2502   \u251c\u2500\u2500 add_connected:    Add connected subnets as nodes\n        \u2502   \u251c\u2500\u2500 ptp_filter:    List of glob patterns to filter point-to-point links based on link IP\n        \u2502   \u2514\u2500\u2500 add_data:    Add data information to nodes and links\n        \u2514\u2500\u2500 filename:    Name of the file to save diagram content\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/","title":"Nornir Service File Copy Task","text":"<p>The Nornir Service File Copy Task is a component of NorFab's Nornir service, designed to facilitate the transfer of files to and from network devices. This task provides network engineers with a reliable and efficient method for managing device configurations, firmware updates, and other critical files. By leveraging the capabilities of the Nornir service, users can automate file transfers.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/#nornir-file-copy-sample-usage","title":"Nornir File Copy Sample Usage","text":"","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/#norfab-nornir-file-copy-shell-reference","title":"NORFAB Nornir File Copy Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>file-copy</code> task:</p> <pre><code>nf#man tree nornir.file-copy\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 file-copy:    Copy files to/from devices\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *source_file:    Source file to copy\n        \u251c\u2500\u2500 plugin:    Connection plugin parameters\n        \u2502   \u2514\u2500\u2500 netmiko:    Use Netmiko plugin to copy files\n        \u2502       \u251c\u2500\u2500 dest-file:    Destination file to copy\n        \u2502       \u251c\u2500\u2500 file-system:    Destination file system\n        \u2502       \u251c\u2500\u2500 direction:    Direction of file copy, default 'put'\n        \u2502       \u251c\u2500\u2500 inline-transfer:    Use inline transfer, supported by Cisco IOS\n        \u2502       \u251c\u2500\u2500 overwrite-file:    Overwrite destination file if it exists, default 'False'\n        \u2502       \u251c\u2500\u2500 socket-timeout:    Socket timeout in seconds, default '10.0'\n        \u2502       \u2514\u2500\u2500 verify-file:    Verify destination file hash after copy, default 'True'\n        \u2514\u2500\u2500 dry-run:    Do not copy files, just show what would be done\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/#python-api-reference","title":"Python API Reference","text":"<p>Task to transfer files to and from hosts using SCP</p> <p>Parameters:</p> Name Type Description Default <code>source_file</code> <code>str</code> <p>path to file to copy, support <code>nf://path/to/file</code> URL to copy from broker</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code></p> <code>'netmiko'</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False produces list</p> <code>True</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>if True will not copy files just return what would be copied</p> <code>False</code> <code>kwargs</code> <p>additional arguments to pass to the plugin function</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the file copy task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def file_copy(\n    self,\n    source_file: str,\n    plugin: str = \"netmiko\",\n    to_dict: bool = True,\n    add_details: bool = False,\n    dry_run: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to transfer files to and from hosts using SCP\n\n    :param source_file: path to file to copy, support ``nf://path/to/file`` URL to copy from broker\n    :param plugin: plugin name to use - ``netmiko``\n    :param to_dict: default is True - produces dictionary results, if False produces list\n    :param add_details: if True will add task execution details to the results\n    :param dry_run: if True will not copy files just return what would be copied\n    :param kwargs: additional arguments to pass to the plugin function\n    :return: dictionary with the results of the file copy task\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:file_copy\", result={} if to_dict else [])\n\n    # download file from broker\n    if self.is_url(source_file):\n        source_file_local = self.fetch_file(\n            source_file, raise_on_fail=True, read=False\n        )\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_file_transfer\n        kwargs[\"source_file\"] = source_file_local\n        kwargs.setdefault(\"socket_timeout\", timeout / 5)\n        kwargs.setdefault(\"dest_file\", os.path.split(source_file_local)[-1])\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(\n        f\"{self.name} - running file copy with arguments '{kwargs}', is dry run - '{dry_run}'\"\n    )\n    if dry_run is True:\n        result = nr.run(task=nr_test, name=\"file_copy_dry_run\", **kwargs)\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/","title":"Nornir Service Network Task","text":"<p>The Nornir Service Network Task is a component of NorFab's Nornir service designed to facilitate various network-related operations. This task suite provides network professionals with essential tools for managing, troubleshooting, and monitoring network infrastructure. By leveraging the capabilities of the Nornir service, users can perform critical network functions such as ICMP echo requests (ping) and DNS resolution checks, ensuring the reliability and performance of their network devices and services.</p> <p>Key features of the Nornir Service Network Task include:</p> <ul> <li> <p>Network Ping: This task allows you to perform ICMP echo requests to verify the reachability of network devices. </p> </li> <li> <p>DNS Testing: This task enables you to perform DNS resolution checks to ensure that domain names are correctly mapped to their respective IP addresses. </p> </li> </ul> <p>The document also includes a reference for the NorFab shell commands related to the Nornir <code>network</code> task, detailing the available options and parameters. These commands provide granular control over the execution of network tasks, enabling users to tailor the behavior of the tasks to meet specific network management needs.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#network-ping","title":"Network Ping","text":"<p>The Network Ping task in NorFab's Nornir service allows you to perform ICMP echo requests (pings) to verify the reachability of network devices. This task is essential for network troubleshooting and monitoring, as it helps you determine if a device is online and responsive. The ping task can be customized with various parameters such as timeout, number of retries, payload size and others. By using the ping task, you can quickly identify connectivity issues and ensure that your network devices are functioning correctly.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#dns-testing","title":"DNS Testing","text":"<p>The DNS Testing task in NorFab's Nornir service enables you to perform DNS resolution checks to verify that domain names are correctly mapped to their respective IP addresses. This task is crucial for ensuring that your DNS infrastructure is working as expected and that your network services are accessible via their domain names. The DNS testing task can be configured with different parameters to control the behavior of the DNS queries, such as specifying the DNS server to use, query timeout, and the type of DNS record to query. By performing DNS tests, you can proactively identify and resolve DNS-related issues, ensuring seamless network operations.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#norfab-nornir-network-shell-reference","title":"NORFAB Nornir Network Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>network</code> task:</p> <pre><code>nf#man tree nornir.network\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 network:    Network utility functions - ping, dns etc.\n        \u251c\u2500\u2500 ping:    Ping devices\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Emit execution progress\n        \u2502   \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u2502   \u251c\u2500\u2500 headers:    Table headers\n        \u2502   \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u2502   \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u2502   \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 use_host_name:    Ping host's name instead of host's hostname\n        \u2502   \u251c\u2500\u2500 count:    Number of pings to run\n        \u2502   \u251c\u2500\u2500 ping_timeout:    Time in seconds before considering each non-arrived reply permanently lost\n        \u2502   \u251c\u2500\u2500 size:    Size of the entire packet to send\n        \u2502   \u251c\u2500\u2500 interval:    Interval to wait between pings\n        \u2502   \u251c\u2500\u2500 payload:    Payload content if size is not set\n        \u2502   \u251c\u2500\u2500 sweep_start:    If size is not set, initial size in a sweep of sizes\n        \u2502   \u251c\u2500\u2500 sweep_end:    If size is not set, final size in a sweep of sizes\n        \u2502   \u251c\u2500\u2500 df:    Don't Fragment flag value for IP Header\n        \u2502   \u251c\u2500\u2500 match:    Do payload matching between request and reply\n        \u2502   \u2514\u2500\u2500 source:    Source IP address\n        \u2514\u2500\u2500 dns:    Resolve DNS\n            \u251c\u2500\u2500 timeout:    Job timeout\n            \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n            \u251c\u2500\u2500 add_details:    Add task details to results\n            \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n            \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n            \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n            \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n            \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n            \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n            \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n            \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n            \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n            \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n            \u251c\u2500\u2500 diff:    File group name to run the diff for\n            \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n            \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n            \u251c\u2500\u2500 headers:    Table headers\n            \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n            \u251c\u2500\u2500 sortby:    Table header column to sort by\n            \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n            \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n            \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n            \u251c\u2500\u2500 FH:    Filter hosts by hostname\n            \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n            \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n            \u251c\u2500\u2500 FG:    Filter hosts by group\n            \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n            \u251c\u2500\u2500 FL:    Filter hosts by names list\n            \u251c\u2500\u2500 FM:    Filter hosts by platform\n            \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n            \u251c\u2500\u2500 FN:    Negate the match\n            \u251c\u2500\u2500 hosts:    Filter hosts to target\n            \u251c\u2500\u2500 use_host_name:    Ping host's name instead of host's hostname\n            \u251c\u2500\u2500 servers:    List of DNS servers to use\n            \u251c\u2500\u2500 dns_timeout:    Time in seconds before considering request lost\n            \u251c\u2500\u2500 ipv4:    Resolve 'A' record\n            \u2514\u2500\u2500 ipv6:    Resolve 'AAAA' record\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#python-api-reference","title":"Python API Reference","text":"<p>Task to call various network related utility functions.</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <p>(str) utility function name to call</p> required <code>kwargs</code> <p>(dict) function arguments  Available utility functions.  resolve_dns function  resolves hosts' hostname DNS returning IP addresses using <code>nornir_salt.plugins.tasks.network.resolve_dns</code> Nornir-Salt function.  ping function  Function to execute ICMP ping to host using <code>nornir_salt.plugins.tasks.network.ping</code> Nornir-Salt function.</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def network(self, fun, **kwargs) -&gt; dict:\n    \"\"\"\n    Task to call various network related utility functions.\n\n    :param fun: (str) utility function name to call\n    :param kwargs: (dict) function arguments\n\n    Available utility functions.\n\n    **resolve_dns** function\n\n    resolves hosts' hostname DNS returning IP addresses using\n    ``nornir_salt.plugins.tasks.network.resolve_dns`` Nornir-Salt\n    function.\n\n    **ping** function\n\n    Function to execute ICMP ping to host using\n    ``nornir_salt.plugins.tasks.network.ping`` Nornir-Salt\n    function.\n    \"\"\"\n    kwargs[\"call\"] = fun\n    return self.task(\n        plugin=\"nornir_salt.plugins.tasks.network\",\n        **kwargs,\n    )\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_parse/","title":"Nornir Service Parse Task","text":"<p>The Nornir Service Parse Task is an integral part of NorFab's Nornir service, designed to facilitate the parsing and extraction of valuable information from network device outputs. This task provides network automation and developer engineers with powerful tools to transform raw command outputs into structured data, enabling more efficient network management and automation workflows.</p> <p>Key features of the Nornir Service Parse Task include:</p> <ul> <li> <p>TextFSM Parsing: This task allows you to use TextFSM templates to parse command outputs into structured data. TextFSM is a powerful text processing tool that uses templates to define how to extract data from unstructured text. By leveraging TextFSM, you can convert complex command outputs into easily readable and processable data formats, which can then be used for further analysis or automation tasks.</p> </li> <li> <p>TTP Parsing: The Template Text Parser (TTP) is a robust parsing tool supported by the Nornir Service Parse Task. TTP allows you to define templates for parsing text data, similar to TextFSM, but with additional flexibility and features. Using TTP, you can extract specific information from command outputs and transform it into structured data, making it easier to integrate with other systems and processes.</p> </li> <li> <p>NAPALM Getters: The Nornir Service Parse Task leverages NAPALM getters to retrieve and parse structured data directly from network devices. NAPALM getters are pre-defined methods that extract specific pieces of information from devices, such as interface details, routing tables, ARP tables, and more.</p> </li> </ul> <p>The Nornir Service Parse Task is essential for network automation and developer engineers who need to process and analyze large volumes of network data. By transforming raw command outputs into structured data, you can automate complex workflows, generate insightful reports, and ensure that your network devices are configured and operating correctly.</p> <p>This document also includes a reference for the NorFab shell commands related to the Nornir <code>parse</code> task, detailing the available options and parameters. These commands provide granular control over the parsing tasks.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_parse/#norfab-nornir-parse-shell-reference","title":"NORFAB Nornir Parse Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>parse</code> task:</p> <pre><code>nf#man tree nornir.parse\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 parse:    Parse network devices output\n        \u251c\u2500\u2500 napalm:    Parse devices output using NAPALM getters\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Emit execution progress\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u2514\u2500\u2500 *getters:    Select NAPALM getters, default 'PydanticUndefined'\n        \u2514\u2500\u2500 ttp:    Parse devices output using TTP templates\n            \u251c\u2500\u2500 timeout:    Job timeout\n            \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n            \u251c\u2500\u2500 add_details:    Add task details to results\n            \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n            \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n            \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n            \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n            \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n            \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n            \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n            \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n            \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n            \u251c\u2500\u2500 diff:    File group name to run the diff for\n            \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n            \u251c\u2500\u2500 progress:    Emit execution progress\n            \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n            \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n            \u251c\u2500\u2500 FH:    Filter hosts by hostname\n            \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n            \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n            \u251c\u2500\u2500 FG:    Filter hosts by group\n            \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n            \u251c\u2500\u2500 FL:    Filter hosts by names list\n            \u251c\u2500\u2500 FM:    Filter hosts by platform\n            \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n            \u251c\u2500\u2500 FN:    Negate the match\n            \u251c\u2500\u2500 hosts:    Filter hosts to target\n            \u251c\u2500\u2500 *template:    TTP Template to parse commands output, default 'PydanticUndefined'\n            \u2514\u2500\u2500 commands:    Commands to collect form devices\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_parse/#python-api-reference","title":"Python API Reference","text":"<p>Function to parse network devices show commands output</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>plugin name to use - <code>napalm</code>, <code>textfsm</code>, <code>ttp</code></p> <code>'napalm'</code> <code>getters</code> <code>str</code> <p>NAPALM getters to use</p> <code>'get_facts'</code> <code>commands</code> <code>list</code> <p>commands to send to devices for TextFSM or TTP template</p> <code>None</code> <code>template</code> <code>str</code> <p>TextFSM or TTP parsing template string or path to file  For NAPALM plugin <code>method</code> can refer to a list of getters names.</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def parse(\n    self,\n    plugin: str = \"napalm\",\n    getters: str = \"get_facts\",\n    template: str = None,\n    commands: list = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Function to parse network devices show commands output\n\n    :param plugin: plugin name to use - ``napalm``, ``textfsm``, ``ttp``\n    :param getters: NAPALM getters to use\n    :param commands: commands to send to devices for TextFSM or TTP template\n    :param template: TextFSM or TTP parsing template string or path to file\n\n    For NAPALM plugin ``method`` can refer to a list of getters names.\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:parse\", result={} if to_dict else [])\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    if plugin == \"napalm\":\n        nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n        result = nr.run(task=napalm_get, getters=getters, **kwargs)\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    elif plugin == \"ttp\":\n        result = self.cli(\n            commands=commands or [],\n            run_ttp=template,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    elif plugin == \"textfsm\":\n        result = self.cli(\n            commands=commands,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            use_textfsm=True,\n            textfsm_template=template,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/","title":"Nornir Service \"Task\" Task","text":"<p>The Nornir Service \"Task\" Task is a versatile component of NorFab's Nornir service, designed to execute any arbitrary Nornir task plugin function. This task provides network automation and developer engineers with the flexibility to run custom Nornir tasks, enabling them to tailor their network automation workflows to meet specific requirements.</p> <p>Key features of the Nornir Service \"Task\" Task include:</p> <ul> <li> <p>Custom Task Execution: The \"Task\" Task allows you to run custom Nornir task functions, which can be referenced using the OS path to the custom task Python file stored on broker or using dot notation to reference an import module. </p> </li> <li> <p>Integration with Nornir Plugins: The Nornir framework supports a wide range of community-built plugins, which can be called directly or leveraged to extend the functionality of your custom tasks. By integrating these plugins, you can enhance your automation capabilities and streamline complex network operations. Reference the Nornir Plugins page for a list of available plugins.</p> </li> <li> <p>Scalability and Reusability: Custom Nornir tasks can be designed to be scalable and reusable, allowing you to apply the same task logic across different network environments and scenarios. This promotes consistency and efficiency in your network automation workflows, reducing the need for repetitive coding and manual intervention.</p> </li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#nornir-tasks-sample-usage","title":"Nornir Tasks Sample Usage","text":"<p>Example of calling Nornir custom task function stored on NORFAB  broker under <code>nornir_tasks/echo.py</code> file path:</p> <pre><code>\u251c\u2500\u2500\u2500inventory.yaml\n\u2514\u2500\u2500\u2500nornir_tasks\n    \u2514\u2500\u2500\u2500echo.py\n</code></pre> <p>Task <code>echo.py</code> takes provided arguments and echoes them back in results:</p> <pre><code>from nornir.core.task import Result, Task\n\n\ndef task(task: Task, **kwargs) -&gt; Result:\n    task.name = \"echo\"\n    return Result(host=task.host, result=kwargs)\n</code></pre> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir]#task\nnf[nornir-task]#plugin nf://nornir_tasks/echo.py arguments {\"foo\": \"bar\"} FC spine\nceos-spine-1:\n    echo:\n        foo: bar\nceos-spine-2:\n    echo:\n        foo: bar\nnf[nornir-task]#top\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>Above runs <code>echo.py</code> custom Nornir task taking arguments <code>{\"foo\": \"bar\"}</code>  as an input and echoing them back. Task only executed for  Nornir hosts that contain <code>ceos-spine</code> in their hostname as  we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting  filter.</p> <p><code>inventory.yaml</code> should be located in same folder where we  start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag  used. Refer to Getting Started  section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"task\",\n        kwargs={\n            \"plugin\": \"nf://nornir_tasks/echo.py\",\n            \"argument\": {\"foo\": \"bar\"},\n            \"FC\": \"ceos-spine\"    \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_task_docs.py\n{'nornir-worker-1': {'errors': [],\n                    'failed': False,\n                    'messages': [],\n                    'result': {'ceos-spine-1': {'echo': {'argument': {'foo': 'bar'}}},\n                                'ceos-spine-2': {'echo': {'argument': {'foo': 'bar'}}}},\n                    'task': 'nornir-worker-1:task'}}\n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.    </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#use-community-module-task","title":"Use Community Module Task","text":"<p>It is possible to run any Nornir task plugin created by open  source community. For example, to use <code>netmiko_send_commands</code> from  <code>nornir_netmiko</code> module need to set plugin argument to  <code>nornir_netmiko.tasks.netmiko_send_commands</code> value and supply <code>arguments</code> option to provide further task parameters.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir]#task\nnf[nornir-task]#plugin \"nornir_netmiko.tasks.netmiko_send_command\" arguments {\"command_string\": \"show hostname\"} FC spine\nceos-spine-1:\n    netmiko_send_command:\n        Hostname: ceos-spine-1\n        FQDN:     ceos-spine-1\nceos-spine-2:\n    netmiko_send_command:\n        Hostname: ceos-spine-2\n        FQDN:     ceos-spine-2\nnf[nornir-task]#top\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>Above runs <code>netmiko_send_command</code> Nornir task from <code>nornir_netmiko</code> module and collects <code>show hostname</code> command output from hosts that contain <code>ceos-spine</code> in their host name  since the use of targeting filter <code>FC</code> - \"Filter Contains\".</p> <p><code>inventory.yaml</code> should be located in same folder where we  start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag  used. Refer to Getting Started  section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"task\",\n        kwargs={\n            \"plugin\": \"nornir_netmiko.tasks.netmiko_send_command\",\n            \"command_string\": \"show hostname\",\n            \"FC\": \"ceos-spine\"    \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Notice slight difference, python api does not make use of <code>arguments</code> option and need to supply task parameters as is  inside of <code>kwargs</code> dictionary.</p> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_task_module_docs.py\n{'nornir-worker-1': {'errors': [],\n                    'failed': False,\n                    'messages': [],\n                    'result': {'ceos-spine-1': {'netmiko_send_command': 'Hostname: '\n                                                                        'ceos-spine-1\\n'\n                                                                        'FQDN:     '\n                                                                        'ceos-spine-1'},\n                                'ceos-spine-2': {'netmiko_send_command': 'Hostname: '\n                                                                        'ceos-spine-2\\n'\n                                                                        'FQDN:     '\n                                                                        'ceos-spine-2'}}}\n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.    </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#norfab-nornir-task-shell-reference","title":"NORFAB Nornir Task Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>task</code> task:</p> <pre><code>nf#man tree nornir.task\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 task:    Run Nornir task\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *plugin:    Nornir task.plugin.name to import or nf://path/to/plugin/file.py\n        \u2514\u2500\u2500 arguments:    Plugin arguments JSON formatted string\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#python-api-reference","title":"Python API Reference","text":"<p>Task to invoke any of supported Nornir task plugins. This function performs dynamic import of requested plugin function and executes <code>nr.run</code> using supplied args and kwargs</p> <p><code>plugin</code> attribute can refer to a file to fetch from file service. File must contain function named <code>task</code> accepting Nornir task object as a first positional argument, for example:</p> <pre><code># define connection name for RetryRunner to properly detect it\nCONNECTION_NAME = \"netmiko\"\n\n# create task function\ndef task(nornir_task_object, **kwargs):\n    pass\n</code></pre> <p>CONNECTION_NAME</p> <p><code>CONNECTION_NAME</code> must be defined within custom task function file if RetryRunner in use, otherwise connection retry logic skipped and connections to all hosts initiated simultaneously up to the number of <code>num_workers</code>.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>(str) <code>path.to.plugin.task_fun</code> to import or <code>nf://path/to/task.py</code> to download custom task</p> required <code>kwargs</code> <p>(dict) arguments to use with specified task plugin</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def task(self, plugin: str, **kwargs) -&gt; Result:\n    \"\"\"\n    Task to invoke any of supported Nornir task plugins. This function\n    performs dynamic import of requested plugin function and executes\n    ``nr.run`` using supplied args and kwargs\n\n    ``plugin`` attribute can refer to a file to fetch from file service. File must contain\n    function named ``task`` accepting Nornir task object as a first positional\n    argument, for example:\n\n    ```python\n    # define connection name for RetryRunner to properly detect it\n    CONNECTION_NAME = \"netmiko\"\n\n    # create task function\n    def task(nornir_task_object, **kwargs):\n        pass\n    ```\n\n    !!! note \"CONNECTION_NAME\"\n\n        ``CONNECTION_NAME`` must be defined within custom task function file if\n        RetryRunner in use, otherwise connection retry logic skipped and connections\n        to all hosts initiated simultaneously up to the number of ``num_workers``.\n\n    :param plugin: (str) ``path.to.plugin.task_fun`` to import or ``nf://path/to/task.py``\n        to download custom task\n    :param kwargs: (dict) arguments to use with specified task plugin\n    \"\"\"\n    # extract attributes\n    add_details = kwargs.pop(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.pop(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:task\", result={} if to_dict else [])\n\n    # download task from broker and load it\n    if plugin.startswith(\"nf://\"):\n        function_text = self.fetch_file(plugin)\n        if function_text is None:\n            raise FileNotFoundError(\n                f\"{self.name} - '{plugin}' task plugin download failed\"\n            )\n\n        # load task function running exec\n        globals_dict = {}\n        exec(function_text, globals_dict, globals_dict)\n        task_function = globals_dict[\"task\"]\n    # import task function\n    else:\n        # below same as \"from nornir.plugins.tasks import task_fun as task_function\"\n        task_fun = plugin.split(\".\")[-1]\n        module = __import__(plugin, fromlist=[\"\"])\n        task_function = getattr(module, task_fun)\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(f\"{self.name} - running Nornir task '{plugin}', kwargs '{kwargs}'\")\n    with self.connections_lock:\n        result = nr.run(task=task_function, **kwargs)\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/","title":"Nornir Service Test Task","text":"<p>The Nornir Service Test Task is a critical component of NorFab's Nornir service, designed to facilitate the execution of network tests. This task provides network operations engineers and network automation developers with powerful tools to validate network configurations, ensure compliance, and monitor network performance. By leveraging the capabilities of the Nornir service, users can automate the testing process, identify issues proactively, and maintain a robust network infrastructure.</p> <p>Nornir service <code>test</code> task uses Nornir TestsProcessor to run the tests and support test suites definition in YAML format, where test suite YAML files can be stored on and sourced from broker.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#nornir-test-sample-usage","title":"Nornir Test Sample Usage","text":"","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#outputting-test-text-tables","title":"Outputting Test Text Tables","text":"<p>NorFab interactive shell allows you to format the results of network tests into text tables. This is particularly useful for presenting test results in a clear and organized manner, making it easier to analyze and interpret the data. The NorFab interactive shell supports the <code>table</code> command, which relies on the tabulate module to generate text tables. By outputting test results in table format, you can quickly identify issues and take appropriate action.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#using-jinja2-templates","title":"Using Jinja2 Templates","text":"<p>Using Jinja2 Templates enables you to create dynamic test suites based on variables defined in your inventory or passed as job data. This approach allows you to tailor tests to specific devices or scenarios, ensuring that the tests are relevant and accurate. Jinja2 templates provide a powerful way to automate the creation of complex test cases, incorporating conditional logic, loops, and other advanced features to meet your testing requirements.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#templating-tests-with-inline-job-data","title":"Templating Tests with Inline Job Data","text":"<p>Inline Job Data allows you to define test parameters directly within the <code>job_data</code> argument, making it easy to customize tests on the fly. This feature is particularly useful for scenarios where test parameters need to be adjusted frequently or based on specific conditions. By templating tests with inline job data, you can ensure that your tests are always up-to-date and aligned with the current network state.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#using-dry-run","title":"Using Dry Run","text":"<p>The Using Dry Run feature allows you to generate the content of network test suites without actually performing any actions on the devices. This is useful for validation purposes, as it enables you to verify the correctness of your tests before running them. By using dry run, you can identify potential issues and make necessary adjustments, ensuring that your tests will execute successfully when run for real.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#running-a-subset-of-tests","title":"Running a Subset of Tests","text":"<p>Running a Subset of Tests allows you to execute only a specific set of tests, rather than running the entire test suite. This is useful for targeted testing, such as validating changes in a particular part of the network configuration or focusing on specific devices features. By running a subset of tests, you can save time and resources, while still ensuring that critical aspects of the network are thoroughly tested.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#returning-only-failed-tests","title":"Returning Only Failed Tests","text":"<p>Returning only failed tests enables you to filter the test results to show only the tests that have failed. This is particularly useful for quickly identifying and addressing issues, as it allows you to focus on the areas that require attention. By returning only failed tests, you can streamline the troubleshooting process and ensure that network problems are resolved efficiently.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#norfab-nornir-test-shell-reference","title":"NORFAB Nornir Test Shell Reference","text":"<p>The NORFAB Nornir Test Shell Reference provides a comprehensive set of command options for the Nornir <code>test</code> task. These commands allow you to control various aspects of the test execution, such as setting job timeouts, filtering devices, adding task details to results, and configuring retry mechanisms. By leveraging these command options, you can tailor the behavior of the tests to meet your specific network management needs, ensuring that your network remains reliable and performant.</p> <p>NorFab shell supports these command options for Nornir <code>test</code> task:</p> <pre><code>nf#man tree nornir.test\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 test:    Run network tests\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *suite:    Nornir suite nf://path/to/file.py, default 'PydanticUndefined'\n        \u251c\u2500\u2500 dry_run:    Return produced per-host tests suite content without running tests\n        \u251c\u2500\u2500 subset:    Filter tests by name\n        \u251c\u2500\u2500 failed_only:    Return test results for failed tests only\n        \u251c\u2500\u2500 remove_tasks:    Include/Exclude tested task results\n        \u2514\u2500\u2500 job_data:    Path to YAML file with job data\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#python-api-reference","title":"Python API Reference","text":"<p>Function to tests data obtained from devices.</p> <p>Parameters:</p> Name Type Description Default <code>suite</code> <code>Union[list, str]</code> <p>path to YAML file with tests</p> required <code>dry_run</code> <code>bool</code> <p>if True, returns produced per-host tests suite content only</p> <code>False</code> <code>subset</code> <code>str</code> <p>list or string with comma separated non case sensitive glob patterns to filter tests' by name, subset argument ignored by dry run</p> <code>None</code> <code>failed_only</code> <code>bool</code> <p>if True returns test results for failed tests only</p> <code>False</code> <code>remove_tasks</code> <code>bool</code> <p>if False results will include other tasks output</p> <code>True</code> <code>return_tests_suite</code> <code>bool</code> <p>if True returns rendered per-host tests suite content in addition to test results using dictionary with <code>results</code> and <code>suite</code> keys</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>kwargs</code> <p>any additional arguments to pass on to Nornir service task</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def test(\n    self,\n    suite: Union[list, str],\n    subset: str = None,\n    dry_run: bool = False,\n    remove_tasks: bool = True,\n    failed_only: bool = False,\n    return_tests_suite: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to tests data obtained from devices.\n\n    :param suite: path to YAML file with tests\n    :param dry_run: if True, returns produced per-host tests suite content only\n    :param subset: list or string with comma separated non case sensitive glob\n        patterns to filter tests' by name, subset argument ignored by dry run\n    :param failed_only: if True returns test results for failed tests only\n    :param remove_tasks: if False results will include other tasks output\n    :param return_tests_suite: if True returns rendered per-host tests suite\n        content in addition to test results using dictionary with ``results``\n        and ``suite`` keys\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param kwargs: any additional arguments to pass on to Nornir service task\n    \"\"\"\n    tests = {}  # dictionary to hold per-host test suites\n    add_details = kwargs.get(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.get(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:test\", result={} if to_dict else [])\n    suites = {}  # dictionary to hold combined test suites\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        if return_tests_suite is True:\n            ret.result = {\"test_results\": [], \"suite\": {}}\n        return ret\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    # generate per-host test suites\n    for host_name, host in filtered_nornir.inventory.hosts.items():\n        # render suite using Jinja2\n        try:\n            rendered_suite = self.render_jinja2_templates(\n                templates=[suite],\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' Jinja2 rendering failed: '{e}'\"\n            raise RuntimeError(msg)\n        # load suit using YAML\n        try:\n            tests[host_name] = yaml.safe_load(rendered_suite)\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' YAML load failed: '{e}'\"\n            raise RuntimeError(msg)\n\n    # validate tests suite\n    try:\n        _ = modelTestsProcessorSuite(tests=tests)\n    except Exception as e:\n        msg = f\"{self.name} - '{suite}' suite validation failed: '{e}'\"\n        raise RuntimeError(msg)\n\n    # download pattern, schema and custom function files\n    for host_name in tests.keys():\n        for index, item in enumerate(tests[host_name]):\n            for k in [\"pattern\", \"schema\", \"function_file\"]:\n                if self.is_url(item.get(k)):\n                    item[k] = self.fetch_file(\n                        item[k], raise_on_fail=True, read=True\n                    )\n                    if k == \"function_file\":\n                        item[\"function_text\"] = item.pop(k)\n            tests[host_name][index] = item\n\n    # save per-host tests suite content before mutating it\n    if return_tests_suite is True:\n        return_suite = copy.deepcopy(tests)\n\n    log.debug(f\"{self.name} - running test '{suite}', is dry run - '{dry_run}'\")\n    # run dry run task\n    if dry_run is True:\n        result = filtered_nornir.run(\n            task=nr_test, name=\"tests_dry_run\", ret_data_per_host=tests\n        )\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    # combine per-host tests in suites based on task and arguments\n    # Why - to run tests using any nornir service tasks with various arguments\n    else:\n        for host_name, host_tests in tests.items():\n            for test in host_tests:\n                dhash = hashlib.md5()\n                test_args = test.pop(\"norfab\", {})\n                nrtask = test_args.get(\"nrtask\", \"cli\")\n                assert nrtask in [\n                    \"cli\",\n                    \"network\",\n                    \"cfg\",\n                    \"task\",\n                ], f\"{self.name} - unsupported NorFab Nornir Service task '{nrtask}'\"\n                test_json = json.dumps(test_args, sort_keys=True).encode()\n                dhash.update(test_json)\n                test_hash = dhash.hexdigest()\n                suites.setdefault(test_hash, {\"params\": test_args, \"tests\": {}})\n                suites[test_hash][\"tests\"].setdefault(host_name, [])\n                suites[test_hash][\"tests\"][host_name].append(test)\n        log.debug(\n            f\"{self.name} - combined per-host tests suites based on NorFab Nornir Service task and arguments:\\n{suites}\"\n        )\n        # run test suites collecting output from devices\n        for tests_suite in suites.values():\n            nrtask = tests_suite[\"params\"].pop(\"nrtask\", \"cli\")\n            function_kwargs = {\n                **tests_suite[\"params\"],\n                **kwargs,\n                **filters,\n                \"tests\": tests_suite[\"tests\"],\n                \"remove_tasks\": remove_tasks,\n                \"failed_only\": failed_only,\n                \"subset\": subset,\n            }\n            result = getattr(self, nrtask)(\n                **function_kwargs\n            )  # returns Result object\n            # save test results into overall results\n            if to_dict == True:\n                for host_name, host_res in result.result.items():\n                    ret.result.setdefault(host_name, {})\n                    ret.result[host_name].update(host_res)\n            else:\n                ret.result.extend(result.result)\n\n    # check if need to return tests suite content\n    if return_tests_suite is True:\n        ret.result = {\"test_results\": ret.result, \"suite\": return_suite}\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"tags/","title":"Tags","text":"<p>Following is a list of tags:</p>"},{"location":"tags/#nfcli","title":"nfcli","text":"<ul> <li>NFCLI Client API</li> <li>NORFAB Shell</li> </ul>"},{"location":"tags/#norfab","title":"norfab","text":"<ul> <li>Getting Started</li> </ul>"},{"location":"tags/#nornir","title":"nornir","text":"<ul> <li>Overview</li> <li>Jina2 Filters Reference</li> <li>Nornir Cfg</li> <li>Nornir Cli</li> <li>Nornir Diagram</li> <li>Nornir File Copy</li> <li>Nornir Network</li> <li>Nornir Parse</li> <li>Nornir Task</li> <li>Nornir Test</li> </ul>"},{"location":"tags/#robot","title":"robot","text":"<ul> <li>ROBOT Client API</li> <li>ROBOT API</li> </ul>"},{"location":"tags/#services","title":"services","text":"<ul> <li>Services Overview</li> </ul>"}]}
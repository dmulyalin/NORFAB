{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Through lifting others we rise </p>"},{"location":"#network-automations-fabric","title":"Network Automations Fabric","text":"<p>Hi , thank you for getting here.</p>"},{"location":"#why-the-story","title":"Why - The Story","text":"<p>In a world devoid of network automations, the streets were silent  and grey. Without network automations, network engineers' lives  became a grueling cycle of manual configurations and endless  troubleshooting. They spent hours accessing each and every device,  manually configuring and patching systems. Nights were sleepless,  filled with frantic calls to resolve outages that could no longer  be preemptively detected or resolved. Overwhelmed and exhausted,  their innovative spirit was stifled by the sheer volume of  repetitive tasks...</p> <p>Let us introduce you to the world of Network Automations Fabric.</p>"},{"location":"#what-the-idea","title":"What - The Idea","text":"<p>NorFab is a task execution framework focused on network automations.</p> <p>NorFab purpose is to augment network engineers capabilities with  automation superpowers i.e. Iron Man Suite.</p> <p>Most of the solutions to manage networks falls into one of the two  categories: </p> <ul> <li>heavyweight platforms running on dedicated infrastructure</li> <li>lightweight scripts or tools developed and run locally</li> </ul> <p>NorFab can be both - software you can run equally well from your laptop or on a server, centralized or fully distributed,  lightweight and feature reach. Capable of doing any use cases  without the need to throw unreasonable amounts of dollars and  man hours at it. Always ready to serve the purpose of unlocking  engineers superpowers managing modern networks and making  engineers life better.</p>"},{"location":"#how-the-vision","title":"How - The Vision","text":"<ul> <li>Run Anywhere - locally on Windows, MAC or Linux, in a container, on a VM, in the cloud, centralized or distributed</li> <li>Extend Anything - extendability is in the core of NorFab</li> <li>Integrate with Everything - Python API, REST API, CLI northbound interfaces</li> <li>Manage Anything - develop your own services or use built-in to manage your network infrastructure</li> <li>Model and data driven - Pydantic models for API, validation and documentation</li> <li>Automate Anything - we mean it, sky is the limit on what you can do with NorFab automating your networks</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>Key actors of the system include</p> <ul> <li>CLIENTS - consume services, processes that run on client machine and connect to broker</li> <li>BROKER - provides access to services for clients</li> <li>SERVICES - a collection of workers and resources they manage</li> <li>WORKERS - form services, processes that run anywhere and act as resource proxy agents</li> <li>RESOURCES - entities managed by workers, e.g. network devices, databases, file systems</li> </ul> <p>Clients communicate with broker to submit jobs, broker distributes  jobs across workers comprising the service, workers run jobs producing  results retrieved by clients. In other words, Services  hosted by Workers and expose functionality consumed by Clients  via Broker.</p> <p></p>"},{"location":"api_reference_clients_nfcli_client/","title":"NFCLI Client API","text":"","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client--picle-shell-client","title":"PICLE Shell CLient","text":"<p>Client that implements interactive shell to work with NorFab.</p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands","title":"<code>FileServiceCommands</code>","text":"<p>               Bases: <code>BaseModel</code></p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands--sample-usage","title":"Sample Usage","text":"","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands--copy","title":"copy","text":"<p>Copy to client's fetched files directory:</p> <p><code>file copy_ url nf://cli/commands.txt</code></p> <p>Copy file to destination relative to current directory</p> <p><code>file copy_ url nf://cli/commands.txt destination commands.txt</code></p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.FileServiceCommands--list","title":"list","text":"<p>List files at broker root directory:</p> <p><code>file list file list url nf://</code></p> <p>List files details:</p> <pre><code>file details\nfile details url nf://\n</code></pre>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.NorFabShell","title":"<code>NorFabShell</code>","text":"<p>               Bases: <code>BaseModel</code></p>","tags":["nfcli"]},{"location":"api_reference_clients_nfcli_client/#norfab.clients.picle_shell_client.NorFabShell.cmd_preloop_override","title":"<code>cmd_preloop_override()</code>  <code>classmethod</code>","text":"<p>This method called before CMD loop starts</p> Source code in <code>norfab\\clients\\picle_shell_client.py</code> <pre><code>@classmethod\ndef cmd_preloop_override(self):\n    \"\"\"This method called before CMD loop starts\"\"\"\n    pass\n</code></pre>","tags":["nfcli"]},{"location":"api_reference_clients_robot_client/","title":"ROBOT Client API","text":"Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>def __init__(\n    self,\n    inventory=\"./inventory.yaml\",\n    log_level=\"WARNING\",\n):\n    self.ROBOT_LIBRARY_LISTENER = self\n\n    # initiate NorFab\n    self.nf = NorFab(inventory=inventory, log_level=log_level)\n    self.nf.start()\n    self.client = self.nf.make_client()\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.workers","title":"<code>workers(*args, **kwargs)</code>","text":"<p>Collect workers to target</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"Workers\")\ndef workers(self, *args, **kwargs):\n    \"\"\"Collect workers to target\"\"\"\n    if args:\n        DATA[\"workers\"] = args\n    else:\n        DATA[\"workers\"] = kwargs.pop(\"workers\", \"all\")\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.hosts","title":"<code>hosts(*args, **kwargs)</code>","text":"<p>Collect hosts to target</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"Hosts\")\ndef hosts(self, *args, **kwargs):\n    \"\"\"Collect hosts to target\"\"\"\n    if args:\n        DATA[\"hosts\"] = {\"FB\": \", \".join(args), **kwargs}\n    else:\n        DATA[\"hosts\"] = kwargs\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.nr_test","title":"<code>nr_test(*args, **kwargs)</code>","text":"<p>Run nr.test  task</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"nr.test\")\ndef nr_test(self, *args, **kwargs):\n    \"\"\"Run nr.test  task\"\"\"\n    tests_pass = 0\n    tests_fail = 0\n    tests_results = []\n    commands_output = {}\n    if args:\n        kwargs[\"suite\"] = args[0]\n    kwargs = {\n        **DATA.pop(\"hosts\", {\"FB\": \"*\"}),\n        **kwargs,\n        \"remove_tasks\": False,\n        \"add_details\": True,\n        \"return_tests_suite\": True,\n        \"to_dict\": False,\n    }\n    logger.info(f\"Running nr.test with kwargs '{kwargs}', global DATA '{DATA}'\")\n    has_errors = False\n    # run this function\n    ret = self.client.run_job(\n        service=\"nornir\",\n        task=\"test\",\n        workers=DATA.get(\"workers\", \"all\"),\n        kwargs=kwargs,\n    )\n    # iterate over results and log tests and task statuses\n    for worker, worker_results in ret.items():\n        for result in worker_results[\"result\"][\"test_results\"]:\n            host = result[\"host\"]\n            # evaluate and log test result\n            if \"success\" in result:\n                if (\n                    result[\"failed\"]\n                    or result[\"exception\"]\n                    or not result[\"success\"]\n                    or \"traceback\" in str(result[\"result\"]).lower()\n                ):\n                    tests_fail += 1\n                    has_errors = True\n                    logger.error(\n                        (\n                            f'{worker} worker, {host} test \"{result[\"name\"]}\" - '\n                            f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"]}\"&lt;/span&gt;'\n                        ),\n                        html=True,\n                    )\n                else:\n                    tests_pass += 1\n                    logger.info(\n                        (\n                            f'{worker} worker, {host} test \"{result[\"name\"]}\" - '\n                            f'&lt;span style=\"background-color: #97BD61\"&gt;success&lt;/span&gt;'\n                        ),\n                        html=True,\n                    )\n                # save test results to log them later\n                tests_results.append({\"worker\": worker, **result})\n            # evaluate and log task result\n            else:\n                # log exception for task\n                if result[\"failed\"] or result[\"exception\"]:\n                    has_errors = True\n                    logger.error(\n                        (\n                            f'{worker} worker, {host} task \"{result[\"name\"]}\" - '\n                            f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"].strip()}\"&lt;/span&gt;'\n                        ),\n                        html=True,\n                    )\n                # save device commands output to log it later\n                commands_output.setdefault(host, {})\n                commands_output[host][result[\"name\"]] = result[\"result\"]\n    # clear global state to prep for next test\n    clean_global_data()\n\n    tests_results_html_table = TabulateFormatter(\n        tests_results,\n        tabulate={\"tablefmt\": \"html\"},\n        headers=[\n            \"worker\",\n            \"host\",\n            \"name\",\n            \"result\",\n            \"failed\",\n            \"task\",\n            \"test\",\n            \"criteria\",\n            \"exception\",\n        ],\n    )\n\n    tests_results_csv_table = [\n        f'''\"{i['worker']}\",\"{i['host']}\",\"{i['name']}\",\"{i['result']}\",\"{i['failed']}\",\"{i['task']}\",\"{i['test']}\",\"{i['criteria']}\",\"{i['exception']}\"'''\n        for i in tests_results\n    ]\n    tests_results_csv_table.insert(\n        0,\n        '\"worker\",\"host\",\"name\",\"result\",\"failed\",\"task\",\"test\",\"criteria\",\"exception\"',\n    )\n    tests_results_csv_table = \"\\n\".join(tests_results_csv_table)\n\n    # form nested HTML of commands output\n    devices_output_html = []\n    for host in sorted(commands_output.keys()):\n        commands = commands_output[host]\n        commands_output_html = []\n        for command, result in commands.items():\n            commands_output_html.append(\n                f'&lt;p&gt;&lt;details style=\"margin-left:20px;\"&gt;&lt;summary&gt;{command}&lt;/summary&gt;&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result}&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;&lt;/p&gt;'\n            )\n        devices_output_html.append(\n            f'&lt;p&gt;&lt;details&gt;&lt;summary&gt;{host} ({len(commands_output_html)} commands)&lt;/summary&gt;&lt;p&gt;{\"\".join(commands_output_html)}&lt;/p&gt;&lt;/details&gt;&lt;/p&gt;'\n        )\n\n    # form nested HTML for devices tes suite\n    devices_test_suite = []\n    for worker, worker_results in ret.items():\n        for host in sorted(worker_results[\"result\"][\"suite\"].keys()):\n            suite_content = worker_results[\"result\"][\"suite\"][host]\n            devices_test_suite.append(\n                f'&lt;p&gt;&lt;details&gt;&lt;summary&gt;{host} ({len(suite_content)} tests)&lt;/summary&gt;&lt;p style=\"margin-left:20px;\"&gt;{yaml.dump(suite_content, default_flow_style=False)}&lt;/p&gt;&lt;/details&gt;&lt;/p&gt;'\n            )\n\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Workers results&lt;/summary&gt;{pprint.pformat(ret)}&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Test suite results details&lt;/summary&gt;&lt;p&gt;{tests_results_html_table}&lt;/p&gt;&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Test suite results CSV table&lt;/summary&gt;&lt;p&gt;{tests_results_csv_table}&lt;/p&gt;&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Devices tests suites content&lt;/summary&gt;{''.join(devices_test_suite)}&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Collected devices output&lt;/summary&gt;{''.join(devices_output_html)}&lt;/details&gt;\",\n        html=True,\n    )\n    logger.info(\n        (\n            f\"Tests completed - {tests_pass + tests_fail}, \"\n            f'&lt;span style=\"background-color: #97BD61\"&gt;success - {tests_pass}&lt;/span&gt;, '\n            f'&lt;span style=\"background-color: #CE3E01\"&gt;failed - {tests_fail}&lt;/span&gt;'\n        ),\n        html=True,\n    )\n\n    # raise if has errors\n    if has_errors:\n        raise ContinuableFailure(\"Tests failed\")\n    # return test results with no errors in structured format\n    return ret\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.nr_cli","title":"<code>nr_cli(*args, **kwargs)</code>","text":"<p>Run Nornir service cli task</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"nr.cli\")\ndef nr_cli(self, *args, **kwargs):\n    \"\"\"Run Nornir service cli task\"\"\"\n    log.info(\n        f\"Running nr.cli with args '{args}', kwargs '{kwargs}', global DATA '{DATA}'\"\n    )\n    has_errors = False\n    if args:\n        kwargs[\"commands\"] = args\n    kwargs = {\n        **DATA.pop(\"hosts\", {\"FB\": \"*\"}),\n        **kwargs,\n        \"add_details\": True,\n        \"to_dict\": False,\n    }\n    # run this function\n    ret = self.client.run_job(\n        service=\"nornir\",\n        task=\"cli\",\n        workers=DATA.get(\"workers\", \"all\"),\n        kwargs=kwargs,\n    )\n    # extract results for the host\n    for worker, worker_results in ret.items():\n        for result in worker_results[\"result\"]:\n            host = result[\"host\"]\n            # evaluate and log results\n            if (\n                result[\"failed\"]\n                or result[\"exception\"]\n                or \"traceback\" in str(result[\"result\"]).lower()\n            ):\n                has_errors = True\n                logger.error(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, comand \"{result[\"name\"]}\" failed - '\n                        f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"]}\"&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n            else:\n                logger.info(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, command \"{result[\"name\"]}\" - '\n                        f'&lt;span style=\"background-color: #97BD61\"&gt;success&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Workers results&lt;/summary&gt;{pprint.pformat(ret)}&lt;/details&gt;\",\n        html=True,\n    )\n    # clean global state to prep for next test\n    clean_global_data()\n    # raise exception if cli command failed\n    if has_errors:\n        raise ContinuableFailure(ret)\n    # return ret with no errors in structured format\n    return ret\n</code></pre>","tags":["robot"]},{"location":"api_reference_clients_robot_client/#norfab.clients.robot_client.NorFabRobot.nr_cfg","title":"<code>nr_cfg(*args, **kwargs)</code>","text":"<p>Run Nornir service cfg task</p> Source code in <code>norfab\\clients\\robot_client.py</code> <pre><code>@keyword(\"nr.cfg\")\ndef nr_cfg(self, *args, **kwargs):\n    \"\"\"Run Nornir service cfg task\"\"\"\n    log.info(\n        f\"Running nr.cfg with args '{args}', kwargs '{kwargs}', global DATA '{DATA}'\"\n    )\n    if args:\n        kwargs[\"config\"] = args\n    kwargs = {\n        **DATA.pop(\"hosts\", {\"FB\": \"*\"}),\n        **kwargs,\n        \"add_details\": True,\n        \"to_dict\": False,\n    }\n    has_errors = False\n    # run this function\n    ret = self.client.run_job(\n        service=\"nornir\",\n        task=\"cfg\",\n        workers=DATA.get(\"workers\", \"all\"),\n        kwargs=kwargs,\n    )\n    # extract results for the host\n    for worker, worker_results in ret.items():\n        for result in worker_results[\"result\"]:\n            host = result[\"host\"]\n            # evaluate and log results\n            if (\n                result[\"failed\"]\n                or result[\"exception\"]\n                or \"traceback\" in str(result[\"result\"]).lower()\n            ):\n                has_errors = True\n                logger.error(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, \"{result[\"name\"]}\" failed - '\n                        f'&lt;span style=\"background-color: #CE3E01\"&gt;\"{result[\"exception\"]}\"&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n            else:\n                logger.info(\n                    (\n                        f'&lt;details&gt;&lt;summary&gt;{worker} worker, {host} device, \"{result[\"name\"]}\" - '\n                        f'&lt;span style=\"background-color: #97BD61\"&gt;success&lt;/span&gt;&lt;/summary&gt;'\n                        f'&lt;p style=\"margin-left:20px;\"&gt;&lt;font face=\"courier new\"&gt;{result[\"result\"]}'\n                        f\"&lt;/font&gt;&lt;/p&gt;&lt;/details&gt;\"\n                    ),\n                    html=True,\n                )\n    logger.info(\n        f\"&lt;details&gt;&lt;summary&gt;Workers results&lt;/summary&gt;{pprint.pformat(ret)}&lt;/details&gt;\",\n        html=True,\n    )\n    # clean global state to prep for next test\n    clean_global_data()\n    # raise exception if cli command failed\n    if has_errors:\n        raise ContinuableFailure(ret)\n    # return ret with no errors in structured format\n    return ret\n</code></pre>","tags":["robot"]},{"location":"api_reference_core_norfab_broker/","title":"Broker","text":"<p>Majordomo Protocol broker A minimal implementation of http:#rfc.zeromq.org/spec:7 and spec:8</p> <p>Author: Min RK benjaminrk@gmail.com Based on Java example by Arkadiusz Orzechowski</p>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPService","title":"<code>NFPService(name)</code>","text":"<p>               Bases: <code>object</code></p> <p>A single NFP Service</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def __init__(self, name: str):\n    self.name = name  # Service name\n    self.workers = []  # list of known workers\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPWorker","title":"<code>NFPWorker(address, socket, socket_lock, multiplier, keepalive, service=None)</code>","text":"<p>               Bases: <code>object</code></p> <p>An NFP Worker convenience class</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def __init__(\n    self,\n    address: str,\n    socket,\n    socket_lock,\n    multiplier: int,  # e.g. 6 times\n    keepalive: int,  # e.g. 5000 ms\n    service: NFPService = None,\n):\n    self.address = address  # Address to route to\n    self.service = service\n    self.ready = False\n    self.socket = socket\n    self.exit_event = threading.Event()\n    self.keepalive = keepalive\n    self.multiplier = multiplier\n    self.socket_lock = socket_lock\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPWorker.is_ready","title":"<code>is_ready()</code>","text":"<p>True if worker signaled W.READY</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def is_ready(self):\n    \"\"\"True if worker signaled W.READY\"\"\"\n    return self.service is not None and self.ready is True\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPWorker.destroy","title":"<code>destroy(disconnect=False)</code>","text":"<p>Clean up routine</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def destroy(self, disconnect=False):\n    \"\"\"Clean up routine\"\"\"\n    self.exit_event.set()\n    if hasattr(self, \"keepaliver\"):\n        self.keepaliver.stop()\n    self.service.workers.remove(self)\n\n    if disconnect is True:\n        msg = [self.address, b\"\", NFP.WORKER, self.service.name, NFP.DISCONNECT]\n        with self.socket_lock:\n            self.socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker","title":"<code>NFPBroker(endpoint, exit_event, inventory, log_level=None, log_queue=None, multiplier=6, keepalive=2500, init_done_event=None)</code>","text":"<p>NORFAB Protocol broker</p> <p>Parameters:</p> Name Type Description Default <code>log_level</code> <code>str</code> <p>override default log levels</p> <code>None</code> <p>Initialize broker state.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def __init__(\n    self,\n    endpoint: str,\n    exit_event: Event,\n    inventory: NorFabInventory,\n    log_level: str = None,\n    log_queue: object = None,\n    multiplier: int = 6,\n    keepalive: int = 2500,\n    init_done_event: Event = None,\n):\n    \"\"\"Initialize broker state.\"\"\"\n    self.setup_logging(log_queue, log_level)\n    self.keepalive = keepalive\n    self.multiplier = multiplier\n    init_done_event = init_done_event or Event()\n\n    self.services = {}\n    self.workers = {}\n    self.exit_event = exit_event\n    self.inventory = inventory\n\n    self.base_dir = self.inventory.base_dir\n    self.broker_base_dir = os.path.join(\n        self.base_dir, \"__norfab__\", \"files\", \"broker\"\n    )\n    os.makedirs(self.base_dir, exist_ok=True)\n    os.makedirs(self.broker_base_dir, exist_ok=True)\n\n    # generate certificates, create directories and load certs\n    generate_certificates(\n        self.broker_base_dir, cert_name=\"broker\", inventory=inventory\n    )\n    self.private_keys_dir = os.path.join(self.broker_base_dir, \"private_keys\")\n    self.public_keys_dir = os.path.join(self.broker_base_dir, \"public_keys\")\n    self.broker_private_key_file = os.path.join(\n        self.private_keys_dir, \"broker.key_secret\"\n    )\n    self.broker_public_key_file = os.path.join(self.public_keys_dir, \"broker.key\")\n    server_public, server_secret = zmq.auth.load_certificate(\n        self.broker_private_key_file\n    )\n\n    self.ctx = zmq.Context()\n\n    # Start an authenticator for this context.\n    self.auth = ThreadAuthenticator(self.ctx)\n    self.auth.start()\n    # self.auth.allow(\"0.0.0.0\")\n    self.auth.allow_any = True\n    # Tell the authenticator how to handle CURVE requests\n    self.auth.configure_curve(location=zmq.auth.CURVE_ALLOW_ANY)\n\n    self.socket = self.ctx.socket(zmq.ROUTER)\n    self.socket.curve_secretkey = server_secret\n    self.socket.curve_publickey = server_public\n    self.socket.curve_server = True  # must come before bind\n    self.socket.linger = 0\n    self.poller = zmq.Poller()\n    self.poller.register(self.socket, zmq.POLLIN)\n    self.socket.bind(endpoint)\n    self.socket_lock = (\n        threading.Lock()\n    )  # used for keepalives to protect socket object\n\n    init_done_event.set()  # signal finished initializing broker\n    log.debug(f\"NFPBroker - is ready and listening on {endpoint}\")\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.setup_logging","title":"<code>setup_logging(log_queue, log_level)</code>","text":"<p>Method to apply logging configuration</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def setup_logging(self, log_queue, log_level: str) -&gt; None:\n    \"\"\"Method to apply logging configuration\"\"\"\n    logging_config_producer[\"handlers\"][\"queue\"][\"queue\"] = log_queue\n    if log_level is not None:\n        logging_config_producer[\"root\"][\"level\"] = log_level\n    logging.config.dictConfig(logging_config_producer)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.mediate","title":"<code>mediate()</code>","text":"<p>Main broker work happens here</p> <p>Client send messages of this frame format:</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def mediate(self):\n    \"\"\"\n    Main broker work happens here\n\n    Client send messages of this frame format:\n\n\n    \"\"\"\n    while True:\n        try:\n            items = self.poller.poll(self.keepalive)\n        except KeyboardInterrupt:\n            break  # Interrupted\n\n        if items:\n            msg = self.socket.recv_multipart()\n            log.debug(f\"NFPBroker - received '{msg}'\")\n\n            sender = msg.pop(0)\n            empty = msg.pop(0)\n            header = msg.pop(0)\n\n            if header == NFP.CLIENT:\n                self.process_client(sender, msg)\n            elif header == NFP.WORKER:\n                self.process_worker(sender, msg)\n\n        self.purge_workers()\n\n        # check if need to stop\n        if self.exit_event.is_set():\n            self.destroy()\n            break\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.destroy","title":"<code>destroy()</code>","text":"<p>Disconnect all workers, destroy context.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def destroy(self):\n    \"\"\"Disconnect all workers, destroy context.\"\"\"\n    log.info(f\"NFPBroker - interrupt received, killing broker\")\n    for name in list(self.workers.keys()):\n        # in case worker self destroyed while we iterating\n        if self.workers.get(name):\n            self.delete_worker(self.workers[name], True)\n    self.auth.stop()\n    self.ctx.destroy(0)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.delete_worker","title":"<code>delete_worker(worker, disconnect)</code>","text":"<p>Deletes worker from all data structures, and deletes worker.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def delete_worker(self, worker, disconnect):\n    \"\"\"Deletes worker from all data structures, and deletes worker.\"\"\"\n    worker.destroy(disconnect)\n    self.workers.pop(worker.address, None)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.purge_workers","title":"<code>purge_workers()</code>","text":"<p>Look for &amp; delete expired workers.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def purge_workers(self):\n    \"\"\"Look for &amp; delete expired workers.\"\"\"\n    for name in list(self.workers.keys()):\n        # in case worker self destroyed while we iterating\n        if self.workers.get(name):\n            w = self.workers[name]\n        if not w.keepaliver.is_alive():\n            self.delete_worker(w, False)\n            log.info(\n                f\"NFPBroker - {w.address.decode(encoding='utf-8')} worker keepalives expired\"\n            )\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.send_to_worker","title":"<code>send_to_worker(worker, command, sender, uuid, data)</code>","text":"<p>Send message to worker. If message is provided, sends that message.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def send_to_worker(\n    self, worker: NFPWorker, command: bytes, sender: bytes, uuid: bytes, data: bytes\n):\n    \"\"\"Send message to worker. If message is provided, sends that message.\"\"\"\n    # Stack routing and protocol envelopes to start of message\n    if command == NFP.POST:\n        msg = [worker.address, b\"\", NFP.WORKER, NFP.POST, sender, b\"\", uuid, data]\n    elif command == NFP.GET:\n        msg = [worker.address, b\"\", NFP.WORKER, NFP.GET, sender, b\"\", uuid, data]\n    else:\n        log.error(f\"NFPBroker - invalid worker command: {command}\")\n        return\n    with self.socket_lock:\n        log.debug(f\"NFPBroker - sending to worker '{msg}'\")\n        self.socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.send_to_client","title":"<code>send_to_client(client, command, service, message)</code>","text":"<p>Send message to client.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def send_to_client(self, client: str, command: str, service: str, message: list):\n    \"\"\"Send message to client.\"\"\"\n    # Stack routing and protocol envelopes to start of message\n    if command == NFP.RESPONSE:\n        msg = [client, b\"\", NFP.CLIENT, NFP.RESPONSE, service] + message\n    elif command == NFP.EVENT:\n        msg = [client, b\"\", NFP.CLIENT, NFP.EVENT, service] + message\n    else:\n        log.error(f\"NFPBroker - invalid client command: {command}\")\n        return\n    with self.socket_lock:\n        log.debug(f\"NFPBroker - sending to client '{msg}'\")\n        self.socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.process_worker","title":"<code>process_worker(sender, msg)</code>","text":"<p>Process message received from worker.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def process_worker(self, sender, msg):\n    \"\"\"Process message received from worker.\"\"\"\n    command = msg.pop(0)\n    worker = self.require_worker(sender)\n\n    if NFP.READY == command and not worker.is_ready():\n        service = msg.pop(0)\n        worker.service = self.require_service(service)\n        worker.ready = True\n        worker.start_keepalives()\n        worker.service.workers.append(worker)\n    elif NFP.RESPONSE == command and worker.is_ready():\n        client = msg.pop(0)\n        empty = msg.pop(0)\n        self.send_to_client(client, NFP.RESPONSE, worker.service.name, msg)\n    elif NFP.KEEPALIVE == command and hasattr(worker, \"keepaliver\"):\n        worker.keepaliver.received_heartbeat([worker.address] + msg)\n    elif NFP.DISCONNECT == command and worker.is_ready():\n        self.delete_worker(worker, False)\n    elif NFP.EVENT == command and worker.is_ready():\n        client = msg.pop(0)\n        empty = msg.pop(0)\n        self.send_to_client(client, NFP.EVENT, worker.service.name, msg)\n    elif not worker.is_ready():\n        self.delete_worker(worker, disconnect=True)\n    else:\n        log.error(f\"NFPBroker - invalid message: {msg}\")\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.require_worker","title":"<code>require_worker(address)</code>","text":"<p>Finds the worker, creates if necessary.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def require_worker(self, address):\n    \"\"\"Finds the worker, creates if necessary.\"\"\"\n    if not self.workers.get(address):\n        self.workers[address] = NFPWorker(\n            address=address,\n            socket=self.socket,\n            multiplier=self.multiplier,\n            keepalive=self.keepalive,\n            socket_lock=self.socket_lock,\n        )\n        log.info(\n            f\"NFPBroker - registered new worker {address.decode(encoding='utf-8')}\"\n        )\n\n    return self.workers[address]\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.require_service","title":"<code>require_service(name)</code>","text":"<p>Locates the service (creates if necessary).</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def require_service(self, name):\n    \"\"\"Locates the service (creates if necessary).\"\"\"\n    if not self.services.get(name):\n        service = NFPService(name)\n        self.services[name] = service\n        log.debug(\n            f\"NFPBroker - registered new service {name.decode(encoding='utf-8')}\"\n        )\n\n    return self.services[name]\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.process_client","title":"<code>process_client(sender, msg)</code>","text":"<p>Process a request coming from a client.</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def process_client(self, sender, msg):\n    \"\"\"Process a request coming from a client.\"\"\"\n    command = msg.pop(0)\n    service = msg.pop(0)\n    target = msg.pop(0)\n    uuid = msg.pop(0)\n    data = msg.pop(0)\n\n    # check if valid command from client\n    if command not in NFP.client_commands:\n        message = f\"NFPBroker - Unsupported client command '{command}'\"\n        log.error(message)\n        self.send_to_client(\n            sender, NFP.RESPONSE, service, [message.encode(\"utf-8\")]\n        )\n    # Management Interface\n    elif service == b\"mmi.service.broker\":\n        self.mmi_service(sender, command, target, uuid, data)\n    elif service == b\"sid.service.broker\":\n        self.inventory_service(sender, command, target, uuid, data)\n    elif service == b\"fss.service.broker\":\n        self.file_sharing_service(sender, command, target, uuid, data)\n    else:\n        self.dispatch(\n            sender, command, self.require_service(service), target, uuid, data\n        )\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.filter_workers","title":"<code>filter_workers(target, service)</code>","text":"<p>Helper function to filter workers</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>bytes</code> <p>bytest string, workers target</p> required <code>service</code> <code>NFPService</code> <p>NFPService object</p> required Source code in <code>norfab\\core\\broker.py</code> <pre><code>def filter_workers(self, target: bytes, service: NFPService) -&gt; list:\n    \"\"\"\n    Helper function to filter workers\n\n    :param target: bytest string, workers target\n    :param service: NFPService object\n    \"\"\"\n    ret = []\n    if not service.workers:\n        log.warning(\n            f\"NFPBroker - '{service.name}' has no active workers registered, try later\"\n        )\n        ret = []\n    elif target == b\"any\":\n        ret = [service.workers[random.randint(0, len(service.workers) - 1)]]\n    elif target == b\"all\":\n        ret = service.workers\n    elif target in self.workers:  # single worker\n        ret = [self.workers[target]]\n    else:  # target list of workers\n        try:\n            target = json.loads(target)\n            if isinstance(target, list):\n                for w in target:\n                    w = w.encode(\"utf-8\")\n                    if w in self.workers:\n                        ret.append(self.workers[w])\n                ret = list(set(ret))  # dedup workers\n        except Exception as e:\n            log.error(\n                f\"NFPBroker - Failed to load target '{target}' with error '{e}'\"\n            )\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.dispatch","title":"<code>dispatch(sender, command, service, target, uuid, data)</code>","text":"<p>Dispatch requests to waiting workers as possible</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <p>service object</p> required <code>target</code> <p>string indicating workers addresses to dispatch to</p> required <code>msg</code> <p>string with work request content</p> required Source code in <code>norfab\\core\\broker.py</code> <pre><code>def dispatch(self, sender, command, service, target, uuid, data):\n    \"\"\"\n    Dispatch requests to waiting workers as possible\n\n    :param service: service object\n    :param target: string indicating workers addresses to dispatch to\n    :param msg: string with work request content\n    \"\"\"\n    log.debug(\n        f\"NFPBroker - dispatching request to workers: sender '{sender}', \"\n        f\"command '{command}', service '{service.name}', target '{target}'\"\n        f\"data '{data}', uuid '{uuid}'\"\n    )\n    self.purge_workers()\n    workers = self.filter_workers(target, service)\n\n    # handle case when service has no workers registered\n    if not workers:\n        message = f\"NFPBroker - {service.name} service failed to target workers '{target}'\"\n        log.error(message)\n        self.send_to_client(\n            sender,\n            NFP.RESPONSE,\n            service.name,\n            [uuid, b\"400\", message.encode(\"utf-8\")],\n        )\n    else:\n        # inform client that JOB dispatched\n        w_addresses = [w.address.decode(\"utf-8\") for w in workers]\n        self.send_to_client(\n            sender,\n            NFP.RESPONSE,\n            service.name,\n            [\n                uuid,\n                b\"202\",\n                json.dumps(\n                    {\n                        \"workers\": w_addresses,\n                        \"uuid\": uuid.decode(\"utf-8\"),\n                        \"target\": target.decode(\"utf-8\"),\n                        \"status\": \"DISPATCHED\",\n                        \"service\": service.name.decode(\"utf-8\"),\n                    }\n                ).encode(\"utf-8\"),\n            ],\n        )\n        # send job to workers\n        for worker in workers:\n            self.send_to_worker(worker, command, sender, uuid, data)\n</code></pre>"},{"location":"api_reference_core_norfab_broker/#norfab.core.broker.NFPBroker.mmi_service","title":"<code>mmi_service(sender, command, target, uuid, data)</code>","text":"<p>Handle internal service according to 8/MMI specification</p> Source code in <code>norfab\\core\\broker.py</code> <pre><code>def mmi_service(self, sender, command, target, uuid, data):\n    \"\"\"Handle internal service according to 8/MMI specification\"\"\"\n    log.debug(\n        f\"mmi.service.broker - processing request: sender '{sender}', \"\n        f\"command '{command}', target '{target}'\"\n        f\"data '{data}', uuid '{uuid}'\"\n    )\n    data = json.loads(data)\n    task = data.get(\"task\")\n    args = data.get(\"args\", [])\n    kwargs = data.get(\"kwargs\", {})\n    ret = f\"Unsupported task '{task}'\"\n    if task == \"show_workers\":\n        if self.workers:\n            ret = [\n                {\n                    \"name\": w.address.decode(\"utf-8\"),\n                    \"service\": w.service.name.decode(\"utf-8\"),\n                    \"status\": \"alive\" if w.keepaliver.is_alive() else \"dead\",\n                    \"holdtime\": str(w.keepaliver.show_holdtime()),\n                    \"keepalives tx/rx\": f\"{w.keepaliver.keepalives_send} / {w.keepaliver.keepalives_received}\",\n                    \"alive (s)\": str(w.keepaliver.show_alive_for()),\n                }\n                for k, w in self.workers.items()\n            ]\n            # filter reply\n            service = kwargs.get(\"service\")\n            status = kwargs.get(\"status\")\n            if service and service != \"all\":\n                ret = [w for w in ret if w[\"service\"] == service]\n            if status in [\"alive\", \"dead\"]:\n                ret = [w for w in ret if w[\"status\"] == status]\n            if not ret:\n                ret = [{\"name\": \"\", \"service\": \"\", \"status\": \"\"}]\n        else:\n            ret = [{\"name\": \"\", \"service\": \"\", \"status\": \"\"}]\n    elif task == \"show_broker\":\n        ret = {\n            \"endpoint\": self.socket.getsockopt_string(zmq.LAST_ENDPOINT),\n            \"status\": \"active\",\n            \"keepalives\": {\n                \"interval\": self.keepalive,\n                \"multiplier\": self.multiplier,\n            },\n            \"workers count\": len(self.workers),\n            \"services count\": len(self.services),\n            \"directories\": {\n                \"base-dir\": self.base_dir,\n                \"private-keys-dir\": self.private_keys_dir,\n                \"public-keys-dir\": self.public_keys_dir,\n            },\n            \"security\": {\n                \"broker-private-key-file\": self.broker_private_key_file,\n                \"broker-public-key-file\": self.broker_public_key_file,\n            },\n        }\n    elif task == \"show_broker_version\":\n        ret = {\n            \"norfab\": \"\",\n            \"pyyaml\": \"\",\n            \"pyzmq\": \"\",\n            \"psutil\": \"\",\n            \"tornado\": \"\",\n            \"jinja2\": \"\",\n            \"python\": sys.version.split(\" \")[0],\n            \"platform\": sys.platform,\n        }\n        # get version of packages installed\n        for pkg in ret.keys():\n            try:\n                ret[pkg] = importlib.metadata.version(pkg)\n            except importlib.metadata.PackageNotFoundError:\n                pass\n    elif task == \"show_broker_inventory\":\n        ret = self.inventory.dict()\n    reply = json.dumps(ret).encode(\"utf-8\")\n    self.send_to_client(\n        sender, NFP.RESPONSE, b\"mmi.service.broker\", [uuid, b\"200\", reply]\n    )\n</code></pre>"},{"location":"api_reference_core_norfab_client/","title":"Client","text":""},{"location":"api_reference_core_norfab_client/#norfab.core.client--cudos","title":"CUDOS","text":"<p>Inspired by Majordomo Protocol Client API, ZeroMQ, Python version.</p> <p>Original MDP/Client spec</p> <p>Location: http://rfc.zeromq.org/spec:7.</p> <p>Author: Min RK benjaminrk@gmail.com</p> <p>Based on Java example by Arkadiusz Orzechowski</p>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient","title":"<code>NFPClient(inventory, broker, name, exit_event=None, event_queue=None)</code>","text":"<p>               Bases: <code>object</code></p> <p>NORFAB Protocol Client API.</p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <p>str, broker endpoint e.g. tcp://127.0.0.1:5555</p> required <code>name</code> <p>str, client name, default is <code>NFPClient</code></p> required <code>exit_event</code> <p>global exit event signalled by NFAPI</p> <code>None</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def __init__(\n    self,\n    inventory: NorFabInventory,\n    broker,\n    name,\n    exit_event=None,\n    event_queue=None,\n):\n    self.inventory = inventory\n    self.name = name\n    self.zmq_name = f\"{self.name}-{uuid4().hex}\"\n    self.broker = broker\n    self.base_dir = os.path.join(\n        self.inventory.base_dir, \"__norfab__\", \"files\", \"client\", self.name\n    )\n    self.jobs_dir = os.path.join(self.base_dir, \"jobs\")\n    self.events_dir = os.path.join(self.base_dir, \"events\")\n    self.running_job = None\n\n    # create base directories\n    os.makedirs(self.base_dir, exist_ok=True)\n    os.makedirs(self.jobs_dir, exist_ok=True)\n    os.makedirs(self.events_dir, exist_ok=True)\n\n    # generate certificates and create directories\n    generate_certificates(\n        self.base_dir,\n        cert_name=self.name,\n        broker_keys_dir=os.path.join(\n            self.inventory.base_dir, \"__norfab__\", \"files\", \"broker\", \"public_keys\"\n        ),\n        inventory=self.inventory,\n    )\n    self.public_keys_dir = os.path.join(self.base_dir, \"public_keys\")\n    self.private_keys_dir = os.path.join(self.base_dir, \"private_keys\")\n\n    self.ctx = zmq.Context()\n    self.poller = zmq.Poller()\n    self.reconnect_to_broker()\n\n    # create queue file\n    self.queue_filename = os.path.join(self.jobs_dir, f\"{self.name}.jobsqueue.txt\")\n    if not os.path.exists(self.queue_filename):\n        with open(self.queue_filename, \"w\") as f:\n            pass\n\n    self.exit_event = threading.Event() if exit_event is None else exit_event\n    self.destroy_event = (\n        threading.Event()\n    )  # destroy event, used by worker to stop its client\n    self.recv_queue = queue.Queue(maxsize=0)\n    self.event_queue = event_queue or queue.Queue(maxsize=1000)\n\n    # start receive thread\n    self.recv_thread = threading.Thread(\n        target=recv, daemon=True, name=f\"{self.name}_recv_thread\", args=(self,)\n    )\n    self.recv_thread.start()\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient._make_workers","title":"<code>_make_workers(workers)</code>","text":"<p>Helper function to convert workers target to bytes</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def _make_workers(self, workers) -&gt; bytes:\n    \"\"\"Helper function to convert workers target to bytes\"\"\"\n    # transform workers string to bytes\n    if isinstance(workers, str):\n        workers = workers.encode(\"utf-8\")\n    # encode workers names list to list of bytes\n    elif isinstance(workers, list):\n        workers = json.dumps(workers).encode(\"utf-8\")\n\n    return workers\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.reconnect_to_broker","title":"<code>reconnect_to_broker()</code>","text":"<p>Connect or reconnect to broker</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def reconnect_to_broker(self):\n    \"\"\"Connect or reconnect to broker\"\"\"\n    if self.broker_socket:\n        self.poller.unregister(self.broker_socket)\n        self.broker_socket.close()\n\n    self.broker_socket = self.ctx.socket(zmq.DEALER)\n    self.broker_socket.setsockopt_unicode(zmq.IDENTITY, self.zmq_name, \"utf8\")\n    self.broker_socket.linger = 0\n\n    # We need two certificates, one for the client and one for\n    # the server. The client must know the server's public key\n    # to make a CURVE connection.\n    self.client_private_key_file = os.path.join(\n        self.private_keys_dir, f\"{self.name}.key_secret\"\n    )\n    client_public, client_secret = zmq.auth.load_certificate(\n        self.client_private_key_file\n    )\n    self.broker_socket.curve_secretkey = client_secret\n    self.broker_socket.curve_publickey = client_public\n\n    # The client must know the server's public key to make a CURVE connection.\n    self.broker_public_key_file = os.path.join(self.public_keys_dir, \"broker.key\")\n    server_public, _ = zmq.auth.load_certificate(self.broker_public_key_file)\n    self.broker_socket.curve_serverkey = server_public\n\n    self.broker_socket.connect(self.broker)\n    self.poller.register(self.broker_socket, zmq.POLLIN)\n    log.debug(f\"{self.name} - client connected to broker at '{self.broker}'\")\n    self.stats_reconnect_to_broker += 1\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.send_to_broker","title":"<code>send_to_broker(command, service, workers, uuid, request)</code>","text":"<p>Send message to broker.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def send_to_broker(self, command, service, workers, uuid, request):\n    \"\"\"Send message to broker.\"\"\"\n    if command == NFP.POST:\n        msg = [b\"\", NFP.CLIENT, command, service, workers, uuid, request]\n    elif command == NFP.GET:\n        msg = [b\"\", NFP.CLIENT, command, service, workers, uuid, request]\n    else:\n        log.error(\n            f\"{self.name} - cannot send '{command}' to broker, command unsupported\"\n        )\n        return\n\n    log.debug(f\"{self.name} - sending '{msg}'\")\n\n    self.broker_socket.send_multipart(msg)\n    self.stats_send_to_broker += 1\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.rcv_from_broker","title":"<code>rcv_from_broker(command, service, uuid)</code>","text":"<p>Wait for response from broker.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def rcv_from_broker(self, command, service, uuid):\n    \"\"\"Wait for response from broker.\"\"\"\n    retries = 3\n    while retries &gt; 0:\n        # check if need to stop\n        if self.exit_event.is_set() or self.destroy_event.is_set():\n            break\n        try:\n            msg = self.recv_queue.get(block=True, timeout=3)\n            self.recv_queue.task_done()\n        except queue.Empty:\n            if retries:\n                log.warning(\n                    f\"{self.name} - '{uuid}:{service}:{command}' job, \"\n                    f\"no reply from broker '{self.broker}', reconnecting\"\n                )\n                self.reconnect_to_broker()\n            retries -= 1\n            continue\n\n        (\n            empty,\n            reply_header,\n            reply_command,\n            reply_service,\n            reply_uuid,\n            reply_status,\n            reply_task_result,\n        ) = msg\n\n        # find message from recv queue for given uuid\n        if reply_uuid == uuid:\n            assert (\n                reply_header == NFP.CLIENT\n            ), f\"Was expecting client header '{NFP.CLIENT}' received '{reply_header}'\"\n            assert (\n                reply_command == command\n            ), f\"Was expecting reply command '{command}' received '{reply_command}'\"\n            assert (\n                reply_service == service\n            ), f\"Was expecting reply from '{service}' but received reply from '{reply_service}' service\"\n\n            return reply_status, reply_task_result\n        else:\n            self.recv_queue.put(msg)\n    else:\n        log.error(\n            f\"{self.name} - '{uuid}:{service}:{command}' job, \"\n            f\"client {retries} retries attempts exceeded\"\n        )\n        return b\"408\", b'{\"status\": \"Request Timeout\"}'\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.post","title":"<code>post(service, task, args=None, kwargs=None, workers='all', uuid=None, timeout=600)</code>","text":"<p>Send job request to broker.</p> <p>Return dictionary with <code>status</code>, <code>workers</code>, <code>errors</code> keys containing list of workers acknowledged POST request.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def post(\n    self,\n    service: str,\n    task: str,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    uuid: hex = None,\n    timeout: int = 600,\n):\n    \"\"\"\n    Send job request to broker.\n\n    Return dictionary with ``status``, ``workers``, ``errors`` keys\n    containing list of workers acknowledged POST request.\n    \"\"\"\n    uuid = uuid or uuid4().hex\n    args = args or []\n    kwargs = kwargs or {}\n    ret = {\"status\": b\"200\", \"workers\": [], \"errors\": [], \"uuid\": uuid}\n\n    if not isinstance(service, bytes):\n        service = service.encode(\"utf-8\")\n\n    if not isinstance(uuid, bytes):\n        uuid = uuid.encode(\"utf-8\")\n\n    workers = self._make_workers(workers)\n\n    request = json.dumps(\n        {\"task\": task, \"kwargs\": kwargs or {}, \"args\": args or []}\n    ).encode(\"utf-8\")\n\n    # run POST response loop\n    start_time = time.time()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set() or self.destroy_event.is_set():\n            return ret\n        self.send_to_broker(\n            NFP.POST, service, workers, uuid, request\n        )  # 1 send POST to broker\n        status, post_response = self.rcv_from_broker(\n            NFP.RESPONSE, service, uuid\n        )  # 2 receive RESPONSE from broker\n        if status == b\"202\":  # 3 go over RESPONSE status and decide what to do\n            break\n        else:\n            msg = f\"{self.name} - '{uuid}' job, POST Request not accepted by broker '{post_response}'\"\n            log.error(msg)\n            ret[\"errors\"].append(msg)\n            ret[\"status\"] = status\n            return ret\n    else:\n        msg = f\"{self.name} - '{uuid}' job, broker POST Request Timeout\"\n        log.error(msg)\n        ret[\"errors\"].append(msg)\n        ret[\"status\"] = b\"408\"\n        return ret\n\n    # get a list of workers where job was dispatched to\n    post_response = json.loads(post_response)\n    workers_dispatched = set(post_response[\"workers\"])\n    log.debug(\n        f\"{self.name} - broker dispatched job '{uuid}' POST request to workers {workers_dispatched}\"\n    )\n\n    # wait workers to ACK POSTed job\n    start_time = time.time()\n    workers_acked = set()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set() or self.destroy_event.is_set():\n            return ret\n        status, response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n        response = json.loads(response)\n        if status == b\"202\":  # ACCEPTED\n            log.debug(\n                f\"{self.name} - '{uuid}' job, acknowledged by worker '{response}'\"\n            )\n            workers_acked.add(response[\"worker\"])\n            if workers_acked == workers_dispatched:\n                break\n        else:\n            msg = (\n                f\"{self.name} - '{uuid}:{service}:{task}' job, \"\n                f\"unexpected POST request status '{status}', response '{response}'\"\n            )\n            log.error(msg)\n            ret[\"errors\"].append(msg)\n    else:\n        msg = (\n            f\"{self.name} - '{uuid}' job, POST request timeout exceeded, these workers did not \"\n            f\"acknowledge the job {workers_dispatched - workers_acked}\"\n        )\n        log.error(msg)\n        ret[\"errors\"].append(msg)\n        ret[\"status\"] = b\"408\"\n\n    ret[\"workers\"] = list(workers_acked)\n    ret[\"status\"] = ret[\"status\"].decode(\"utf-8\")\n\n    log.debug(f\"{self.name} - '{uuid}' job POST request completed '{ret}'\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.get","title":"<code>get(service, task=None, args=None, kwargs=None, workers='all', uuid=None, timeout=600)</code>","text":"<p>S end job reply message to broker requesting job results.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>mandatory, service name to target</p> required <code>task</code> <code>str</code> <p>mandatory, service task name to run</p> <code>None</code> <code>args</code> <code>list</code> <p>optional, list of position argument for the task</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>optional, dictionary of key-word arguments for the task</p> <code>None</code> <code>workers</code> <code>str</code> <p>optional, workers to target - <code>all</code>, <code>any</code>, or list of workers names</p> <code>'all'</code> <code>uuid</code> <code>hex</code> <p>optional, unique job identifier</p> <code>None</code> <code>timeout</code> <code>int</code> <p>optional, job timeout in seconds, for how long client waits for job result before giving up  Returns dictionary of <code>status</code>, <code>results</code> and <code>errors</code> keys, where <code>results</code> key is a dictionary keyed by workers' names, and <code>errors</code> is a list of error strings.</p> <code>600</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def get(\n    self,\n    service: str,\n    task: str = None,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    uuid: hex = None,\n    timeout: int = 600,\n):\n    \"\"\"S\n    end job reply message to broker requesting job results.\n\n    :param service: mandatory, service name to target\n    :param task: mandatory, service task name to run\n    :param args: optional, list of position argument for the task\n    :param kwargs: optional, dictionary of key-word arguments for the task\n    :param workers: optional, workers to target - ``all``, ``any``, or\n        list of workers names\n    :param uuid: optional, unique job identifier\n    :param timeout: optional, job timeout in seconds, for how long client\n        waits for job result before giving up\n\n    Returns dictionary of ``status``, ``results`` and ``errors`` keys,\n    where ``results`` key is a dictionary keyed by workers' names, and\n    ``errors`` is a list of error strings.\n    \"\"\"\n    uuid = uuid or uuid4().hex\n    args = args or []\n    kwargs = kwargs or {}\n    wkrs = {\n        \"requested\": workers,\n        \"done\": set(),\n        \"dispatched\": set(),\n        \"pending\": set(),\n    }\n    ret = {\"status\": b\"200\", \"results\": {}, \"errors\": [], \"workers\": wkrs}\n\n    if not isinstance(service, bytes):\n        service = service.encode(\"utf-8\")\n\n    if not isinstance(uuid, bytes):\n        uuid = uuid.encode(\"utf-8\")\n\n    workers = self._make_workers(workers)\n\n    request = json.dumps(\n        {\"task\": task, \"kwargs\": kwargs or {}, \"args\": args or []}\n    ).encode(\"utf-8\")\n\n    # run GET response loop\n    start_time = time.time()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set() or self.destroy_event.is_set():\n            return None\n        # dispatch GET request to workers\n        self.send_to_broker(NFP.GET, service, workers, uuid, request)\n        status, get_response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n        ret[\"status\"] = status\n        # received actual GET request results from broker e.g. MMI, SID or FSS services\n        if status == b\"200\":\n            ret[\"results\"] = json.loads(get_response.decode(\"utf-8\"))\n            break\n        # received DISPATCH response from broker\n        if status != b\"202\":\n            msg = f\"{status}, {self.name} job '{uuid}' GET Request not accepted by broker '{get_response}'\"\n            log.error(msg)\n            ret[\"status\"] = status\n            ret[\"errors\"].append(msg)\n            break\n        get_response = json.loads(get_response)\n        wkrs[\"dispatched\"] = set(get_response[\"workers\"])\n        # collect GET responses from individual workers\n        workers_responded = set()\n        while timeout &gt; time.time() - start_time:\n            # check if need to stop\n            if self.exit_event.is_set() or self.destroy_event.is_set():\n                return None\n            status, response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n            log.debug(\n                f\"{self.name} - job '{uuid}' response from worker '{response}'\"\n            )\n            response = json.loads(response)\n            if status == b\"200\":  # OK\n                ret[\"results\"].update(response)\n                log.debug(\n                    f\"{self.name} - job '{uuid}' results returned by worker '{response}'\"\n                )\n                for w in response.keys():\n                    wkrs[\"done\"].add(w)\n                    workers_responded.add(w)\n                    if w in wkrs[\"pending\"]:\n                        wkrs[\"pending\"].remove(w)\n                if wkrs[\"done\"] == wkrs[\"dispatched\"]:\n                    break\n            elif status == b\"300\":  # PENDING\n                # set status to pending if at least one worker is pending\n                ret[\"status\"] = b\"300\"\n                wkrs[\"pending\"].add(response[\"worker\"])\n                workers_responded.add(response[\"worker\"])\n            else:\n                if response.get(\"worker\"):\n                    workers_responded.add(response[\"worker\"])\n                msg = (\n                    f\"{self.name} - '{uuid}:{service}:{task}' job, \"\n                    f\"unexpected GET Response status '{status}', response '{response}'\"\n                )\n                log.error(msg)\n                ret[\"errors\"].append(msg)\n            if workers_responded == wkrs[\"dispatched\"]:\n                break\n        if wkrs[\"done\"] == wkrs[\"dispatched\"]:\n            break\n        time.sleep(0.2)\n    else:\n        msg = f\"{self.name} - '{uuid}' job, broker {timeout}s GET request timeout expired\"\n        log.info(msg)\n        ret[\"errors\"].append(msg)\n        ret[\"status\"] = b\"408\"\n\n    ret[\"status\"] = ret[\"status\"].decode(\"utf-8\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.get_iter","title":"<code>get_iter(service, task, args=None, kwargs=None, workers='all', uuid=None, timeout=600)</code>","text":"<p>Send job reply message to broker requesting job results.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def get_iter(\n    self,\n    service: str,\n    task: str,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    uuid: hex = None,\n    timeout: int = 600,\n):\n    \"\"\"Send job reply message to broker requesting job results.\"\"\"\n    uuid = uuid or uuid4().hex\n    args = args or []\n    kwargs = kwargs or {}\n\n    if not isinstance(service, bytes):\n        service = service.encode(\"utf-8\")\n\n    if not isinstance(uuid, bytes):\n        uuid = uuid.encode(\"utf-8\")\n\n    workers = self._make_workers(workers)\n\n    request = json.dumps(\n        {\"task\": task, \"kwargs\": kwargs or {}, \"args\": args or []}\n    ).encode(\"utf-8\")\n\n    # run GET response loop\n    start_time = time.time()\n    workers_done = set()\n    while timeout &gt; time.time() - start_time:\n        # check if need to stop\n        if self.exit_event.is_set() or self.destroy_event.is_set():\n            break\n        # dispatch GET request to workers\n        self.send_to_broker(NFP.GET, service, workers, uuid, request)\n        status, get_response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n        # received DISPATCH response from broker\n        if status != b\"202\":\n            msg = f\"{status}, {self.name} job '{uuid}' GET Request not accepted by broker '{get_response}'\"\n            log.error(msg)\n            break\n        get_response = json.loads(get_response)\n        workers_dispatched = set(get_response[\"workers\"])\n        # collect GET responses from workers\n        workers_responded = set()\n        while timeout &gt; time.time() - start_time:\n            # check if need to stop\n            if self.exit_event.is_set() or self.destroy_event.is_set():\n                break\n            status, response = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n            log.debug(\n                f\"{self.name} - job '{uuid}' response from worker '{response}'\"\n            )\n            response = json.loads(response)\n            if status == b\"200\":  # OK\n                log.debug(\n                    f\"{self.name} - job '{uuid}' results returned by worker '{response}'\"\n                )\n                yield response\n                for w in response.keys():\n                    workers_done.add(w)\n                    workers_responded.add(w)\n                if workers_done == workers_dispatched:\n                    break\n            elif status == b\"300\":  # PENDING\n                workers_responded.add(response[\"worker\"])\n            else:\n                msg = f\"{self.name} - unexpected GET Response status '{status}', response '{response}'\"\n                log.error(msg)\n                ret[\"errors\"].append(msg)\n            if workers_responded == workers_dispatched:\n                break\n        if workers_done == workers_dispatched:\n            break\n        time.sleep(0.2)\n    else:\n        msg = f\"408, {self.name} job '{uuid}' broker GET Request Timeout\"\n        log.error(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.fetch_file","title":"<code>fetch_file(url, destination=None, chunk_size=250000, pipiline=10, timeout=600, read=False)</code>","text":"<p>Function to download file from Broker File Sharing Service.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>(str), path to file relative to <code>base_dir</code></p> required <code>destination</code> <code>str</code> <p>(str), if provided destination to save file, returns file content otherwise</p> <code>None</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def fetch_file(\n    self,\n    url: str,\n    destination: str = None,\n    chunk_size: int = 250000,\n    pipiline: int = 10,\n    timeout: int = 600,\n    read: bool = False,\n):\n    \"\"\"\n    Function to download file from Broker File Sharing Service.\n\n    :param url: (str), path to file relative to ``base_dir``\n    :param destination: (str), if provided destination to save file,\n        returns file content otherwise\n    \"\"\"\n    uuid = str(uuid4().hex).encode(\"utf-8\")\n    total = 0  # Total bytes received\n    chunks = 0  # Total chunks received\n    offset = 0  # Offset of next chunk request\n    credit = pipiline  # Up to PIPELINE chunks in transit\n    service = b\"fss.service.broker\"\n    workers = b\"any\"\n    reply = \"\"\n    status = \"200\"\n    downloaded = False\n    md5hash = None\n\n    # define file destination\n    if destination is None:\n        destination = os.path.join(\n            self.base_dir, \"fetchedfiles\", *os.path.split(url.replace(\"nf://\", \"\"))\n        )\n\n    # make sure all destination directories exist\n    os.makedirs(os.path.split(destination)[0], exist_ok=True)\n\n    # get file details\n    request = json.dumps({\"task\": \"file_details\", \"kwargs\": {\"url\": url}}).encode(\n        \"utf-8\"\n    )\n    self.send_to_broker(NFP.GET, service, workers, uuid, request)\n    rcv_status, file_details = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n    file_details = json.loads(file_details)\n\n    # check if file already downloaded\n    if os.path.isfile(destination):\n        file_hash = hashlib.md5()\n        with open(destination, \"rb\") as f:\n            chunk = f.read(8192)\n            while chunk:\n                file_hash.update(chunk)\n                chunk = f.read(8192)\n        md5hash = file_hash.hexdigest()\n        downloaded = md5hash == file_details[\"md5hash\"]\n        log.debug(f\"{self.name} - file already downloaded, nothing to do\")\n\n    # fetch file content from broker and save to local file\n    if file_details[\"exists\"] is True and downloaded is False:\n        file_hash = hashlib.md5()\n        with open(destination, \"wb\") as dst_file:\n            start_time = time.time()\n            while timeout &gt; time.time() - start_time:\n                # check if need to stop\n                if self.exit_event.is_set() or self.destroy_event.is_set():\n                    return \"400\", \"\"\n                # ask for chunks\n                while credit:\n                    request = json.dumps(\n                        {\n                            \"task\": \"fetch_file\",\n                            \"kwargs\": {\n                                \"offset\": offset,\n                                \"chunk_size\": chunk_size,\n                                \"url\": url,\n                            },\n                        }\n                    ).encode(\"utf-8\")\n                    self.send_to_broker(NFP.GET, service, workers, uuid, request)\n                    offset += chunk_size\n                    credit -= 1\n                # receive chunks from broker\n                status, chunk = self.rcv_from_broker(NFP.RESPONSE, service, uuid)\n                log.debug(\n                    f\"{self.name} - status '{status}', chunk '{chunks}', downloaded '{total}'\"\n                )\n                dst_file.write(chunk)\n                file_hash.update(chunk)\n                chunks += 1\n                credit += 1\n                size = len(chunk)\n                total += size\n                if size &lt; chunk_size:\n                    break  # Last chunk received; exit\n            else:\n                reply = \"File download failed - timeout\"\n                status = \"408\"\n        # verify md5hash\n        md5hash = file_hash.hexdigest()\n    elif file_details[\"exists\"] is False:\n        reply = \"File download failed - file not found\"\n        status = \"404\"\n\n    # decide on what to reply and status\n    if file_details[\"exists\"] is not True:\n        reply = reply\n    elif md5hash != file_details[\"md5hash\"]:\n        reply = \"File download failed - MD5 hash mismatch\"\n        status = \"417\"\n    elif read:\n        with open(destination, \"r\", encoding=\"utf-8\") as f:\n            reply = f.read()\n    else:\n        reply = destination\n    # decode status\n    if isinstance(status, bytes):\n        status = status.decode(\"utf-8\")\n\n    return status, reply\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.run_job","title":"<code>run_job(service, task, uuid=None, args=None, kwargs=None, workers='all', timeout=600, retry=10)</code>","text":"<p>Run job and return results produced by workers.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>str, service name to send request to</p> required <code>task</code> <code>str</code> <p>str, task name to run for given service</p> required <code>uuid</code> <code>str</code> <p>(str) Job ID to use</p> <code>None</code> <code>args</code> <code>list</code> <p>list, task arguments</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>dict, task key-word arguments</p> <code>None</code> <code>workers</code> <code>str</code> <p>str or list, worker names to target</p> <code>'all'</code> <code>timeout</code> <code>int</code> <p>overall job timeout in seconds</p> <code>600</code> <code>retry</code> <p>number of times to try and GET job results</p> <code>10</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def run_job(\n    self,\n    service: str,\n    task: str,\n    uuid: str = None,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    timeout: int = 600,\n    retry=10,\n):\n    \"\"\"\n    Run job and return results produced by workers.\n\n    :param service: str, service name to send request to\n    :param task: str, task name to run for given service\n    :param uuid: (str) Job ID to use\n    :param args: list, task arguments\n    :param kwargs: dict, task key-word arguments\n    :param workers: str or list, worker names to target\n    :param timeout: overall job timeout in seconds\n    :param retry: number of times to try and GET job results\n    \"\"\"\n    self.running_job = True\n    uuid = uuid or uuid4().hex\n    start_time = int(time.time())\n    ret = None\n\n    # POST job to workers\n    post_result = self.post(service, task, args, kwargs, workers, uuid, timeout)\n    if post_result[\"status\"] != \"200\":\n        log.error(\n            f\"{self.name}:run_job - {service}:{task} POST status \"\n            f\"to '{workers}' workers is not 200 - '{post_result}'\"\n        )\n        self.running_job = False\n        return ret\n\n    remaining_timeout = timeout - (time.time() - start_time)\n    get_timeout = remaining_timeout / retry\n\n    # GET job results\n    while retry:\n        get = self.get(\n            service, task, [], {}, post_result[\"workers\"], uuid, get_timeout\n        )\n        if self.exit_event.is_set() or self.destroy_event.is_set():\n            break\n        elif get[\"status\"] == \"300\":  # PENDING\n            retry -= 1\n            log.debug(\n                f\"{self.name}:run_job - {service}:{task}:{uuid} GET \"\n                f\"results pending, keep waiting\"\n            )\n            continue\n        elif get[\"status\"] == \"408\":  # TIMEOUT\n            retry -= 1\n            log.debug(\n                f\"{self.name}:run_job - {service}:{task}:{uuid} GET \"\n                f\"results {get_timeout}s timeout expired, keep waiting\"\n            )\n            continue\n        elif get[\"status\"] in [\"200\", \"202\"]:  # OK\n            ret = get[\"results\"]\n            break\n        else:\n            log.error(\n                f\"{self.name}:run_job - {service}:{task}:{uuid} \"\n                f\"stopping, GET returned unexpected results - '{get}'\"\n            )\n            break\n    else:\n        log.error(\n            f\"{self.name}:run_job - {service}:{task}:{uuid} \"\n            f\"retry exceeded, GET returned no results, timeout {timeout}s\"\n        )\n    self.running_job = False\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.NFPClient.run_job_iter","title":"<code>run_job_iter(service, task, uuid=None, args=None, kwargs=None, workers='all', timeout=600)</code>","text":"<p>Iter run_job allows to return job results from workers progressively as they are responded, rather than waiting for workers to respond first. This should allow to client an interactive experience for the user where job results would be presented as soon as they are available.</p> <p>Parameters:</p> Name Type Description Default <code>service</code> <code>str</code> <p>str, service name to send request to</p> required <code>task</code> <code>str</code> <p>str, task name to run for given service</p> required <code>uuid</code> <code>str</code> <p>(str) Job ID to use</p> <code>None</code> <code>args</code> <code>list</code> <p>list, task arguments</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>dict, task key-word arguments</p> <code>None</code> <code>workers</code> <code>str</code> <p>str or list, worker names to target</p> <code>'all'</code> Source code in <code>norfab\\core\\client.py</code> <pre><code>def run_job_iter(\n    self,\n    service: str,\n    task: str,\n    uuid: str = None,\n    args: list = None,\n    kwargs: dict = None,\n    workers: str = \"all\",\n    timeout: int = 600,\n):\n    \"\"\"\n    Iter run_job allows to return job results from workers progressively\n    as they are responded, rather than waiting for workers to respond first.\n    This should allow to client an interactive experience for the user where\n    job results would be presented as soon as they are available.\n\n    :param service: str, service name to send request to\n    :param task: str, task name to run for given service\n    :param uuid: (str) Job ID to use\n    :param args: list, task arguments\n    :param kwargs: dict, task key-word arguments\n    :param workers: str or list, worker names to target\n    \"\"\"\n    self.running_job = True\n    uuid = uuid or uuid4().hex\n\n    # POST job to workers\n    post_result = self.post(service, task, args, kwargs, workers, uuid, timeout)\n\n    # GET job results\n    for result in self.get_iter(\n        service, task, [], {}, post_result[\"workers\"], uuid, timeout\n    ):\n        yield result\n\n    self.running_job = False\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.event_filename","title":"<code>event_filename(suuid, events_dir)</code>","text":"<p>Returns freshly allocated event filename for given UUID str</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def event_filename(suuid: str, events_dir: str):\n    \"\"\"Returns freshly allocated event filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(events_dir, f\"{suuid}.json\")\n</code></pre>"},{"location":"api_reference_core_norfab_client/#norfab.core.client.recv","title":"<code>recv(client)</code>","text":"<p>Thread to process receive messages from broker.</p> Source code in <code>norfab\\core\\client.py</code> <pre><code>def recv(client):\n    \"\"\"Thread to process receive messages from broker.\"\"\"\n    while not client.exit_event.is_set():\n        # Poll socket for messages every timeout interval\n        try:\n            items = client.poller.poll(1000)\n        except KeyboardInterrupt:\n            break  # Interrupted\n        except:\n            continue\n        if items:\n            msg = client.broker_socket.recv_multipart()\n            log.debug(f\"{client.name} - received '{msg}'\")\n            if msg[2] == NFP.EVENT:\n                client.event_queue.put(msg)\n                client.stats_recv_event_from_broker += 1\n            else:\n                client.recv_queue.put(msg)\n                client.stats_recv_from_broker += 1\n</code></pre>"},{"location":"api_reference_core_norfab_exceptions/","title":"Exceptions","text":""},{"location":"api_reference_core_norfab_exceptions/#norfab.core.exceptions.UnsupportedPluginError","title":"<code>UnsupportedPluginError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when specified plugin not supported</p>"},{"location":"api_reference_core_norfab_exceptions/#norfab.core.exceptions.UnsupportedServiceError","title":"<code>UnsupportedServiceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when specified service not supported</p>"},{"location":"api_reference_core_norfab_exceptions/#norfab.core.exceptions.NorfabJobFailedError","title":"<code>NorfabJobFailedError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when job failed</p>"},{"location":"api_reference_core_norfab_nfapi/","title":"NFAPI (Python API)","text":"<p>Utility class to implement Python API for interfacing with NorFab.</p> <p>NorFab Python API Client initialization class</p> <pre><code>from norfab.core.nfapi import NorFab\n\nnf = NorFab(inventory=\"./inventory.yaml\")\nnf.start(start_broker=True, workers=[\"my-worker-1\"])\nNFCLIENT = nf.make_client()\n</code></pre> <p>or using dictionary data</p> <pre><code>from norfab.core.nfapi import NorFab\n\ndata = {\n    'broker': {'endpoint': 'tcp://127.0.0.1:5555'},\n    'workers': {'my-worker-1': ['workers/common.yaml'],\n}\n\nnf = NorFab(inventory_data=data, base_dir=\"./\")\nnf.start(start_broker=True, workers=[\"my-worker-1\"])\nNFCLIENT = nf.make_client()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>inventory</code> <code>str</code> <p>OS path to NorFab inventory YAML file</p> <code>'./inventory.yaml'</code> <code>inventory_data</code> <code>dict</code> <p>dictionary with NorFab inventory</p> <code>None</code> <code>base_dir</code> <code>str</code> <p>OS path to base directory to anchor NorFab at</p> <code>None</code> <code>log_level</code> <code>str</code> <p>one or supported logging levels - <code>CRITICAL</code>, <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code></p> <code>None</code> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def __init__(\n    self,\n    inventory: str = \"./inventory.yaml\",\n    inventory_data: dict = None,\n    base_dir: str = None,\n    log_level: str = None,\n) -&gt; None:\n    \"\"\"\n    NorFab Python API Client initialization class\n\n    ```\n    from norfab.core.nfapi import NorFab\n\n    nf = NorFab(inventory=\"./inventory.yaml\")\n    nf.start(start_broker=True, workers=[\"my-worker-1\"])\n    NFCLIENT = nf.make_client()\n    ```\n\n    or using dictionary data\n\n    ```\n    from norfab.core.nfapi import NorFab\n\n    data = {\n        'broker': {'endpoint': 'tcp://127.0.0.1:5555'},\n        'workers': {'my-worker-1': ['workers/common.yaml'],\n    }\n\n    nf = NorFab(inventory_data=data, base_dir=\"./\")\n    nf.start(start_broker=True, workers=[\"my-worker-1\"])\n    NFCLIENT = nf.make_client()\n    ```\n\n    :param inventory: OS path to NorFab inventory YAML file\n    :param inventory_data: dictionary with NorFab inventory\n    :param base_dir: OS path to base directory to anchor NorFab at\n    :param log_level: one or supported logging levels - `CRITICAL`, `ERROR`, `WARNING`, `INFO`, `DEBUG`\n    \"\"\"\n    self.exiting = False  # flag to signal that Norfab is exiting\n    self.inventory = NorFabInventory(\n        path=inventory, data=inventory_data, base_dir=base_dir\n    )\n    self.log_queue = Queue()\n    self.log_level = log_level\n    self.broker_endpoint = self.inventory.broker[\"endpoint\"]\n    self.workers_init_timeout = self.inventory.topology.get(\n        \"workers_init_timeout\", 300\n    )\n    self.broker_exit_event = Event()\n    self.workers_exit_event = Event()\n    self.clients_exit_event = Event()\n\n    # create needed folders to kickstart the logs\n    os.makedirs(\n        os.path.join(self.inventory.base_dir, \"__norfab__\", \"files\"), exist_ok=True\n    )\n    os.makedirs(\n        os.path.join(self.inventory.base_dir, \"__norfab__\", \"logs\"), exist_ok=True\n    )\n\n    self.setup_logging()\n    signal.signal(signal.SIGINT, self.handle_ctrl_c)\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.start","title":"<code>start(start_broker=True, workers=True)</code>","text":"<p>Main entry method to start NorFab components.</p> <p>Parameters:</p> Name Type Description Default <code>start_broker</code> <code>bool</code> <p>if True, starts broker process as defined in inventory <code>topology</code> section</p> <code>True</code> <code>workers</code> <code>Union[bool, list]</code> <p>list of worker names to start processes for or boolean, if True starts all workers defined in inventory <code>topology</code> sections</p> <code>True</code> <code>client</code> <p>If true return and instance of NorFab client</p> required Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def start(\n    self,\n    start_broker: bool = True,\n    workers: Union[bool, list] = True,\n) -&gt; None:\n    \"\"\"\n    Main entry method to start NorFab components.\n\n    :param start_broker: if True, starts broker process as defined in inventory\n        ``topology`` section\n    :param workers: list of worker names to start processes for or boolean, if True\n        starts all workers defined in inventory ``topology`` sections\n    :param client: If true return and instance of NorFab client\n    \"\"\"\n    workers_to_start = set()\n\n    # start the broker\n    if start_broker is True and self.inventory.topology.get(\"broker\") is True:\n        self.start_broker()\n\n    # decide on a set of workers to start\n    if workers is False or workers is None:\n        workers = []\n    elif isinstance(workers, list) and workers:\n        workers = [w.strip() for w in workers if w.strip()]\n    # start workers defined in inventory\n    elif workers is True:\n        workers = self.inventory.topology.get(\"workers\", [])\n\n    # exit if no workers\n    if not workers:\n        return\n\n    # form a list of workers to start\n    for worker_name in workers:\n        if isinstance(worker_name, dict):\n            worker_name = tuple(worker_name)[0]\n        if worker_name:\n            workers_to_start.add(worker_name)\n        else:\n            log.error(f\"'{worker_name}' - worker name is bad, skipping..\")\n            continue\n\n    while workers_to_start != set(self.workers_processes.keys()):\n        for worker in workers:\n            # extract worker name and data/params\n            if isinstance(worker, dict):\n                worker_name = tuple(worker)[0]\n                worker_data = worker[worker_name]\n            elif worker:\n                worker_name = worker\n                worker_data = {}\n            else:\n                continue\n            # verify if need to start this worker\n            if worker_name not in workers_to_start:\n                continue\n            # start worker\n            try:\n                self.start_worker(worker_name, worker_data)\n            # if failed to start remove from workers to start\n            except KeyError:\n                workers_to_start.discard(worker_name)\n                log.error(\n                    f\"'{worker_name}' - failed to start worker, no inventory data found\"\n                )\n            except FileNotFoundError as e:\n                workers_to_start.discard(worker_name)\n                log.error(\n                    f\"'{worker_name}' - failed to start worker, inventory file not found '{e}'\"\n                )\n            except Exception as e:\n                workers_to_start.discard(worker_name)\n                log.exception(\n                    f\"'{worker_name}' - failed to start worker, error '{e}'\"\n                )\n\n        time.sleep(0.01)\n\n    # wait for workers to initialize\n    start_time = time.time()\n    while self.workers_init_timeout &gt; time.time() - start_time:\n        if all(w[\"init_done\"].is_set() for w in self.workers_processes.values()):\n            break\n    else:\n        log.error(\n            f\"TimeoutError - {self.workers_init_timeout}s workers init timeout expired\"\n        )\n        self.destroy()\n\n    # run startup hooks\n    for f in self.inventory.hooks.get(\"startup\", []):\n        f[\"function\"](self, *f.get(\"args\", []), **f.get(\"kwargs\", {}))\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.run","title":"<code>run()</code>","text":"<p>Helper method to run the loop before CTRL+C called</p> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def run(self):\n    \"\"\"\n    Helper method to run the loop before CTRL+C called\n    \"\"\"\n    if not self.broker and not self.workers_processes:\n        log.critical(\n            f\"NorFab detected no broker or worker processes running, exiting..\"\n        )\n        return\n\n    while self.exiting is False:\n        time.sleep(0.1)\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.destroy","title":"<code>destroy()</code>","text":"<p>Stop NORFAB processes.</p> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def destroy(self) -&gt; None:\n    \"\"\"\n    Stop NORFAB processes.\n    \"\"\"\n    # run exit hooks\n    for f in self.inventory.hooks.get(\"exit\", []):\n        f[\"function\"](self, *f.get(\"args\", []), **f.get(\"kwargs\", {}))\n\n    if self.exiting is not True:\n        self.exiting = True  # indicate that NorFab already exiting\n        # stop client\n        log.info(\"NorFab is exiting, stopping clients\")\n        self.clients_exit_event.set()\n        if self.client:\n            self.client.destroy()\n        # stop workers\n        log.info(\"NorFab is exiting, stopping workers\")\n        self.workers_exit_event.set()\n        while self.workers_processes:\n            wname, w = self.workers_processes.popitem()\n            w[\"process\"].join()\n            log.info(f\"NorFab is exiting, stopped {wname} worker\")\n        # stop broker\n        log.info(\"NorFab is exiting, stopping broker\")\n        self.broker_exit_event.set()\n        if self.broker:\n            self.broker.join()\n        # stop logging thread\n        log.info(\"NorFab is exiting, stopping logging queue listener\")\n        self.log_listener.stop()\n</code></pre>"},{"location":"api_reference_core_norfab_nfapi/#norfab.core.nfapi.NorFab.make_client","title":"<code>make_client(broker_endpoint=None)</code>","text":"<p>Make an instance of NorFab client</p> <p>Parameters:</p> Name Type Description Default <code>broker_endpoint</code> <code>str</code> <p>(str), Broker URL to connect with</p> <code>None</code> Source code in <code>norfab\\core\\nfapi.py</code> <pre><code>def make_client(self, broker_endpoint: str = None) -&gt; NFPClient:\n    \"\"\"\n    Make an instance of NorFab client\n\n    :param broker_endpoint: (str), Broker URL to connect with\n    \"\"\"\n\n    if broker_endpoint or self.broker_endpoint:\n        client = NFPClient(\n            self.inventory,\n            broker_endpoint or self.broker_endpoint,\n            \"NFPClient\",\n            self.clients_exit_event,\n        )\n        if self.client is None:  # own the first client\n            self.client = client\n        return client\n    else:\n        log.error(\"Failed to make client, no broker endpoint defined\")\n        return None\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/","title":"Simple Inventory","text":"<p>Simple Local Inventory is an inventory plugin to load  inventory data from locally stored files.</p> <p>Sample inventory file</p> <pre><code>broker:\n  endpoint: \"tcp://127.0.0.1:5555\"\n\nlogging:\n  handlers:\n    terminal:\n      level: CRITICAL\n    file: \n      level: DEBUG\n\nworkers:\n  nornir-*:\n    - nornir/common.yaml  \n  nornir-worker-1:\n    - nornir/nornir-worker-1.yaml\n\ntopology:\n  broker: True\n  workers:\n    - nornir-worker-1\n</code></pre> <p>where <code>nornir/common.yaml</code> contains</p> <pre><code>service: nornir\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\nrunner:\n  plugin: RetryRunner\n  options: \n    num_workers: 100\n    num_connectors: 10\n    connect_retry: 3\n    connect_backoff: 1000\n    connect_splay: 100\n    task_retry: 3\n    task_backoff: 1000\n    task_splay: 100\n    reconnect_on_fail: True\n    task_timeout: 600\n</code></pre> <p>and <code>nornir/nornir-worker-1.yaml</code> contains</p> <pre><code>hosts: \n  csr1000v-1:\n    hostname: sandbox-1.lab.com\n    platform: cisco_ios\n    username: developer\n    password: secretpassword\n  csr1000v-2:\n    hostname: sandbox-2.lab.com\n    platform: cisco_ios\n    username: developer\n    password: secretpassword\ngroups: {}\ndefaults: {}\n</code></pre> <p>Whenever inventory queried to provide data for worker with name <code>nornir-worker-1</code> Simple Inventory iterates over <code>workers</code> dictionary and recursively merges  data for keys (glob patterns) that matched worker name.</p>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.WorkersInventory","title":"<code>WorkersInventory(path, data)</code>","text":"<p>Class to collect and server NorFab workers inventory data, forming it by recursively merging all data files that associated with the name of worker requesting inventory data.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>OS path to top folder with workers inventory data</p> required <code>data</code> <code>dict</code> <p>dictionary keyed by glob patterns matching workers names and values being a list of OS paths to files or dictionaries with workers inventory data</p> required Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def __init__(self, path: str, data: dict) -&gt; None:\n    \"\"\"\n    Class to collect and server NorFab workers inventory data,\n    forming it by recursively merging all data files that associated\n    with the name of worker requesting inventory data.\n\n    :param path: OS path to top folder with workers inventory data\n    :param data: dictionary keyed by glob patterns matching workers names\n        and values being a list of OS paths to files or dictionaries with workers\n        inventory data\n    \"\"\"\n    self.path = path\n    self.data = data\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.NorFabInventory","title":"<code>NorFabInventory(path=None, data=None, base_dir=None)</code>","text":"<p>NorFabInventory class to instantiate simple inventory either from file or from dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>OS path to YAML file with inventory data</p> <code>None</code> <code>data</code> <code>dict</code> <p>NorFab inventory dictionary</p> <code>None</code> Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def __init__(\n    self, path: str = None, data: dict = None, base_dir: str = None\n) -&gt; None:\n    \"\"\"\n    NorFabInventory class to instantiate simple inventory either\n    from file or from dictionary.\n\n    :param path: OS path to YAML file with inventory data\n    :param data: NorFab inventory dictionary\n    \"\"\"\n    self.broker = {}\n    self.workers = {}\n    self.topology = {}\n    self.logging = {}\n    self.hooks = {}\n\n    if data:\n        self.base_dir = base_dir or os.path.split(os.getcwd())[0]\n        self.load_data(data)\n    elif path:\n        path = os.path.abspath(path)\n        self.base_dir = base_dir or os.path.split(path)[0]\n        self.load_path(path)\n    else:\n        raise RuntimeError(\n            \"Either path to inventory.yaml or inventory data dictionary must be provided.\"\n        )\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.NorFabInventory.dict","title":"<code>dict()</code>","text":"<p>Return serialized dictionary of inventory</p> Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def dict(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Return serialized dictionary of inventory\n    \"\"\"\n    return {\n        \"broker\": self.broker,\n        \"workers\": self.workers.data,\n        \"topology\": self.topology,\n        \"logging\": self.logging,\n        \"hooks\": {\n            \"startup\": [\n                {**i, \"function\": i[\"function\"].__name__}\n                for i in self.hooks[\"startup\"]\n            ],\n            \"exit\": [\n                {**i, \"function\": i[\"function\"].__name__}\n                for i in self.hooks[\"exit\"]\n            ],\n        },\n    }\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.make_logging_config","title":"<code>make_logging_config(base_dir, inventory)</code>","text":"<p>Helper function to combine inventory logging section and logging_config_listener dictionary.</p> Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def make_logging_config(base_dir: str, inventory: dict) -&gt; dict:\n    \"\"\"\n    Helper function to combine inventory logging section and\n    logging_config_listener dictionary.\n    \"\"\"\n    logging_config_listener[\"handlers\"][\"file\"][\"filename\"] = os.path.join(\n        base_dir, \"__norfab__\", \"logs\", \"norfab.log\"\n    )\n\n    if not inventory:\n        return logging_config_listener\n\n    log_cfg = copy.deepcopy(inventory)\n    ret = copy.deepcopy(logging_config_listener)\n\n    # merge handlers\n    ret[\"handlers\"][\"terminal\"].update(log_cfg.get(\"handlers\", {}).pop(\"terminal\", {}))\n    ret[\"handlers\"][\"file\"].update(log_cfg.get(\"handlers\", {}).pop(\"file\", {}))\n    ret[\"handlers\"].update(log_cfg.pop(\"handlers\", {}))\n    # merge formatters\n    ret[\"formatters\"][\"default\"].update(\n        log_cfg.get(\"formatters\", {}).pop(\"default\", {})\n    )\n    ret[\"formatters\"].update(log_cfg.pop(\"formatters\", {}))\n    # merge root logger\n    ret[\"root\"].update(log_cfg.pop(\"root\", {}))\n    if \"file\" not in ret[\"root\"][\"handlers\"]:\n        ret[\"root\"][\"handlers\"].append(\"file\")\n    if \"terminal\" not in ret[\"root\"][\"handlers\"]:\n        ret[\"root\"][\"handlers\"].append(\"terminal\")\n    # merge remaining config\n    ret.update(log_cfg)\n    ret[\"disable_existing_loggers\"] = False\n\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.merge_recursively","title":"<code>merge_recursively(data, merge)</code>","text":"<p>Function to merge two dictionaries data recursively.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>primary dictionary</p> required <code>merge</code> <code>dict</code> <p>dictionary to merge into primary overriding the content</p> required Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def merge_recursively(data: dict, merge: dict) -&gt; None:\n    \"\"\"\n    Function to merge two dictionaries data recursively.\n\n    :param data: primary dictionary\n    :param merge: dictionary to merge into primary overriding the content\n    \"\"\"\n    assert isinstance(data, dict) and isinstance(\n        merge, dict\n    ), f\"Only supports dictionary/dictionary data merges, not {type(data)}/{type(merge)}\"\n    for k, v in merge.items():\n        if k in data:\n            # merge two lists\n            if isinstance(data[k], list) and isinstance(v, list):\n                for i in v:\n                    if i not in data[k]:\n                        data[k].append(i)\n            # recursively merge dictionaries\n            elif isinstance(data[k], dict) and isinstance(v, dict):\n                merge_recursively(data[k], v)\n            # rewrite existing value with new data\n            else:\n                data[k] = v\n        else:\n            data[k] = v\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.make_hooks","title":"<code>make_hooks(base_dir, hooks)</code>","text":"<p>Function to load hook functions</p> Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def make_hooks(base_dir, hooks):\n    \"\"\"\n    Function to load hook functions\n    \"\"\"\n    ret = {\"startup\": [], \"exit\": []}\n\n    # make sure to include current and base_dir directories in search path\n    if os.getcwd() not in sys.path:\n        sys.path.append(os.getcwd())\n    if base_dir not in sys.path:\n        sys.path.append(base_dir)\n\n    # load hook functions one by one\n    for item in hooks:\n        try:\n            *imp_str, hook_function_name = item[\"function\"].split(\".\")\n            imp_str = \".\".join(imp_str)\n            log.info(f\"Importing hook '{imp_str}' function '{hook_function_name}'\")\n            hook_module = __import__(imp_str, fromlist=[\"\"])\n            item[\"function\"] = getattr(hook_module, hook_function_name)\n            ret[item.pop(\"attachpoint\")].append(item)\n            log.info(f\"Successfully loaded hook function {item['function']}\")\n        except Exception as e:\n            log.exception(f\"Failed loading hook {item}\")\n\n    return ret\n</code></pre>"},{"location":"api_reference_core_norfab_simple_inventory/#norfab.core.inventory.render_jinja2_template","title":"<code>render_jinja2_template(template, context=None, filters=None)</code>","text":"<p>Helper function to render a list of Jinja2 template.</p> <p>Parameters:</p> Name Type Description Default <code>templates</code> <p>list of template strings to render</p> required <code>context</code> <code>dict</code> <p>Jinja2 context dictionary</p> <code>None</code> <code>filter</code> <p>custom Jinja2 filters</p> required <p>Returns:</p> Type Description <code>str</code> <p>list of rendered strings</p> Source code in <code>norfab\\core\\inventory.py</code> <pre><code>def render_jinja2_template(\n    template: str, context: dict = None, filters: dict = None\n) -&gt; str:\n    \"\"\"\n    Helper function to render a list of Jinja2 template.\n\n    :param templates: list of template strings to render\n    :param context: Jinja2 context dictionary\n    :param filter: custom Jinja2 filters\n    :returns: list of rendered strings\n    \"\"\"\n    rendered = \"\"\n    filters = filters or {}\n    context = context or {}\n\n    # get OS environment variables\n    context[\"env\"] = {k: v for k, v in os.environ.items()}\n\n    # render template\n    j2env = Environment(loader=\"BaseLoader\")\n    j2env.filters.update(filters)  # add custom filters\n    renderer = j2env.from_string(template)\n    rendered = renderer.render(**context)\n\n    return rendered\n</code></pre>"},{"location":"api_reference_core_norfab_worker/","title":"Worker","text":""},{"location":"api_reference_core_norfab_worker/#norfab.core.worker--cudos","title":"CUDOS","text":"<p>Inspired by Majordomo Protocol Worker API, ZeroMQ, Python version.</p> <p>Original MDP/Worker spec </p> <p>Location: http://rfc.zeromq.org/spec:7.</p> <p>Author: Min RK benjaminrk@gmail.com</p> <p>Based on Java example by Arkadiusz Orzechowski</p>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.WorkerWatchDog","title":"<code>WorkerWatchDog(worker)</code>","text":"<p>               Bases: <code>Thread</code></p> <p>Class to monitor worker performance</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def __init__(self, worker):\n    super().__init__()\n    self.worker = worker\n    self.worker_process = psutil.Process(os.getpid())\n\n    # extract inventory attributes\n    self.watchdog_interval = worker.inventory.get(\"watchdog_interval\", 30)\n    self.memory_threshold_mbyte = worker.inventory.get(\n        \"memory_threshold_mbyte\", 1000\n    )\n    self.memory_threshold_action = worker.inventory.get(\n        \"memory_threshold_action\", \"log\"\n    )\n\n    # initiate variables\n    self.runs = 0\n    self.watchdog_tasks = []\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.WorkerWatchDog.get_ram_usage","title":"<code>get_ram_usage()</code>","text":"<p>Return RAM usage in Mbyte</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def get_ram_usage(self):\n    \"\"\"Return RAM usage in Mbyte\"\"\"\n    return self.worker_process.memory_info().rss / 1024000\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.Result","title":"<code>Result(result=None, failed=False, errors=None, task=None, messages=None, juuid=None)</code>","text":"<p>Result of running individual tasks.</p> <p>Attributes/Arguments:</p> <p>Parameters:</p> Name Type Description Default <code>changed</code> <p><code>True</code> if the task is changing the system</p> required <code>result</code> <code>Any</code> <p>Result of the task execution, see task's documentation for details</p> <code>None</code> <code>failed</code> <code>bool</code> <p>Whether the execution failed or not</p> <code>False</code> <code>(logging.LEVEL)</code> <code>severity_level</code> <p>Severity level associated to the result of the execution</p> required <code>errors</code> <code>Optional[List[str]]</code> <p>exception thrown during the execution of the task (if any)</p> <code>None</code> <code>task</code> <code>str</code> <p>Task function name that produced the results</p> <code>None</code> <code>messages</code> <code>Optional[List[str]]</code> <p>List of messages produced by the task</p> <code>None</code> <code>juuid</code> <code>Optional[str]</code> <p>Job UUID associated with the task</p> <code>None</code> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def __init__(\n    self,\n    result: Any = None,\n    failed: bool = False,\n    errors: Optional[List[str]] = None,\n    task: str = None,\n    messages: Optional[List[str]] = None,\n    juuid: Optional[str] = None,\n) -&gt; None:\n    self.task = task\n    self.result = result\n    self.failed = failed\n    self.errors = errors or []\n    self.messages = messages or []\n    self.juuid = juuid\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.Result.raise_for_status","title":"<code>raise_for_status(message='')</code>","text":"<p>Method to raise error if job failed</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def raise_for_status(self, message=\"\"):\n    \"\"\"Method to raise error if job failed\"\"\"\n    if self.failed:\n        if message:\n            raise NorfabJobFailedError(\n                f\"{message}; Errors: {'; '.join(self.errors)}\"\n            )\n        else:\n            raise NorfabJobFailedError(f\"Errors: {'; '.join(self.errors)}\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.Result.dictionary","title":"<code>dictionary()</code>","text":"<p>Method to serialize result to a dictionary</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def dictionary(self):\n    \"\"\"Method to serialize result to a dictionary\"\"\"\n    if not isinstance(self.errors, list):\n        self.errors = [self.errors]\n    if not isinstance(self.messages, list):\n        self.messages = [self.messages]\n\n    return {\n        \"task\": self.task,\n        \"failed\": self.failed,\n        \"errors\": self.errors,\n        \"result\": self.result,\n        \"messages\": self.messages,\n        \"juuid\": self.juuid,\n    }\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker","title":"<code>NFPWorker(inventory, broker, service, name, exit_event, log_level=None, log_queue=None, multiplier=6, keepalive=2500)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>broker</code> <code>str</code> <p>str, broker endpoint e.g. tcp://127.0.0.1:5555</p> required <code>service</code> <code>str</code> <p>str, service name</p> required <code>name</code> <code>str</code> <p>str, worker name</p> required <code>exist_event</code> <p>obj, threading event, if set signal worker to stop</p> required <code>multiplier</code> <code>int</code> <p>int, number of keepalives lost before consider other party dead</p> <code>6</code> <code>keepalive</code> <code>int</code> <p>int, keepalive interval in milliseconds</p> <code>2500</code> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def __init__(\n    self,\n    inventory: NorFabInventory,\n    broker: str,\n    service: str,\n    name: str,\n    exit_event,\n    log_level: str = None,\n    log_queue: object = None,\n    multiplier: int = 6,\n    keepalive: int = 2500,\n):\n    self.setup_logging(log_queue, log_level)\n    self.inventory = inventory\n    self.broker = broker\n    self.service = service\n    self.name = name\n    self.exit_event = exit_event\n    self.broker_socket = None\n    self.multiplier = multiplier\n    self.keepalive = keepalive\n    self.socket_lock = (\n        threading.Lock()\n    )  # used for keepalives to protect socket object\n\n    # create base directories\n    self.base_dir = os.path.join(\n        self.inventory.base_dir, \"__norfab__\", \"files\", \"worker\", self.name\n    )\n    self.base_dir_jobs = os.path.join(self.base_dir, \"jobs\")\n    os.makedirs(self.base_dir, exist_ok=True)\n    os.makedirs(self.base_dir_jobs, exist_ok=True)\n\n    # create events and queues\n    self.destroy_event = threading.Event()\n    self.request_thread = None\n    self.reply_thread = None\n    self.close_thread = None\n    self.recv_thread = None\n    self.event_thread = None\n\n    self.post_queue = queue.Queue(maxsize=0)\n    self.get_queue = queue.Queue(maxsize=0)\n    self.delete_queue = queue.Queue(maxsize=0)\n    self.event_queue = queue.Queue(maxsize=0)\n\n    # generate certificates and create directories\n    generate_certificates(\n        self.base_dir,\n        cert_name=self.name,\n        broker_keys_dir=os.path.join(\n            self.inventory.base_dir, \"__norfab__\", \"files\", \"broker\", \"public_keys\"\n        ),\n        inventory=self.inventory,\n    )\n    self.public_keys_dir = os.path.join(self.base_dir, \"public_keys\")\n    self.secret_keys_dir = os.path.join(self.base_dir, \"private_keys\")\n\n    self.ctx = zmq.Context()\n    self.poller = zmq.Poller()\n    self.reconnect_to_broker()\n\n    # create queue file\n    self.queue_filename = os.path.join(self.base_dir_jobs, f\"{self.name}.queue.txt\")\n    if not os.path.exists(self.queue_filename):\n        with open(self.queue_filename, \"w\") as f:\n            pass\n    self.queue_done_filename = os.path.join(\n        self.base_dir_jobs, f\"{self.name}.queue.done.txt\"\n    )\n    if not os.path.exists(self.queue_done_filename):\n        with open(self.queue_done_filename, \"w\") as f:\n            pass\n\n    self.client = NFPClient(\n        self.inventory,\n        self.broker,\n        name=f\"{self.name}-NFPClient\",\n        exit_event=self.exit_event,\n    )\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.setup_logging","title":"<code>setup_logging(log_queue, log_level)</code>","text":"<p>Method to apply logging configuration</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def setup_logging(self, log_queue, log_level: str) -&gt; None:\n    \"\"\"Method to apply logging configuration\"\"\"\n    logging_config_producer[\"handlers\"][\"queue\"][\"queue\"] = log_queue\n    if log_level is not None:\n        logging_config_producer[\"root\"][\"level\"] = log_level\n    logging.config.dictConfig(logging_config_producer)\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.reconnect_to_broker","title":"<code>reconnect_to_broker()</code>","text":"<p>Connect or reconnect to broker</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def reconnect_to_broker(self):\n    \"\"\"Connect or reconnect to broker\"\"\"\n    if self.broker_socket:\n        self.send_to_broker(NFP.DISCONNECT)\n        self.poller.unregister(self.broker_socket)\n        self.broker_socket.close()\n\n    self.broker_socket = self.ctx.socket(zmq.DEALER)\n    self.broker_socket.setsockopt_unicode(zmq.IDENTITY, self.name, \"utf8\")\n    self.broker_socket.linger = 0\n\n    # We need two certificates, one for the client and one for\n    # the server. The client must know the server's public key\n    # to make a CURVE connection.\n    client_secret_file = os.path.join(\n        self.secret_keys_dir, f\"{self.name}.key_secret\"\n    )\n    client_public, client_secret = zmq.auth.load_certificate(client_secret_file)\n    self.broker_socket.curve_secretkey = client_secret\n    self.broker_socket.curve_publickey = client_public\n\n    # The client must know the server's public key to make a CURVE connection.\n    server_public_file = os.path.join(self.public_keys_dir, \"broker.key\")\n    server_public, _ = zmq.auth.load_certificate(server_public_file)\n    self.broker_socket.curve_serverkey = server_public\n\n    self.broker_socket.connect(self.broker)\n    self.poller.register(self.broker_socket, zmq.POLLIN)\n\n    # Register service with broker\n    self.send_to_broker(NFP.READY)\n\n    # start keepalives\n    if self.keepaliver is not None:\n        self.keepaliver.restart(self.broker_socket)\n    else:\n        self.keepaliver = KeepAliver(\n            address=None,\n            socket=self.broker_socket,\n            multiplier=self.multiplier,\n            keepalive=self.keepalive,\n            exit_event=self.destroy_event,\n            service=self.service,\n            whoami=NFP.WORKER,\n            name=self.name,\n            socket_lock=self.socket_lock,\n        )\n        self.keepaliver.start()\n\n    self.stats_reconnect_to_broker += 1\n    log.info(\n        f\"{self.name} - registered to broker at '{self.broker}', \"\n        f\"service '{self.service.decode('utf-8')}'\"\n    )\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.send_to_broker","title":"<code>send_to_broker(command, msg=None)</code>","text":"<p>Send message to broker.</p> <p>If no msg is provided, creates one internally</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def send_to_broker(self, command, msg: list = None):\n    \"\"\"Send message to broker.\n\n    If no msg is provided, creates one internally\n    \"\"\"\n    if command == NFP.READY:\n        msg = [b\"\", NFP.WORKER, NFP.READY, self.service]\n    elif command == NFP.DISCONNECT:\n        msg = [b\"\", NFP.WORKER, NFP.DISCONNECT, self.service]\n    elif command == NFP.RESPONSE:\n        msg = [b\"\", NFP.WORKER, NFP.RESPONSE] + msg\n    elif command == NFP.EVENT:\n        msg = [b\"\", NFP.WORKER, NFP.EVENT] + msg\n    else:\n        log.error(\n            f\"{self.name} - cannot send '{command}' to broker, command unsupported\"\n        )\n        return\n\n    log.debug(f\"{self.name} - sending '{msg}'\")\n\n    with self.socket_lock:\n        self.broker_socket.send_multipart(msg)\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.load_inventory","title":"<code>load_inventory()</code>","text":"<p>Function to load inventory from broker for this worker name.</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def load_inventory(self):\n    \"\"\"\n    Function to load inventory from broker for this worker name.\n    \"\"\"\n    inventory_data = self.client.get(\n        \"sid.service.broker\", \"get_inventory\", kwargs={\"name\": self.name}\n    )\n\n    log.debug(f\"{self.name} - worker received invenotry data {inventory_data}\")\n\n    if inventory_data[\"results\"]:\n        return inventory_data[\"results\"]\n    else:\n        return {}\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.worker_exit","title":"<code>worker_exit()</code>","text":"<p>Method to override in child classes with a set of actions to perform on exit call</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def worker_exit(self) -&gt; None:\n    \"\"\"Method to override in child classes with a set of actions to perform on exit call\"\"\"\n    return None\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.get_inventory","title":"<code>get_inventory()</code>","text":"<p>Method to override in child classes to retrieve worker inventory</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def get_inventory(self) -&gt; Dict:\n    \"\"\"Method to override in child classes to retrieve worker inventory\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.get_version","title":"<code>get_version()</code>","text":"<p>Method to override in child classes to retrieve worker version report</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def get_version(self) -&gt; Dict:\n    \"\"\"Method to override in child classes to retrieve worker version report\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.fetch_file","title":"<code>fetch_file(url, raise_on_fail=False, read=True)</code>","text":"<p>Function to download file from broker File Sharing Service</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>file location string in <code>nf://&lt;filepath&gt;</code> format</p> required <code>raise_on_fail</code> <code>bool</code> <p>raise FIleNotFoundError if download fails</p> <code>False</code> <code>read</code> <code>bool</code> <p>if True returns file content, return OS path to saved file otherwise</p> <code>True</code> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def fetch_file(\n    self, url: str, raise_on_fail: bool = False, read: bool = True\n) -&gt; str:\n    \"\"\"\n    Function to download file from broker File Sharing Service\n\n    :param url: file location string in ``nf://&lt;filepath&gt;`` format\n    :param raise_on_fail: raise FIleNotFoundError if download fails\n    :param read: if True returns file content, return OS path to saved file otherwise\n    \"\"\"\n    status, file_content = self.client.fetch_file(url=url, read=read)\n    msg = f\"{self.name} - worker '{url}' fetch file failed with status '{status}'\"\n\n    if status == \"200\":\n        return file_content\n    elif raise_on_fail is True:\n        raise FileNotFoundError(msg)\n    else:\n        log.error(msg)\n        return None\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.fetch_jinja2","title":"<code>fetch_jinja2(url)</code>","text":"<p>Helper function to recursively download Jinja2 template together with other templates referenced using \"include\" statements</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p><code>nf://file/path</code> like URL to download file</p> required Source code in <code>norfab\\core\\worker.py</code> <pre><code>def fetch_jinja2(self, url: str) -&gt; str:\n    \"\"\"\n    Helper function to recursively download Jinja2 template together with\n    other templates referenced using \"include\" statements\n\n    :param url: ``nf://file/path`` like URL to download file\n    \"\"\"\n    filepath = self.fetch_file(url, read=False)\n    if filepath is None:\n        msg = f\"{self.name} - file download failed '{url}'\"\n        raise FileNotFoundError(msg)\n\n    # download Jinja2 template \"include\"-ed files\n    content = self.fetch_file(url, read=True)\n    j2env = Environment(loader=\"BaseLoader\")\n    try:\n        parsed_content = j2env.parse(content)\n    except Exception as e:\n        msg = f\"{self.name} - Jinja2 template parsing failed '{url}', error: '{e}'\"\n        raise Exception(msg)\n\n    # run recursion on include statements\n    for node in parsed_content.find_all(Include):\n        include_file = node.template.value\n        base_path = os.path.split(url)[0]\n        self.fetch_jinja2(os.path.join(base_path, include_file))\n\n    return filepath\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.job_details","title":"<code>job_details(uuid, data=True, result=True, events=True)</code>","text":"<p>Method to get job details by UUID for completed jobs.</p> <p>Parameters:</p> Name Type Description Default <code>uuid</code> <code>str</code> <p>str, job UUID to return details for</p> required <code>data</code> <code>bool</code> <p>bool, if True return job data</p> <code>True</code> <code>result</code> <code>bool</code> <p>bool, if True return job result</p> <code>True</code> <code>events</code> <code>bool</code> <p>bool, if True return job events</p> <code>True</code> <p>Returns:</p> Type Description <code>Result</code> <p>Result object with job details</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def job_details(\n    self, uuid: str, data: bool = True, result: bool = True, events: bool = True\n) -&gt; Result:\n    \"\"\"\n    Method to get job details by UUID for completed jobs.\n\n    :param uuid: str, job UUID to return details for\n    :param data: bool, if True return job data\n    :param result: bool, if True return job result\n    :param events: bool, if True return job events\n    :return: Result object with job details\n    \"\"\"\n    job = None\n    with queue_file_lock:\n        with open(self.queue_done_filename, \"rb+\") as f:\n            for entry in f.readlines():\n                job_data, job_result, job_events = None, None, []\n                job_entry = entry.decode(\"utf-8\").strip()\n                suuid, start, end = job_entry.split(\"--\")  # {suuid}--start--end\n                if suuid != uuid:\n                    continue\n                # load job request details\n                client_address, empty, juuid, job_data_bytes = loader(\n                    request_filename(suuid, self.base_dir_jobs)\n                )\n                if data:\n                    job_data = json.loads(job_data_bytes.decode(\"utf-8\"))\n                # load job result details\n                if result:\n                    rep_filename = reply_filename(suuid, self.base_dir_jobs)\n                    if os.path.exists(rep_filename):\n                        job_result = loader(rep_filename)\n                        job_result = json.loads(job_result[-1].decode(\"utf-8\"))\n                        job_result = job_result[self.name]\n                # load event details\n                if events:\n                    events_filename = event_filename(suuid, self.base_dir_jobs)\n                    if os.path.exists(events_filename):\n                        job_events = loader(events_filename)\n                        job_events = [e[-1] for e in job_events]\n\n                job = {\n                    \"uuid\": suuid,\n                    \"client\": client_address.decode(\"utf-8\"),\n                    \"received_timestamp\": start,\n                    \"done_timestamp\": end,\n                    \"status\": \"COMPLETED\",\n                    \"job_data\": job_data,\n                    \"job_result\": job_result,\n                    \"job_events\": job_events,\n                }\n\n    if job:\n        return Result(\n            task=f\"{self.name}:job_details\",\n            result=job,\n        )\n    else:\n        raise FileNotFoundError(f\"{self.name} - job with UUID '{uuid}' not found\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.NFPWorker.job_list","title":"<code>job_list(pending=True, completed=True, task=None, last=None, client=None, uuid=None)</code>","text":"<p>Method to list worker jobs completed and pending.</p> <p>Parameters:</p> Name Type Description Default <code>pending</code> <code>bool</code> <p>bool, if True or None return pending jobs, if False skip pending jobs</p> <code>True</code> <code>completed</code> <code>bool</code> <p>bool, if True or None return completed jobs, if False skip completed jobs</p> <code>True</code> <code>task</code> <code>str</code> <p>str, if provided return only jobs with this task name</p> <code>None</code> <code>last</code> <code>int</code> <p>int, if provided return only last N completed and last N pending jobs</p> <code>None</code> <code>client</code> <code>str</code> <p>str, if provided return only jobs submitted by this client</p> <code>None</code> <code>uuid</code> <code>str</code> <p>str, if provided return only job with this UUID</p> <code>None</code> <p>Returns:</p> Type Description <code>Result</code> <p>Result object with list of jobs</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def job_list(\n    self,\n    pending: bool = True,\n    completed: bool = True,\n    task: str = None,\n    last: int = None,\n    client: str = None,\n    uuid: str = None,\n) -&gt; Result:\n    \"\"\"\n    Method to list worker jobs completed and pending.\n\n    :param pending: bool, if True or None return pending jobs, if\n        False skip pending jobs\n    :param completed: bool, if True or None return completed jobs,\n        if False skip completed jobs\n    :param task: str, if provided return only jobs with this task name\n    :param last: int, if provided return only last N completed and\n        last N pending jobs\n    :param client: str, if provided return only jobs submitted by this client\n    :param uuid: str, if provided return only job with this UUID\n    :return: Result object with list of jobs\n    \"\"\"\n    job_pending = []\n    # load pending jobs\n    if pending is True:\n        with queue_file_lock:\n            with open(self.queue_filename, \"rb+\") as f:\n                for entry in f.readlines():\n                    job_entry = entry.decode(\"utf-8\").strip()\n                    suuid, start = job_entry.split(\"--\")  # {suuid}--start\n                    if uuid and suuid != uuid:\n                        continue\n                    client_address, empty, juuid, data = loader(\n                        request_filename(suuid, self.base_dir_jobs)\n                    )\n                    if client and client_address.decode(\"utf-8\") != client:\n                        continue\n                    job_task = json.loads(data.decode(\"utf-8\"))[\"task\"]\n                    # check if need to skip this job\n                    if task and job_task != task:\n                        continue\n                    job_pending.append(\n                        {\n                            \"uuid\": suuid,\n                            \"client\": client_address.decode(\"utf-8\"),\n                            \"received_timestamp\": start,\n                            \"done_timestamp\": None,\n                            \"task\": job_task,\n                            \"status\": \"PENDING\",\n                            \"worker\": self.name,\n                            \"service\": self.service.decode(\"utf-8\"),\n                        }\n                    )\n    job_completed = []\n    # load done jobs\n    if completed is True:\n        with queue_file_lock:\n            with open(self.queue_done_filename, \"rb+\") as f:\n                for entry in f.readlines():\n                    job_entry = entry.decode(\"utf-8\").strip()\n                    suuid, start, end = job_entry.split(\"--\")  # {suuid}--start--end\n                    if uuid and suuid != uuid:\n                        continue\n                    client_address, empty, juuid, data = loader(\n                        request_filename(suuid, self.base_dir_jobs)\n                    )\n                    if client and client_address.decode(\"utf-8\") != client:\n                        continue\n                    job_task = json.loads(data.decode(\"utf-8\"))[\"task\"]\n                    # check if need to skip this job\n                    if task and job_task != task:\n                        continue\n                    job_completed.append(\n                        {\n                            \"uuid\": suuid,\n                            \"client\": client_address.decode(\"utf-8\"),\n                            \"received_timestamp\": start,\n                            \"done_timestamp\": end,\n                            \"task\": job_task,\n                            \"status\": \"COMPLETED\",\n                            \"worker\": self.name,\n                            \"service\": self.service.decode(\"utf-8\"),\n                        }\n                    )\n    if last:\n        return Result(\n            task=f\"{self.name}:job_list\",\n            result=job_completed[len(job_completed) - last :]\n            + job_pending[len(job_pending) - last :],\n        )\n    else:\n        return Result(\n            task=f\"{self.name}:job_list\",\n            result=job_completed + job_pending,\n        )\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.request_filename","title":"<code>request_filename(suuid, base_dir_jobs)</code>","text":"<p>Returns freshly allocated request filename for given UUID str</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def request_filename(suuid: Union[str, bytes], base_dir_jobs: str):\n    \"\"\"Returns freshly allocated request filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(base_dir_jobs, f\"{suuid}.req\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.reply_filename","title":"<code>reply_filename(suuid, base_dir_jobs)</code>","text":"<p>Returns freshly allocated reply filename for given UUID str</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def reply_filename(suuid: Union[str, bytes], base_dir_jobs: str):\n    \"\"\"Returns freshly allocated reply filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(base_dir_jobs, f\"{suuid}.rep\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.event_filename","title":"<code>event_filename(suuid, base_dir_jobs)</code>","text":"<p>Returns freshly allocated event filename for given UUID str</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def event_filename(suuid: Union[str, bytes], base_dir_jobs: str):\n    \"\"\"Returns freshly allocated event filename for given UUID str\"\"\"\n    suuid = suuid.decode(\"utf-8\") if isinstance(suuid, bytes) else suuid\n    return os.path.join(base_dir_jobs, f\"{suuid}.event\")\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker._post","title":"<code>_post(worker, post_queue, queue_filename, destroy_event, base_dir_jobs)</code>","text":"<p>Thread to receive POST requests and save them to hard disk</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def _post(worker, post_queue, queue_filename, destroy_event, base_dir_jobs):\n    \"\"\"Thread to receive POST requests and save them to hard disk\"\"\"\n    # Ensure message directory exists\n    if not os.path.exists(base_dir_jobs):\n        os.mkdir(base_dir_jobs)\n\n    while not destroy_event.is_set():\n        try:\n            work = post_queue.get(block=True, timeout=0.1)\n        except queue.Empty:\n            continue\n        timestamp = time.ctime()\n        client_address = work[0]\n        suuid = work[2]\n        filename = request_filename(suuid, base_dir_jobs)\n        dumper(work, filename)\n\n        # write reply for this job indicating it is pending\n        filename = reply_filename(suuid, base_dir_jobs)\n        dumper(\n            [\n                client_address,\n                b\"\",\n                suuid,\n                b\"300\",\n                json.dumps(\n                    {\n                        \"worker\": worker.name,\n                        \"uuid\": suuid.decode(\"utf-8\"),\n                        \"status\": \"PENDING\",\n                        \"service\": worker.service.decode(\"utf-8\"),\n                    }\n                ).encode(\"utf-8\"),\n            ],\n            filename,\n        )\n        log.debug(f\"{worker.name} - '{suuid}' job, saved PENDING reply filename\")\n\n        # add job request to the queue_filename\n        with queue_file_lock:\n            with open(queue_filename, \"ab\") as f:\n                f.write(f\"{suuid.decode('utf-8')}--{timestamp}\\n\".encode(\"utf-8\"))\n        log.debug(f\"{worker.name} - '{suuid}' job, added job to queue filename\")\n\n        # ack job back to client\n        worker.send_to_broker(\n            NFP.RESPONSE,\n            [\n                client_address,\n                b\"\",\n                suuid,\n                b\"202\",\n                json.dumps(\n                    {\n                        \"worker\": worker.name,\n                        \"uuid\": suuid.decode(\"utf-8\"),\n                        \"status\": \"ACCEPTED\",\n                        \"service\": worker.service.decode(\"utf-8\"),\n                    }\n                ).encode(\"utf-8\"),\n            ],\n        )\n        log.debug(\n            f\"{worker.name} - '{suuid}' job, sent ACK back to client '{client_address}'\"\n        )\n\n        post_queue.task_done()\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker._get","title":"<code>_get(worker, get_queue, destroy_event, base_dir_jobs)</code>","text":"<p>Thread to receive GET requests and retrieve results from the hard disk</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def _get(worker, get_queue, destroy_event, base_dir_jobs):\n    \"\"\"Thread to receive GET requests and retrieve results from the hard disk\"\"\"\n    while not destroy_event.is_set():\n        try:\n            work = get_queue.get(block=True, timeout=0.1)\n        except queue.Empty:\n            continue\n\n        client_address = work[0]\n        suuid = work[2]\n        rep_filename = reply_filename(suuid, base_dir_jobs)\n\n        if os.path.exists(rep_filename):\n            reply = loader(rep_filename)\n        else:\n            reply = [\n                client_address,\n                b\"\",\n                suuid,\n                b\"400\",\n                json.dumps(\n                    {\n                        \"worker\": worker.name,\n                        \"uuid\": suuid.decode(\"utf-8\"),\n                        \"status\": \"JOB RESULTS NOT FOUND\",\n                        \"service\": worker.service.decode(\"utf-8\"),\n                    }\n                ).encode(\"utf-8\"),\n            ]\n\n        worker.send_to_broker(NFP.RESPONSE, reply)\n\n        get_queue.task_done()\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker._event","title":"<code>_event(worker, event_queue, destroy_event)</code>","text":"<p>Thread function to emit events to Clients</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def _event(worker, event_queue, destroy_event):\n    \"\"\"Thread function to emit events to Clients\"\"\"\n    while not destroy_event.is_set():\n        try:\n            work = event_queue.get(block=True, timeout=0.1)\n        except queue.Empty:\n            continue\n\n        client_address = work[0]\n        suuid = work[1]\n        task = work[2]\n        timeout = work[3]\n        data = work[4]\n\n        event = [\n            client_address,\n            b\"\",\n            suuid,\n            b\"200\",\n            json.dumps(\n                {\n                    \"worker\": worker.name,\n                    \"service\": worker.service.decode(\"utf-8\"),\n                    \"uuid\": suuid.decode(\"utf-8\"),\n                    \"task\": task,\n                    \"timeout\": timeout,\n                    **data,\n                }\n            ).encode(\"utf-8\"),\n        ]\n\n        worker.send_to_broker(NFP.EVENT, event)\n\n        event_queue.task_done()\n</code></pre>"},{"location":"api_reference_core_norfab_worker/#norfab.core.worker.recv","title":"<code>recv(worker, destroy_event)</code>","text":"<p>Thread to process receive messages from broker.</p> Source code in <code>norfab\\core\\worker.py</code> <pre><code>def recv(worker, destroy_event):\n    \"\"\"Thread to process receive messages from broker.\"\"\"\n    while not destroy_event.is_set():\n        # Poll socket for messages every second\n        try:\n            items = worker.poller.poll(1000)\n        except KeyboardInterrupt:\n            break  # Interrupted\n        if items:\n            msg = worker.broker_socket.recv_multipart()\n            log.debug(f\"{worker.name} - received '{msg}'\")\n            empty = msg.pop(0)\n            header = msg.pop(0)\n            command = msg.pop(0)\n\n            if command == NFP.POST:\n                worker.post_queue.put(msg)\n            elif command == NFP.DELETE:\n                worker.delete_queue.put(msg)\n            elif command == NFP.GET:\n                worker.get_queue.put(msg)\n            elif command == NFP.KEEPALIVE:\n                worker.keepaliver.received_heartbeat([header] + msg)\n            elif command == NFP.DISCONNECT:\n                worker.reconnect_to_broker()\n            else:\n                log.debug(\n                    f\"{worker.name} - invalid input, header '{header}', command '{command}', message '{msg}'\"\n                )\n\n        if not worker.keepaliver.is_alive():\n            log.warning(f\"{worker.name} - '{worker.broker}' broker keepalive expired\")\n            worker.reconnect_to_broker()\n</code></pre>"},{"location":"clients_nfcli_overview/","title":"NFCLI Shell","text":"<p>NORFAB comes with interactive command line shell interface invoked using <code>nfcli</code> to work with the system.</p> <p>NORFAB CLI designed as a modal operating system. The term modal  describes a system that has various modes of operation, each having its own  domain of operation. The CLI uses a hierarchical structure for the modes.</p> <p>You can access a lower-level mode only from a higher-level mode. For example,  to access the Nornir mode, you must be in the privileged EXEC mode. Each mode  is used to accomplish particular tasks and has a specific set of commands that  are available in this mode. For example, to configure a router interface, you  must be in Nornir configuration mode. All configurations that you enter in  configuration mode apply only to this function.</p> <p>NORFAB CLI build using PICLE package.</p> <p>It is important to remember that in PICLE Shell, when you enter a command, the  command is executed. If you enter an incorrect command in a production environment,  it can negatively impact it.</p>","tags":["nfcli"]},{"location":"clients_python_api_overview/","title":"NORFAB Python API","text":"<p>NorFab Python API can be used to interact with automations fabric To start working with Python API need to import <code>NorFab</code> object and instantiate it.</p> <pre><code>from norfab.core.nfapi import NorFab\n\nnf = NorFab(inventory=\"./inventory.yaml\")\nnf.start()\nnf.destroy()\n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p> <p>All interaction with NorFab happens via client, to create a client need to call <code>make_client</code> method:</p> <pre><code>import pprint\nfrom norfab.core.nfapi import NorFab\n\nnf = NorFab(inventory=\"./inventory.yaml\")\nnf.start()\n\nclient = nf.make_client()\n\nresult = nf.client.run_job(\n    service=\"nornir\",\n    task=\"cli\",\n    kwargs={\"commands\": [\"show version\", \"show clock\"]}\n)\n\npprint.pprint(ret)\n\nnf.destroy()\n</code></pre> <p>Calling <code>destroy</code> method will kill all the clients as well.</p>"},{"location":"clients_robot_client_overview/","title":"NorFab Robot Client","text":"<p>NORFAB Robot Client integrates with ROBOT framework to interact  with NORFAB, allowing to construct workflows and tasks using  ROBOT domain specific language (DSL).</p> <p>Robot Framework needs to be installed on the client:</p> <pre><code>pip install robotframework\n</code></pre>","tags":["robot"]},{"location":"clients_robot_client_overview/#supported-robot-keywords","title":"Supported ROBOT Keywords","text":"<ul> <li><code>Hosts</code> - <code>Fx</code> filters to target specific hosts, if not      provided targets all hosts</li> <li><code>Workers</code> - names of the workers to target, default is <code>all</code></li> <li><code>nr.test</code> - run Nornir Service <code>test</code> task using      provided Nornir tests suite</li> <li><code>nr.cli</code> - run Nornir Service <code>cli</code> task using      provided show commands and arguments</li> <li><code>nr.cfg</code> - run Nornir Service <code>cfg</code> task using      provided configuration commands and arguments</li> </ul>","tags":["robot"]},{"location":"clients_robot_client_overview/#nornir-tests-examples","title":"Nornir Tests Examples","text":"<p>This ROBOT framework test suite runs two tests using <code>nr.test</code>:</p> /path/to/robot_suite.robot<pre><code>*** Settings ***\nLibrary    norfab.clients.robot_client.NorFabRobot\n\n*** Test Cases ***\nTest NTP\n    nr.test    suite=nf://tests/test_ntp_config.yaml\n\nTest Software Version\n    Hosts      FM=arista_eos\n    nr.test    suite=nf://tests/test_version.yaml\n</code></pre> <p>Run test suite from client using <code>robot</code> command line tool:</p> <pre><code>robot /path/to/robot_suite.robot\n</code></pre>","tags":["robot"]},{"location":"norfab_changelog/","title":"Changelog","text":""},{"location":"norfab_changelog/#040","title":"0.4.0","text":""},{"location":"norfab_changelog/#changes","title":"CHANGES","text":"<ol> <li>Improved netbox get_circuits logic.</li> <li>Standartised worker <code>get_version</code> and <code>get_inventory</code> methods</li> </ol>"},{"location":"norfab_changelog/#features","title":"Features","text":"<ol> <li>Added <code>runtime_inventory</code> task to Nornir service, #6</li> <li>Added support to configure <code>startup</code> and <code>exit</code> hook functions in inventory to be executed by nfapi on start and on exit.</li> </ol>"},{"location":"norfab_changelog/#031","title":"0.3.1","text":""},{"location":"norfab_changelog/#changes_1","title":"CHANGES","text":"<ol> <li>Improved logging handling for NFAPI if it failing to start a worker</li> <li>Update client <code>get</code> method to return result as a dictionary for broker MMI, file and inventory services</li> <li>Enhanced Netbox <code>update_device_facts</code> and <code>update_device_interface</code> to support <code>batch_size</code> argument - a number of devices to process at a time</li> <li>Improved nfcli shell for Netbox service to provide more arguments for <code>netbox update device facts</code> command</li> </ol>"},{"location":"norfab_changelog/#features_1","title":"FEATURES","text":"<ol> <li>Added Netbox Service <code>update_device_ip</code> task to retrieve device interface IP addresses and create them in Netbox</li> <li>Added support to NorFab simple inventory and nfapi to load inventory from dictionary data as well as to explicitly provide <code>base_dir</code> information where to anchor NorFab environment</li> <li>Added support for NorFab inventory workers section items to be dictionaries in addition to OS path to YAML files allowing to construct workers inventory out of dictionaries and/or YAML files.</li> </ol>"},{"location":"norfab_changelog/#030","title":"0.3.0","text":""},{"location":"norfab_changelog/#features_2","title":"FEATURES","text":"<ol> <li>Added \"show version\" support for nfcli client to display versions of locally installed libraries, fixes. #4</li> <li>Added \"show broker version\" support for nfcli client to  retrieve broker report of the version of libraries broker is running on, fixes. #4</li> <li>Added support \"show broker inventory\" command to display broker inventory</li> <li>Simple inventory added support to produce a serialized dictionary output</li> <li>Broker added \"show_broker_inventory\" and \"show_broker_version\" MMI endpoints</li> <li>Added support for simple inventory service to render inventory using Jinja2, renderer passed on <code>env</code> variable that contains operating system environment variables, allowing to source any env data into NorFab inventory for both broker and workers. #5</li> <li>Created <code>fastapi</code> service to host REST API for NorFab</li> </ol>"},{"location":"norfab_changelog/#024","title":"0.2.4","text":""},{"location":"norfab_changelog/#bugs","title":"BUGS","text":"<ol> <li>Fixed nfcli <code>--workers-list</code> handling</li> <li>Fixed <code>job_data</code> url handling for nornir cli/cfg/test tasks</li> <li>Fixed nfapi handling of empty worker name</li> </ol>"},{"location":"norfab_changelog/#features_3","title":"FEATURES","text":"<ol> <li>Added a set of confirmed commit shell commands to nornir cfg netmiko plugin</li> </ol>"},{"location":"norfab_changelog/#023","title":"0.2.3","text":""},{"location":"norfab_changelog/#features_4","title":"FEATURES","text":"<ol> <li>Added nfcli <code>--workers-list</code> option to specify a list of workers to start</li> </ol>"},{"location":"norfab_changelog/#changes_2","title":"CHANGES","text":"<ol> <li>Fixed handling of jinja2 import for the worker to make it optional </li> </ol>"},{"location":"norfab_changelog/#021","title":"0.2.1","text":""},{"location":"norfab_changelog/#changes_3","title":"CHANGES","text":"<ol> <li>Improved libs imports handling to account for distributed deployment</li> <li>Improved logging handling</li> <li>Fixed nfcli issue with starting components onf NorFab #2</li> <li>Changed CTRL+C handling to trigger graceful NorFab exit</li> </ol>"},{"location":"norfab_changelog/#features_5","title":"FEATURES","text":"<ol> <li>Added <code>broker -&gt; shared_secret</code> parameter in <code>inventory.yaml</code> to configure clients and workers broker shared secret key</li> <li>Added and tested docker files</li> </ol>"},{"location":"norfab_changelog/#020","title":"0.2.0","text":""},{"location":"norfab_changelog/#changes_4","title":"CHANGES","text":"<ol> <li>refactored <code>get_circuits</code> to use <code>threadpoolexecutor</code> to fetch circuits path from netbox</li> <li>adding <code>job_data</code> json load to nornir cli, cfg and test tasks</li> </ol>"},{"location":"norfab_changelog/#bugs_1","title":"BUGS","text":"<ol> <li>Fixing netbox <code>get_devices</code> dry run test</li> <li>Fixed netbox <code>get_circuits</code> devices site retrieval handling</li> </ol>"},{"location":"norfab_changelog/#features_6","title":"FEATURES","text":"<ol> <li>Added cache to Netbox <code>get_circuits</code> and <code>get_devices</code> tasks</li> <li>Added new <code>agent</code> worker to stsart working on use cases to interface with LLMs</li> </ol>"},{"location":"norfab_changelog/#011","title":"0.1.1","text":""},{"location":"norfab_changelog/#bugs_2","title":"BUGS","text":"<ol> <li>FIxed Netbox CLI Shell handling of NFCLIENT</li> </ol>"},{"location":"norfab_changelog/#changes_5","title":"CHANGES","text":"<ol> <li>Updated and tested dependencies for Netmiko 4.5.0</li> <li>Updated and tested dependencies for Nornir 3.5.0</li> <li>Updated and tested dependencies for Nornir-Salt 0.22.1</li> </ol>"},{"location":"norfab_changelog/#010","title":"0.1.0","text":""},{"location":"norfab_changelog/#changes_6","title":"Changes","text":"<ol> <li>Changes to Nornir service module files structure</li> <li>PICLE dependency updated: 0.7. -&gt; 0.8.</li> <li>Made Nornir Service <code>progress</code> argument set to <code>True</code> by default to emit and display events for all Nornir Jobs</li> <li>Nornir tests changed <code>table</code> argument to be set to <code>True</code> by default</li> <li>Improved <code>nfapi</code> broker start logic to wait until broker fully initialized before proceeding to start workers</li> </ol>"},{"location":"norfab_changelog/#features_7","title":"Features","text":"<ol> <li>Added support for Nornir parse task to source TTP template from file with autocompletion</li> <li>Added Nornir File Copy task to copy files to devices using SCP</li> <li>Added support for logs to  be collected into single file from all NorFab local processes</li> <li>Added to NorFab worker <code>job_list</code> and <code>job_details</code> methods</li> <li>Added <code>show jobs summary</code> and <code>show jobs details</code> commands to NorFab shell and to Nornir shell</li> <li>Added <code>--create-env</code> argument to nfcli utility to create NorFab folders and files to make it easier to get started using norfab</li> </ol>"},{"location":"norfab_changelog/#bugs_3","title":"BUGS","text":"<ol> <li>Fixed Nornir Service Watchdog to clean up dead connections from hosts data</li> </ol>"},{"location":"norfab_changelog/#000","title":"0.0.0","text":"<p>Initial Release</p>"},{"location":"norfab_changelog/#notable-features","title":"Notable Features","text":"<ol> <li>NorFAB Broker, Client and Worker base classes</li> <li>Nornir Service</li> <li>Network Service</li> <li>Simple Inventory Datastore Service</li> <li>File service</li> <li>ZeroMQ encryption</li> </ol>"},{"location":"norfab_distributed_deployment/","title":"Distributed Deployment","text":"<p>TBD</p>"},{"location":"norfab_docker_deployment/","title":"Docker Deployment","text":"<p>NorFab comes with a set of docker files to get NorFab up and running on the Docker.</p> <p></p> <p>Broker and workers deployed in docker environment, while clients can run on Windows, Linux or MAC machine connecting to the broker instance.</p> <p>Prerequisites:</p> <ol> <li>Docker setup is independent from this guide and assumption is that docker is installed and running </li> <li>Docker compose utility is available on the docker host</li> <li>GIT also need to be installed on the docker host</li> </ol> <p>Assumptions:</p> <ol> <li>Docker host IP address is 192.168.1.130 and it is accessible by clients on TCP port 5555, docker host IP address of course will be different in your setup, adjust clients <code>inventory.yaml</code> file accordingly.</li> </ol>","tags":["norfab"]},{"location":"norfab_docker_deployment/#broker-and-workers-containers-deployment","title":"Broker and Workers Containers Deployment","text":"<p>First, need to clone NorFab repository to the local folder on the docker host:</p> <pre><code>cd ~/\ngit clone https://github.com/dmulyalin/NORFAB.git norfab\n</code></pre> <p>To build NorFab docker images we are going to use <code>docker compose</code> utility, it will create broker and nornir service workers containers:</p> <pre><code>cd norfab/docker\ndocker compose build\n</code></pre> <p>Once build finishes we can start the containers:</p> <pre><code>docker compose start\n</code></pre> <p>After broker reports that it is started and worker shows that it is registered with broker, this is a good indication that things are going ok:</p> <pre><code>root@dockervm:/home/user/norfab/docker# docker compose up\n[+] Running 2/0\n \u2714 Container norfab-broker          Created                   0.0s \n \u2714 Container norfab-service-nornir  Created                   0.0s \nAttaching to norfab-broker, norfab-service-nornir\nnorfab-broker          | 2025-02-02 10:40:20.453 INFO [norfab.core.nfapi:210 ] -- Started broker, broker listening for connections on 'tcp://10.0.0.100:5555'\nnorfab-service-nornir  | 2025-02-02 10:40:21.528 INFO [norfab.core.worker:557 ] -- nornir-worker-1 - registered to broker at 'tcp://10.0.0.100:5555', service 'nornir'\nnorfab-broker          | 2025-02-02 10:40:21.530 INFO [norfab.core.broker:317 ] -- NFPBroker - registered new worker nornir-worker-1\nnorfab-service-nornir  | 2025-02-02 10:40:21.554 INFO [nornir_salt.plugins.inventory.DictInventory:138 ] -- nornir-salt.DictInventory inventory data validated\nnorfab-service-nornir  | 2025-02-02 10:40:21.566 INFO [norfab.workers.nornir_worker:246 ] -- nornir-worker-1 - Started\n...\n</code></pre> <p>Folder <code>norfab/docker/norfab</code> mounted to the containers as a volume under <code>/etc/norfab</code> path and this is the content of <code>inventory.yaml</code> file:</p> <pre><code># broker settings\nbroker:\n  endpoint: \"tcp://10.0.0.100:5555\"\n\n# workers inventory section\nworkers:\n  nornir-*:\n    - nornir/common.yaml  \n  nornir-worker-1:\n    - nornir/nornir-worker-1.yaml\n\n# list what entities we want to start on this node\ntopology:\n  broker: True\n  workers:\n    - nornir-worker-1\n</code></pre> <p>Docker compose starts a broker process on <code>norfab-broker</code> container that uses <code>10.0.0.100</code> IP address and starts a single Nornir Service worker process named <code>nornir-worker-1</code> on a <code>norfab-service-nornir</code> container. </p> <p>File <code>inventory.yaml</code> can be adjusted to configure additional Nornir service workers to make <code>norfab-service-nornir</code> container run as many Nornir Service worker processes as needed.</p> <p>Before we proceed with setting up the client, need to grab encryption public key value from the broker, run these commands:</p> <pre><code>docker exec -it norfab-broker bash\ncd /etc/norfab/\nnfcli --show-broker-shared-key\n</code></pre> <p>Running above commands will produce similar to this output:</p> <pre><code>root@user:/home/user/norfab/docker# docker exec -it norfab-broker bash\nroot@norfab-broker:/# cd /etc/norfab\nroot@norfab-broker:/etc/norfab# nfcli --show-broker-shared-key\nNorFab broker public key content:\n\n'''\n#   ****  Generated on 2025-02-02 09:31:04.387927 by pyzmq  ****\n#   ZeroMQ CURVE Public Certificate\n#   Exchange securely, or use a secure mechanism to verify the contents\n#   of this file after exchange. Store public certificates in your home\n#   directory, in the .curve subdirectory.\n\nmetadata\ncurve\n    public-key = \"j{5-J9&lt;Qs:!@CVFsO$)UH&gt;mf%mP&lt;05[#%bBf(ofo\"\n\n'''\n\nKey file location: '__norfab__/files/broker/public_keys/broker.key'\n\nCopy above key into NorFab clients and workers 'public_keys/broker.key' file or \nput public-key value into clients and workers inventory.yaml 'broker' section \nunder 'shared_key' parameter:\n\nbroker:\n  shared_key: \"j{5-J9&lt;Qs:!@CVFsO$)UH&gt;mf%mP&lt;05[#%bBf(ofo\"\n\nroot@norfab-broker:/etc/norfab# \n</code></pre> <p>Public key value NorFab clients will need in this case is:</p> <pre><code>\"j{5-J9&lt;Qs:!@CVFsO$)UH&gt;mf%mP&lt;05[#%bBf(ofo\"\n</code></pre>","tags":["norfab"]},{"location":"norfab_docker_deployment/#client-setup","title":"Client Setup","text":"<p>After broker and worker containers are running need to setup a NorFab client, client can run on any machine that can connect to the docker host on its IP address on TCP port 5555.</p> <p>First, lets install NorFab on the client machine:</p> <pre><code>pip install norfab[nfcli]\n</code></pre> <p>Second, need to create a folder to host NorFab files:</p> <pre><code>nfcli --create-env norfab-env\n</code></pre> <p>Next need to configure broker endpoint pointing to docker host IP (<code>192.168.1.130</code> in this example) and broker encryption key in the <code>norfab-env/inventory.yaml</code> under <code>broker</code> section:</p> <pre><code># broker settings\nbroker:\n  endpoint: \"tcp://192.168.1.130:5555\"\n  shared_key: \"j{5-J9&lt;Qs:!@CVFsO$)UH&gt;mf%mP&lt;05[#%bBf(ofo\"\n</code></pre> <p>All the other <code>inventory.yaml</code> file content can be deleted, folder <code>norfab-env/nornir</code> also can be deleted. Client only need <code>inventory.yaml</code> file with broker endpoint and broker shared key details to successfully connect with the broker.</p> <p>Lastly, run <code>nfcli</code> client from within <code>norfab-env</code> folder:</p> <pre><code>cd norfab-env\nnfcli -c\n</code></pre> <p>NorFan interactive shell should start:</p> <pre><code>Welcome to NorFab Interactive Shell.\n\nnf#show broker\n status: active\n keepalives:\n   interval: 2500\n   multiplier: 6\n workers count: 1\n services count: 1\n directories:\n   base-dir: /etc/norfab\n   private-keys-dir: /etc/norfab/__norfab__/files/broker/private_keys\n   public-keys-dir: /etc/norfab/__norfab__/files/broker/public_keys\n security:\n   broker-private-key-file: /etc/norfab/__norfab__/files/broker/private_keys/broker.key_secret\n   broker-public-key-file: /etc/norfab/__norfab__/files/broker/public_keys/broker.key\nnf#show workers\n name             service  status  holdtime  keepalives tx/rx  alive (s) \n nornir-worker-1  nornir   alive   12.6      835 / 835         2104\nnf#\n</code></pre> <p>Successfully running <code>show broker</code> and <code>show workers</code> commands is a good indication that everything works well and you did a great job setting up NorFab in a distributed dockerized fashion .</p> <p>Next steps would be to adjust <code>inventory.yaml</code> file on the docker host to configure Nornir Service workers to manage your environment, for further details on how to do it refer to Nornir Service documentations. Good Luck \ud83e\udd1e</p>","tags":["norfab"]},{"location":"norfab_getting_started/","title":"Getting Started","text":"<p>The simplest way to start with NorFab is to do local deployment when broker, workers and client processes all run locally, this is what we going to demonstrate in this guide.</p> <p></p> <p>Client, broker and worker all should be able to run on same machine Windows, Linux or MAC.</p> <p>Once NorFab installed, next step is to create a folder that will hold your environment. Run this command to create NorFab folders and files:</p> <pre><code>nfcli --create-env norfab\n</code></pre> <p>This will create <code>norfab</code> folder and inside of it will create <code>inventory.yaml</code>, file name is important as NORFAB by default searches for <code>inventory.yaml</code>, file content is:</p> inventory.yaml<pre><code>broker: # (1)!\n  endpoint: \"tcp://127.0.0.1:5555\" # (2)!\n\nworkers: # (3)!\n  nornir-*: # (4)!\n    - nornir/common.yaml   \n  nornir-worker-1: # (5)!\n    - nornir/nornir-worker-1.yaml\n\ntopology: # (6)!\n  broker: True # (7)!\n  workers: # (8)!\n    - nornir-worker-1\n</code></pre> <ol> <li>Broker configuration inventory section</li> <li>URL to listen for connections on - <code>localhost</code> port <code>5555</code> in this case</li> <li>Workers configuration inventory section</li> <li>glob pattern that will match all workers with <code>nornir-</code> in the name and map <code>common.yaml</code> file content for each of them</li> <li>Worker definition to map inventory file to a specific worker that has name <code>nornir-worker-1</code></li> <li>Topology section to define what components to run</li> <li>Start broker process</li> <li>List of workers names to start processes for</li> </ol> <p>Command <code>--create-env</code> assumes we are working with Nornir service and creates <code>nornir</code> folder and inside of it creates two files. First file <code>common.yaml</code> to host configuration common for all Nornir service workers:</p> common.yaml<pre><code>service: nornir # (1)!\nbroker_endpoint: \"tcp://127.0.0.1:5555\" # (2)!\n\n# Nornir inventory and configuration\nrunner: # (3)!\n  plugin: RetryRunner\nhosts: {}\ndefault: {} # (4)!\ngroups: {} # (5)!\n</code></pre> <ol> <li>Name of the service this worker hosting</li> <li>Broker URL to initiate connections with</li> <li>Nornir runner plugin configuration</li> <li>Nornir <code>default</code> data section</li> <li>Nornir groups definition section</li> </ol> <p>Second file specific to the worker with name <code>nornir-worker-1</code> which holds Nornir inventory data:</p> nornir-worker-1.yaml<pre><code>hosts:\n  ios-device-1:\n    hostname: 192.168.1.1\n    platform: cisco_ios\n    username: admin\n    password: admin\n</code></pre> <p>This is how files structure will look like:</p> <pre><code>\u2514\u2500\u2500\u2500norfab\n    \u2502   inventory.yaml\n    \u2502\n    \u2514\u2500\u2500\u2500nornir\n            common.yaml\n            nornir-worker-1.yaml\n</code></pre> <p>Now you are ready to start NorFab Interactive Command Line Shell Client. Open terminal window, navigate to the folder where <code>inventory.yaml</code> located and start NFCLI:</p> <pre><code>C:\\&gt;cd norfab\nC:\\norfab&gt;nfcli\nnf#\n</code></pre> <p>this will start the NorFab broker process, Nornir worker process, instantiate NFCLI client and drop you into interactive command line shell </p> <pre><code>nf#? # (1)!\n file      File sharing service\n netbox    Netbox service\n nornir    Nornir service\n show      NorFab show commands\n exit      Exit current shell\n help      Print help message\n pwd       Print current shell path\n top       Exit to top shell\nnf#show workers # (2)!\n name             service  status  holdtime  keepalives tx/rx  alive (s)\n nornir-worker-1  nornir   alive   12.8      58 / 58           149\nnf#\nnf#nornir # (3)!\nnf[nornir]#?\n cfg     Configure devices over CLI interface\n cli     Send CLI commands to devices\n show    Show Nornir service parameters\n task    Run Nornir task\n test    Run network tests\n end     Exit application\n exit    Exit current shell\n help    Print help message\n pwd     Print current shell path\n top     Exit to top shell\nnf[nornir]#show hosts table details\n+-----------------+--------------+------------+-------------+--------+----------+------------+\n| worker          | host         | platform   | hostname    | port   | groups   | username   |\n+=================+==============+============+=============+========+==========+============+\n| nornir-worker-1 | ios-device-1 | cisco_ios  | 192.168.1.1 | None   | []       | admin      |\n+-----------------+--------------+------------+-------------+--------+----------+------------+\nnf[nornir]# end\nExiting...\n</code></pre> <ol> <li>Question mark plus enter to print commands help</li> <li>Run show command</li> <li>Drop into Nornir Service command shell</li> </ol> <p>NorFab CLI supports Tab completions, question mark help together with sub-shells, read more about NorFab CLI and how to use it here.</p> <p> That's it </p>","tags":["norfab"]},{"location":"norfab_help_with_norfab/","title":"Help with NORFAB","text":""},{"location":"norfab_help_with_norfab/#github","title":"GitHub","text":"<p>For issues and suggestions reach out on GitHub</p>"},{"location":"norfab_installation/","title":"Installation","text":""},{"location":"norfab_installation/#install-norfab","title":"Install NorFab","text":"<p>Install NorFab from PyPI</p> <pre><code>pip install norfab\n</code></pre> <p>NorFab core runs equally well on both Windows and Linux. Some  services might work only on one or the other, in that case that will be noted in service deployment details.</p>"},{"location":"norfab_installation/#extras","title":"Extras","text":"<p>Several extra installations supported tailoring certain services dependencies that you want to run on a given node.</p> <p>To install all dependencies for all services can use <code>full</code> extras:</p> <pre><code>pip install norfab[full]\n</code></pre>"},{"location":"norfab_installation/#norfab-cli-dependencies","title":"NORFAB CLI Dependencies","text":"<p>To install NorFab Interactive CLI dependencies</p> <pre><code>pip install norfab[nfcli]\n</code></pre>"},{"location":"norfab_installation/#robot-client-dependencies","title":"Robot Client Dependencies","text":"<p>To install Robot library dependencies</p> <pre><code>pip install norfab[robot]\n</code></pre>"},{"location":"norfab_installation/#nornir-service-dependencies","title":"Nornir Service Dependencies","text":"<p>To install Nornir service dependencies</p> <pre><code>pip install norfab[nornirservice]\n</code></pre>"},{"location":"norfab_installation/#netbox-service-dependencies","title":"Netbox Service Dependencies","text":"<p>To install Netbox service dependencies</p> <pre><code>pip install norfab[netboxservice]\n</code></pre>"},{"location":"norfab_installation/#operating-systems-support","title":"Operating Systems Support","text":"Component Windows Linux MacOS NorFab Core Nornir Service Netbox Service"},{"location":"norfab_installation/#dependencies-matrix","title":"Dependencies Matrix","text":"<p>TBD</p>"},{"location":"norfab_why_use_norfab/","title":"Why Use NORFAB","text":""},{"location":"norfab_why_use_norfab/#unlock-the-full-potential-of-network-automation","title":"Unlock the Full Potential of Network Automation","text":"<p>In today's fast-paced digital world, network automation is no longer a luxury\u2014it's a necessity. NORFAB (Network Automations Fabric) is designed to empower network engineers with unparalleled automation capabilities, transforming the way you manage and optimize your network infrastructure.</p>"},{"location":"norfab_why_use_norfab/#key-features","title":"Key Features","text":""},{"location":"norfab_why_use_norfab/#1-run-anywhere","title":"1. Run Anywhere","text":"<p>NORFAB is incredibly versatile. Whether you're running on Windows, Mac, Linux, in a container, or a virtual machine, NORFAB adapts to your environment. Deploy it on-premises or in the cloud, centralized or fully distributed\u2014the choice is yours.</p>"},{"location":"norfab_why_use_norfab/#2-extend-anything","title":"2. Extend Anything","text":"<p>Extendability is at the core of NORFAB. With its modular architecture, you can easily integrate new functionalities, customize workflows, and adapt to evolving network requirements. NORFAB grows with your business.</p>"},{"location":"norfab_why_use_norfab/#3-integrate-with-everything","title":"3. Integrate with Everything","text":"<p>NORFAB offers seamless integration with a wide range of interfaces, including Python API, REST API, and CLI. This ensures that NORFAB can fit into any existing workflow or toolchain, making it easier to automate and manage your network.</p>"},{"location":"norfab_why_use_norfab/#4-manage-anything","title":"4. Manage Anything","text":"<p>From network devices to databases, NORFAB can manage a diverse set of resources. Use built-in services or develop your own to meet specific needs. NORFAB's flexibility ensures that you can automate any aspect of your network operations.</p>"},{"location":"norfab_why_use_norfab/#5-model-and-data-driven","title":"5. Model and Data-Driven","text":"<p>NORFAB leverages Pydantic models for API validation and documentation, ensuring that your automation processes are robust and reliable. This model-driven approach simplifies the management of complex network configurations.</p>"},{"location":"norfab_why_use_norfab/#6-automate-anything","title":"6. Automate Anything","text":"<p>With NORFAB, the sky's the limit. Automate routine tasks, complex workflows, and everything in between. NORFAB's powerful automation capabilities free up your time, allowing you to focus on strategic initiatives.</p>"},{"location":"norfab_why_use_norfab/#benefits","title":"Benefits","text":"<ul> <li>Increased Efficiency: Automate repetitive tasks and reduce manual intervention, leading to faster and more efficient network operations.</li> <li>Enhanced Reliability: Minimize human errors and ensure consistent network performance with automated processes.</li> <li>Scalability: Easily scale your network automation efforts as your infrastructure grows, without compromising on performance.</li> <li>Cost Savings: Reduce operational costs by streamlining network management and optimizing resource utilization.</li> <li>Future-Proof: Stay ahead of the curve with a solution that evolves with technological advancements and industry trends.</li> </ul>"},{"location":"norfab_why_use_norfab/#comparison-with-other-tools","title":"Comparison With Other Tools","text":"Feature NORFAB Ansible Cisco NSO PyATS Nornir Programming Language Python YAML, Python YANG, XML, Python Python Python Extensibility High High Medium Medium High Model-Driven No No Yes, YANG models No No API Support REST, Python, CLI REST, Python REST, NETCONF, CLI Python Python Multi-vendor Yes Yes Yes Yes Yes Config Management Yes Yes Yes Yes Yes Network Testing Yes Limited Limited Yes Yes Orchestration Limited Limited Yes No Limited Scalability High Medium High Medium Medium Ease of Use Requires knowledge of typing CLI commands Requires knowledge of proprietary YAML DSL Requires knowledge of Python, YANG, XML Requires knowledge of Python Requires knowledge of Python Deployment Centralized, Distributed, Hybrid Centralized Centralized, Hierarchical Centralized Centralized Templating Jinja2 Jinja2 XML Proprietary Jinja2 Jinja2 Datastorage Database, Text files Text files Database, Text files Text files Text files Device Inventory Internal, External Internal, External Internal Internal Internal, External Community Support Available Available Available Available Available Commercial Support Available Available Available Not Available Not Available"},{"location":"norfab_why_use_norfab/#conclusion","title":"Conclusion","text":"<p>NORFAB is more than just a network automation tool\u2014it's a comprehensive solution designed to enhance your network management capabilities. By choosing NORFAB, you're investing in a future where network operations are seamless, efficient, and highly automated. Unlock the full potential of your network with NORFAB today!</p> <p>For more information or to schedule a demo, contact NorFab Support.</p>"},{"location":"reference_architecture_nfp/","title":"NORFAB Protocol","text":"<p>Status: experimental Editor: d.mulyalin@gmail.com Contributors: </p> <p>The NORFAB Protocol (NFP) defines a reliable service-oriented request-reply dialog between a set of client applications, a broker and a set of worker applications representing service managing a set of resources. </p> <p>NFP covers presence, heartbeating, and service-resource-oriented request-reply processing. NFP originated from the MDP pattern defined in Chapter 4 of the ZeroMQ Guide and combined with TSP pattern (developed in same chapter) approach for persistent messaging across a network of arbitrarily connected clients and workers as a design for disk-based reliable messaging. NORFAB allows clients and workers to work without being connected to the network at the same time, and defines handshaking for safe storage of requests, and retrieval of replies.</p>"},{"location":"reference_architecture_nfp/#license","title":"License","text":"<p>Copyright (c) 2024 Denis Mulyalin.</p> <p>This Specification is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.</p> <p>This Specification is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program; if not, see http://www.gnu.org/licenses.</p>"},{"location":"reference_architecture_nfp/#change-process","title":"Change Process","text":"<p>This Specification is a free and open standard (see \u201cDefinition of a Free and Open Standard\") and is governed by the Digital Standards Organization\u2019s Consensus-Oriented Specification System (COSS) (see \u201cConsensus Oriented Specification System\").</p>"},{"location":"reference_architecture_nfp/#language","title":"Language","text":"<p>The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 (see \u201cKey words for use in RFCs to Indicate Requirement Levels\").</p>"},{"location":"reference_architecture_nfp/#goals","title":"Goals","text":"<p>The NORFAB Protocol (NFP) defines a reliable service-resource-oriented request-reply dialog between a set of client applications, a broker and a set of worker applications. NFP covers presence, heartbeating, and service-oriented request-reply processing. </p> <p>NFP uses name-based service resolution, named based resource targeting and structured protocol commands.</p> <p>The goals of NFP are to:</p> <ul> <li>Allow requests to be routed to workers on the basis of abstract service names.</li> <li>Allow broker and workers to detect disconnection of one another, through the use of heartbeating.</li> <li>ALlow task distribution by clients targeting <code>all</code> (broadcast), <code>any</code> (anycast) or <code>unicast</code> certain workers by names within given service.</li> <li>Allow the broker to recover from dead or disconnected workers by re-sending requests to other workers.</li> <li>Allow workers to manage <code>resource</code> entities, where entities can be dynamically distributed across all workers within the service.</li> <li>Allow workers to have access to inventory data hosted by broker</li> </ul>"},{"location":"reference_architecture_nfp/#architecture","title":"Architecture","text":""},{"location":"reference_architecture_nfp/#overall-topology","title":"Overall Topology","text":"<p>NFP connects a set of client applications, a single broker device and a pool of workers applications. Clients connect to the broker, as do workers. Clients and workers do not see each other, and both can come and go arbitrarily. The broker MAY open two sockets (ports), one front-end for clients, and one back-end for workers. However NFP is also designed to work over a single broker socket.</p> <p>We define \u2018client\u2019 applications as those issuing requests, and \u2018worker\u2019 applications as those processing them. NFP makes these assumptions:</p> <ul> <li>Workers are idempotent, i.e. it is safe to execute the same request more than once.</li> <li>Workers will handle at most one request a time, and will issue exactly one reply for each successful request.</li> <li>The NORFAB broker mediates requests one a per service basis. The broker SHOULD serve clients on a fair basis and SHOULD deliver requests to workers on the basis of targeting specified by client - <code>any</code> worker, <code>all</code> workers or <code>unicast</code> worker identified by name.</li> </ul> <p>NFP consists of four sub-protocols:</p> <ul> <li>NFP/Client, which covers how the NFP broker communicates with client applications.</li> <li>NFP/Worker, which covers how the NFP broker communicates with workers applications.</li> <li>NFP/Worker-PUB, which covers how broker subscribes to events published by workers.</li> <li>NFP/Broker-PUB, which covers how broker publishes collected worker events to clients.</li> </ul> <p>The broker SHOULD be an intermediary (a device) application that mediates Client-Workers communication. The broker SHOULD integrate Management Interface (MMI) service directly into it together with simple disk based Inventory service for workers.</p>"},{"location":"reference_architecture_nfp/#router-addressing","title":"ROUTER Addressing","text":"<p>The broker MUST use a ROUTER socket to accept requests from clients, and connections from workers. The broker MAY use a separate socket for each sub-protocol, or MAY use a single socket for both sub-protocols.</p> <p>From the \u00d8MQ Reference Manual:</p> <p>When receiving messages a ROUTER socket shall prepend a message part containing the identity of the originating peer to the message before passing it to the application. When sending messages a ROUTER socket shall remove the first part of the message and use it to determine the identity of the peer the message shall be routed to.</p> <p>This extra frame is not shown in the sub-protocol commands explained below.</p>"},{"location":"reference_architecture_nfp/#nfp-messages","title":"NFP messages","text":""},{"location":"reference_architecture_nfp/#open","title":"OPEN","text":"<p>A OPEN command consists of 4 frames, formatted on the wire as follows:</p> <pre><code>OPEN command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPC01\u201d or \u201cNFPW01\u201d or \u201cNFPB01\u201d (six bytes, representing NFP/Client or NFP/Worker or NFP/Broker v0.1)\nFrame 2: 0x00 (one byte, representing OPEN)\nFrame 3: Open body (opaque binary)\n</code></pre> <p>Worker and client use OPEN message to introduce itself to broker to negotiate connection parameters. Broker sends OPEN message back to client or worker to confirm the connection.</p>"},{"location":"reference_architecture_nfp/#ready","title":"READY","text":"<p>A READY command consists of a multipart message of 4 frames, formatted on the wire as follows:</p> <pre><code>READY command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPW01\u201d (six bytes, representing NFP/Worker v0.1)\nFrame 2: 0x01 (one byte, representing READY)\nFrame 3: Service name (printable string)\n</code></pre> <p>Worker sends READY command to broker, broker accepts ready request and registers worker with a service.</p>"},{"location":"reference_architecture_nfp/#keepalive","title":"KEEPALIVE","text":"<p>A KEEPALIVE command consists of 4 frames, formatted on the wire as follows:</p> <pre><code>KEEPALIVE command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPB01\u201d or \u201cNFPW01\u201d (six bytes, representing NFP/Broker or NFP/Worker v0.1)\nFrame 2: 0x02 (one byte, representing KEEPALIVE)\nFrame 3: Service name (printable string)\n</code></pre> <p>Broker sends KEEPALIVE messages to workers to indicate broker is still alive.</p> <p>Workers send KEEPALIVE messages to broker to indicate worker is still alive.</p>"},{"location":"reference_architecture_nfp/#disconnect","title":"DISCONNECT","text":"<p>A DISCONNECT command consists of 3 frames, formatted on the wire as follows:</p> <pre><code>DISCONNECT command\n---------------------------------------------------------------\nFrame 0: Empty frame\nFrame 1: \u201cNFPB01\u201d or \u201cNFPW01\u201d (six bytes, representing NFP/Broker or NFP/Worker v0.1)\nFrame 2: 0x03 (one byte, representing DISCONNECT)\nFrame 3: Service name (printable string)\nFrame 4: Disconnect body (opaque binary)\n</code></pre> <p>Broker sends DISCONNECT command to workers to signal the request to disconnect. </p> <p>Workers also can send DISCONNECT command to broker to signal the request to disconnect. </p>"},{"location":"reference_architecture_nfp/#post","title":"POST","text":"<p>A POST command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>POST command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPC01\u201d or \"NFPB01\" (six bytes, representing NFP/Client or NFP/Broker v0.1)\nFrame 2: 0x04 (one byte, representing POST)\nFrame 3: Service name (printable string)\nFrame 4: Target (printable string) workers, `all` (default), `any` or comma separated `worker names`\nFrame 5: Job UUID (printable string)\nFrames 6: POST body (opaque binary)\n</code></pre> <p>Client sends POST message to broker to distribute job requests among workers. </p> <p>Broker relays POST message to individual workers to publish job request.</p>"},{"location":"reference_architecture_nfp/#response","title":"RESPONSE","text":"<p>A RESPONSE command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>RESPONSE command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPB01\u201d or \u201cNFPW01\u201d (six bytes, representing NFP/Broker or NFP/Worker v0.1)\nFrame 2: 0x05 (one byte, representing RESPONSE)\nFrame 3: Service name (printable string)\nFrame 4: Job UUID (printable string)\nFrame 5: Status code (explained below)\nFrames 6: Response body (opaque binary)\n</code></pre> <p>Worker sends RESPONSE message to broker with requests status or job results. </p> <p>Broker relays RESPONSE message to client.</p>"},{"location":"reference_architecture_nfp/#get","title":"GET","text":"<p>A GET command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>GET command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPC01\u201d or \"NFPB01\" (six bytes, representing NFP/Client or NFP/Broker v0.1)\nFrame 2: 0x06 (one byte, representing GET)\nFrame 3: Service name (printable string)\nFrame 4: Target (printable string) workers, `all` (default), `any` or comma separated `worker names`\nFrame 5: Job UUID (printable string)\nFrames 6: GET request body (opaque binary)\n</code></pre> <p>Client sends GET message to broker to retrieve job results. </p> <p>Broker relays GET message to individual workers to request job request.</p>"},{"location":"reference_architecture_nfp/#delete","title":"DELETE","text":"<p>A DELETE command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>DELETE command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPC01\u201d or \"NFPB01\" (six bytes, representing NFP/Client or NFP/Broker v0.1)\nFrame 2: 0x07 (one byte, representing POST)\nFrame 3: Service name (printable string)\nFrame 4: Target (printable string) workers, `all` (default), `any` or comma separated `worker names`\nFrame 5: Job UUID (printable string)\nFrames 6: DELETE body (opaque binary)\n</code></pre> <p>Client sends DELETE message to broker to distribute job delete requests to workers. </p> <p>Broker relays DELETE message to individual workers to cancel the job.</p>"},{"location":"reference_architecture_nfp/#event","title":"EVENT","text":"<p>A EVENT command consists of 7 or more frames, formatted on the wire as follows:</p> <pre><code>EVENT command\n---------------------------------------------------------------\nFrame 0: Empty (zero bytes, invisible to REQ application)\nFrame 1: \u201cNFPW01\u201d (six bytes, representing NFP/Worker v0.1)\nFrame 2: 0x08 (one byte, representing EVENT)\nFrame 3: Service name (printable string)\nFrame 4: Topic (printable string e.g. Job UUID)\nFrame 5: Status code 200 (explained below)\nFrames 6: Event body (opaque binary)\n</code></pre> <p>Worker sends EVENT message to Broker to supply information about job execution. </p> <p>Broker relays EVENT message to certain Client.</p>"},{"location":"reference_architecture_nfp/#status-frames","title":"Status Frames","text":"<p>Every RESPONSE message contains a status frame followed by zero or more content frames. The status frame contains a string formatted as three digits, optionally followed by a space and descriptive text. A client MUST NOT treat the text as significant in any way. Implementations MAY NOT use status codes that are not defined here:</p> <p>200 - OK. The NORFAB worker executed the request successfully.  202 - ACCEPTED. The NORFAB Broker accepted POST request to dispatch the job. 300 - PENDING. The client SHOULD retry the request at a later time. 400 - UNKNOWN. The client is using an invalid or unknown UUID and SHOULD NOT retry. 408 - REQUEST TIMEOUT. Client did not receive response from broker or worker. 417 - EXPECT FAILED. Client did not receive what it was expecting to receive. 500 - ERROR. The server cannot complete the request due to some internal error. The client SHOULD retry at some later time.</p>"},{"location":"reference_architecture_nfp/#nfpclient","title":"NFP/Client","text":"<p>NFP/Client is a strictly synchronous dialog initiated by the client (where \u2018C\u2019 represents the client, and \u2018B\u2019 represents the broker):</p> <pre><code>C: OPEN\nB: OPEN\n\nRepeat:\n\n    C: POST\n    B: RESPONSE\n    ...\n\n    C: GET\n    B: RESPONSE\n    ...\n</code></pre> <p>Clients SHOULD use a REQ socket when implementing a synchronous request-reply pattern. The REQ socket will silently create frame 0 for outgoing requests, and remove it for replies before passing them to the calling application. </p> <p>Clients MAY use any suitable strategy for recovering from a non-responsive broker. One recommended strategy is:</p> <ul> <li>To use polling instead of blocking receives on the request socket.</li> <li>If there is no reply within some timeout, to close the request socket and open a new socket, and resend the request on that new socket.</li> <li>If there is no reply after several retries, to signal the transaction as failed.</li> <li>The service name is a 0MQ string that matches the service name specified by a worker in its READY command (see NFP/Worker below). The broker SHOULD queue client requests for which service no workers has been registered and SHOULD expire these requests after a reasonable and configurable time if no service's workers has been registered.</li> </ul>"},{"location":"reference_architecture_nfp/#nfpbroker","title":"NFP/Broker","text":"<p>NFP/Broker is a mediator that receives messages from clients and dispatches them out to workers. In return messages from workers routed to clients.</p>"},{"location":"reference_architecture_nfp/#nfpworker","title":"NFP/Worker","text":"<p>NFP/Worker is a mix of a synchronous request-reply dialog, initiated by the service worker, and an asynchronous heartbeat dialog that operates independently in both directions. This is the synchronous dialog (where \u2018W\u2019 represents the service worker, and \u2018B\u2019 represents the broker):</p> <pre><code>W: OPEN\nB: OPEN\nW: READY\n\nRepeat:\n\n    B: POST\n    W: RESPONSE\n    ...\n\n    B: GET\n    W: RESPONSE\n    ... \n</code></pre> <p>The asynchronous heartbeat dialog operates on the same sockets and works thus:</p> <pre><code>Repeat:                 Repeat:\n\n    W: HEARTBEAT            B: HEARTBEAT\n    ...                     ...\n\nW: DISCONNECT           B: DISCONNECT\n</code></pre> <p>NFP/Worker commands all start with an empty frame to allow consistent processing of client and worker frames in a broker, over a single socket. The empty frame has no other significance.</p>"},{"location":"reference_architecture_nfp/#nfpworker-pub","title":"NFP/Worker-PUB","text":"<p>TBD </p>"},{"location":"reference_architecture_nfp/#nfpbroker-pub","title":"NFP/Broker-PUB","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#job-persistence","title":"Job Persistence","text":"<p>Workers SHOULD persistently store job requests and job execution results for a configurable amount of time allowing clients (client submitted job request or any other client) to request job execution results on demand.</p> <p>Clients SHOULD persistently store job requests and MAY store job execution results locally for a configurable amount of time.</p>"},{"location":"reference_architecture_nfp/#opening-and-closing-a-connection","title":"Opening and Closing a Connection","text":"<p>The worker is responsible for opening and closing a logical connection. One worker MUST connect to exactly one broker using a single \u00d8MQ DEALER (XREQ) socket.</p> <p>Since \u00d8MQ automatically reconnects peers after a failure, every NFP command includes the protocol header to allow proper validation of all messages that a peer receives.</p> <p>The worker opens the connection to the broker by creating a new socket, connecting it, and then sending a READY command to register to a service. One worker handles precisely one service, and many workers MAY handle the same service. The worker MUST NOT send a further READY.</p> <p>There is no response to a READY. The worker SHOULD assume the registration succeeded until or unless it receives a DISCONNECT, or it detects a broker failure through heartbeating.</p> <p>The worker MAY send DISCONNECT at any time, including before READY. When the broker receives DISCONNECT from a worker it MUST send no further commands to that worker.</p> <p>The broker MAY send DISCONNECT at any time, by definition after it has received at least one command from the worker.</p> <p>The broker MUST respond to any valid but unexpected command by sending DISCONNECT and then no further commands to that worker. The broker SHOULD respond to invalid messages by dropping them and treating that peer as invalid.</p> <p>When the worker receives DISCONNECT it must send no further commands to the broker; it MUST close its socket, and reconnect to the broker on a new socket. This mechanism allows workers to re-register after a broker failure and recovery.</p>"},{"location":"reference_architecture_nfp/#post-and-response-processing","title":"POST and RESPONSE Processing","text":"<p>The POST and the RESPONSE commands MUST contain precisely one client address frame. This frame MUST be followed by an empty (zero sized) frame.</p> <p>The address of each directly connected client is prepended by the ROUTER socket to all request messages coming from clients. That ROUTER socket also expects a client address to be prepended to each reply message sent to a client.</p>"},{"location":"reference_architecture_nfp/#keepaliving","title":"Keepaliving","text":"<p>KEEPALIVE commands are valid at any time, after a READY command.</p> <p>Any received command except DISCONNECT acts as a keepalive. Peers SHOULD NOT send KEEPALIVE commands while also sending other commands.</p> <p>Both broker and worker MUST send heartbeats at regular and agreed-upon intervals. A peer MUST consider the other peer \u201cdisconnected\u201d if no keepalive arrives within some multiple of that interval (usually 3-5).</p> <p>If the worker detects that the broker has disconnected, it SHOULD restart a new conversation.</p> <p>If the broker detects that the worked has disconnected, it SHOULD stop sending messages of any type to that worker.</p>"},{"location":"reference_architecture_nfp/#broker-management-interface-bmmi","title":"Broker Management Interface (BMMI)","text":"<p>Broker SHOULD implement Management interface as a service endpoint for clients to interact with.</p> <p>Broker should use <code>mmi.service.broker</code> service endpoint to listen to client's requests. </p> <p>These MMI functions SHOULD be implemented:</p> <ul> <li><code>show_broker</code> - to return broker status and statistics</li> <li><code>show_workers</code> - to return worker status and statistics </li> <li><code>show_clients</code> - to return clients statistics</li> <li><code>show_services</code> - to return services status and statistics </li> <li><code>restart</code> - restart broker</li> <li><code>shutdown</code> - shutdown broker completely</li> <li><code>disconnect</code> - to disconnect all workers</li> </ul>"},{"location":"reference_architecture_nfp/#worker-management-interface-wmmi","title":"Worker Management Interface (WMMI)","text":"<p>Worker SHOULD implement Management interface as a service endpoint for clients to interact with.</p> <p>Worker should use <code>mmi.service.worker</code> service endpoint to listen to client's requests. </p> <p>These MMI functions SHOULD be implemented:</p> <ul> <li><code>show_broker</code> - to return broker status and statistics</li> <li><code>show_workers</code> - to return worker status and statistics </li> <li><code>show_clients</code> - to return clients statistics</li> <li><code>restart</code> - restart worker</li> <li><code>shutdown</code> - shutdown worker completely</li> <li><code>disconnect</code> - to disconnect worker from broker and re-establish connection</li> </ul>"},{"location":"reference_architecture_nfp/#broker-simple-inventory-datastore-sid","title":"Broker Simple Inventory Datastore (SID)","text":"<p>Broker should implement Inventory Datastore to store and serve configuration to workers as well as arbitrary workers inventory data.</p> <p>Broker should use <code>sid.service.broker</code> service endpoint to listen to worker's requests. </p> <p>Workers willing to make use of broker's inventory datastore should implement <code>NFP/Client</code> protocol defined above to request inventory data.</p> <p>These SID functions SHOULD be implemented:</p> <ul> <li><code>get_inventory</code> - to return inventory content for given worker</li> </ul>"},{"location":"reference_architecture_nfp/#sid-implementation","title":"SID Implementation","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#broker-file-sharing-service-fss","title":"Broker File Sharing Service (FSS)","text":"<p>Broker implements service to serve files to clients and workers from local file system using <code>nf://&lt;filepath&gt;</code> URL for supported arguments.</p> <p>Broker should use <code>fss.service.broker</code> service endpoint to listen to worker's requests. </p>"},{"location":"reference_architecture_nfp/#fss-implementation","title":"FSS Implementation","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#reliability","title":"Reliability","text":"<p>The NORFAB pattern is designed to extend the basic \u00d8MQ request-reply pattern with the ability to detect and recover from a specific set of failures:</p> <ul> <li>Worker applications which crash, run too slowly, or freeze.</li> <li>Worker applications that are disconnected from the network (temporarily or permanently).</li> <li>Client applications that are temporarily disconnected from the network.</li> <li>A queue broker that crashes and is restarted.</li> <li>A queue broker that suffers a permanent failure.</li> <li>Requests or replies that are lost due to any of these failures.</li> <li>The general approach is to retry and reconnect, using heartbeating when needed. </li> </ul>"},{"location":"reference_architecture_nfp/#scalability-and-performance","title":"Scalability and Performance","text":"<p>NORFAB is designed to be scalable to large numbers (thousands) of workers and clients allowing to manage 10s of thousands resource entities, limited only by system resources on the broker. Partitioning of workers by service allows for multiple applications to share the same broker infrastructure. Workers manage a set of resources defined by system administrator. Same resource can be managed by single or multiple workers, system impose no restrictions on how resource entities distributed across workers.</p> <p>Throughput performance for a single client application will be limited to tens of thousands, not millions, of request-reply transactions per second due to round-trip costs and the extra latency of a broker-based approach. The larger the request and reply messages, the more efficient NORFAB will become. </p> <p>System requirements for the broker are moderate: no more than one outstanding request per client will be queued, and message contents can be switched between clients and workers without copying or processing. A single broker thread can therefore switch several million messages per second.</p>"},{"location":"reference_architecture_nfp/#security","title":"Security","text":""},{"location":"reference_architecture_nfp/#worker-authentication","title":"Worker Authentication","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#worker-authorization","title":"Worker Authorization","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#client-authentication","title":"Client Authentication","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#client-authorization-role-based-access-control-rbac","title":"Client Authorization - Role Based Access Control (RBAC)","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#client-encryption","title":"Client Encryption","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#worker-encryption","title":"Worker Encryption","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#accounting","title":"Accounting","text":"<p>TBD</p>"},{"location":"reference_architecture_nfp/#known-weaknesses","title":"Known Weaknesses","text":"<ul> <li>The heartbeat rate must be set to similar values in broker and worker, or false disconnections will occur. </li> <li>The use of multiple frames for command formatting has a performance impact.</li> </ul>"},{"location":"reference_architecture_norfab/","title":"NORFAB Architecture","text":""},{"location":"reference_architecture_norfab/#high-level-design","title":"High Level Design","text":""},{"location":"reference_architecture_norfab/#low-level-design","title":"Low Level Design","text":"<p>Low level design revolves around resource oriented services - services that manage resources, where resources could be databases, network devices, file system etc.</p> <p></p>"},{"location":"reference_architecture_norfab/#jobs-execution-flow","title":"Jobs Execution Flow","text":"<p>There are multiple job flows implemented:</p> <ul> <li>JOB POST FLOW - for clients to publish jobs to workers</li> <li>JOB LOOP - job execution performed by workers</li> <li>JOB GET FLOW - for clients to retrieve job execution results</li> </ul> <p>Above flows depicted on the diagram.</p> <p></p>"},{"location":"reference_norfab_inventory/","title":"NorFab Inventory","text":"<p>NorFab comes with Simple Inventory Datastore (SID) hosted by broker, allowing workers to source inventory data from broker.</p> <p>NorFab inventory separated in sections, each responsible for configuring different aspects of the system.</p> inventory.yaml<pre><code>broker: # (1)!\n  endpoint: \"tcp://127.0.0.1:5555\" # (2)!\n\nworkers: # (3)!\n  nornir-*: # (4)!\n    - nornir/common.yaml   \n  nornir-worker-1: # (5)!\n    - nornir/nornir-worker-1.yaml\n\ntopology: # (6)!\n  broker: True # (7)!\n  workers: # (8)!\n    - nornir-worker-1\n\nlogging: # (9)!\n  handlers:\n    terminal:\n      level: WARNING\n    file: \n      level: INFO\n</code></pre> <ol> <li>Broker configuration inventory section</li> <li>URL to listen for connections on - <code>localhost</code> port <code>5555</code> in this case</li> <li>Workers configuration inventory section</li> <li>glob pattern that will match all workers with <code>nornir-</code> in the name and map <code>common.yaml</code> file content for each of them</li> <li>Worker definition to map inventory file to a specific worker that has name <code>nornir-worker-1</code></li> <li>Topology section to define what components to run</li> <li>Start broker process</li> <li>List of workers names to start processes for</li> <li>Logging configuration section</li> </ol>"},{"location":"reference_norfab_inventory/#broker-inventory-section","title":"Broker Inventory Section","text":"<p>Broker inventory must have <code>broker_endpoint</code> parameter defined for workers and clients to identify how connect with broker, and for broker itself to identify where to listen for connections.</p> inventory.yaml<pre><code># broker settings\nbroker:\n  endpoint: \"tcp://127.0.0.1:5555\"\n  shared_key: \"5z1:yW}]n?UXhGmz+5CeHN1&gt;:S9k!eCh6JyIhJqO\"\n</code></pre> <p>In addition these parameters are supported</p> <ol> <li><code>shared_key</code> - broker encryption shared key may or may not be needed depending of type of the setup you are running, in case if all components - broker, client and workers run on same machine, configuring <code>shared_key</code> parameter is options, as <code>nfapi</code> is smart enough to auto-configure all workers and client with correct broker shared key. In case if broker and workers with clients are distributed i.e. running in separate containers or on separate machines, <code>share_key</code> parameter must be configured on all workers and clients to match shared key used by broker.</li> </ol>"},{"location":"reference_norfab_inventory/#workers-inventory-section","title":"Workers Inventory Section","text":"<p>To understand how Simple Inventory Datastore serves workers inventory it is good to know that each worker has a unique name to identify it.</p> <p>With that in mind, the goal is to map inventory data to individual worker by its name.</p> <p>For example, let's pretend that worker name is <code>nornir-worker-1</code> and we have <code>common.yaml</code> and <code>nornir-worker-1.yaml</code> files with inventory data  that we need to provide worker with.</p> <p>To do the mapping between worker name and inventory files we can put this in NorFab inventory (<code>inventory.yaml</code>) file:</p> inventory.yaml<pre><code>workers:\n  nornir-*:\n    - nornir/common.yaml  \n  nornir-worker-1:\n    - nornir/nornir-worker-1.yaml\n</code></pre> <p>Where files structure would look like this:</p> <pre><code>\u2514\u2500\u2500\u2500rootfolder\n    \u2502   inventory.yaml\n    \u2502\n    \u2514\u2500\u2500\u2500nornir\n            common.yaml\n            nornir-worker-1.yaml\n</code></pre> <p>As you can see, <code>inventory.yaml</code> file contains <code>workers</code> section with a dictionary keyed by glob patterns  to match against workers' names, once worker name matched by the pattern, all items in the list underneaths that pattern being loaded and recursively merged. As such, process continues until all patterns evaluated. Final output of the process is a combined inventory data of all the matched files.</p> <p>The recursive logic of combining inventory data files is pretty  straightforward - each next data file merged into the previous data file  overriding the overlapping values.</p> <p>The glob pattern matching logic allows be as specific as required and  map specific files to individual workers or to map single data file to  multiple workers or map multiple files to multiple workers, all combinations  supported.</p> <p>For example, we have a group of two workers with names <code>netbox-wroker-1.1</code> and <code>netbox-worker-1.2</code> and we want to map <code>netbox_common.yaml</code> to both of the workers, in that case NorFab inventory (<code>inventory.yaml</code>) file could have this content:</p> inventory.yaml<pre><code>workers:\n  netbox-worker-1.*:\n    - nornir/netbox_common.yaml  \n</code></pre> <p>Where files structure would look like this:</p> <pre><code>\u2514\u2500\u2500\u2500rootfolder\n    \u2502   inventory.yaml\n    \u2502\n    \u2514\u2500\u2500\u2500netbox\n            netbox_common.yaml\n</code></pre> <p>Both workers will be served with  <code>netbox_common.yaml</code> file content as an inventory data.</p>"},{"location":"reference_norfab_inventory/#workers-inventory-parameters","title":"Workers Inventory Parameters","text":"<p>Workers inventory can contain these common parameters:</p> <ol> <li><code>service</code> - name of the service this worker belongs to</li> </ol> <p>Sample worker base inventory:</p> <pre><code>service: nornir\n</code></pre> <p>The rest of the inventory data is worker specific.</p>"},{"location":"reference_norfab_inventory/#topology-inventory-section","title":"Topology Inventory Section","text":"<p>Topology section of NorFab inventory identifies the components that need to be started on the given node.</p>"},{"location":"reference_norfab_inventory/#logging-inventory-section","title":"Logging Inventory Section","text":"<p>Logging inventory section allows to configure logging parameters such file retention option, logging to remote hosts, logging levels etc.</p>"},{"location":"reference_norfab_inventory/#hooks-section","title":"Hooks Section","text":"<p>Hooks section allows to configure a list of functions to run during NorFab execution lifespan events.</p> <p>Supported attach points:</p> <ul> <li><code>startup</code> - list of functions to run right after NorFab nfapi started broker and worker process and fully initialized. Startup hook function must accept <code>norfab</code> object as a single argument.</li> <li><code>exit</code> - list of functions to run right before NorFab nfapi initiates exit sequence. Exit hook function must accept <code>norfab</code> object as a single argument.</li> </ul> <p>Each hook defined as a dictionary that can contain these keys:</p> <ul> <li><code>function</code> - Python import path for hook function</li> <li><code>attachpoint</code> - one of the attach points indicating when to run hook function e.g. <code>startup</code></li> <li><code>args</code> - optional list of function positional arguments</li> <li><code>kwargs</code> - optional dictionary of function key-word arguments</li> </ul> <p>Sample hooks definition:</p> inventory.yaml<pre><code>hooks:\n  - attachpoint: startup\n    function: \"hooks.functions.do_on_startup\"\n    args: []\n    kwargs: {}\n    description: \"Function to run on startup\"\n  - attachpoint: exit\n    function: \"hooks.functions.do_on_exit\"\n    args: []\n    kwargs: {}\n    description: \"Function to run on startup\"\n</code></pre> <p>Where hook functions are:</p> hooks/functions.py<pre><code>def do_on_startup(norfab):\n    print(\"Startup hook executed\")\n\ndef do_on_exit(norfab):\n    print(\"Exit hook executed\")\n</code></pre> <p>Function import path is a dot separated path used to import module file that contains hook functions, where individual function name is a last item in dot separated path definition. For example <code>hooks.functions.do_on_startup</code> path is equivalent of running Python import <code>from hooks.functions import do_on_startup</code>.</p>"},{"location":"reference_norfab_inventory/#jinja2-support","title":"Jinja2 Support","text":"<p>Starting with version 0.3.0 NorFab supports Jinja2 syntax rendering of inventory files, in addition, <code>env</code> dictionary variable available to source environment variables:</p> inventory.yaml<pre><code>logging:\n  handlers:\n    terminal:\n      level: {{ env.get(\"TERMINAL_LOGGING_LEVEL\", \"WARNING\") }}\n    file: \n      level: {{ env.get(\"FILE_LOGGING_LEVEL\", \"INFO\") }}\n</code></pre> <p>Above example demonstrates how terminal and file logging level can be sourced from environment using Jinja2 syntax. </p> <p>All workers inventory files also passed through Jinja2 renderer with access to <code>env</code> dictionary variable:</p> nornir/common.yaml<pre><code>defaults:\n  username: {{ env.get(\"NORNIR_USERNAME\", \"nornir\") }}\n  password: {{ env.get(\"NORNIR_PASSWORD\", \"password\" ) }}\n</code></pre> <p><code>env</code> variable passed onto Jinja2 context as a dictionary that contains environment variables keys and values supporting all Jinja2 dictionary access operations:</p> nornir/common.yaml<pre><code>defaults:\n  username: {{ env[\"NORNIR_USERNAME\"] }}\n  password: {{ env.NORNIR_PASSWORD }}\n  port: {{ env.get(\"NORNIR_PORT\", 22) }}\n</code></pre>"},{"location":"reference_norfab_inventory/#loading-inventory-from-dictionary","title":"Loading Inventory from Dictionary","text":"<p>By default NorFab supports loading inventory from <code>inventory.yaml</code> file together with <code>workers</code> section items referring to a list of OS paths to YAML files with workers inventory data. As an alternative it is possible to load full NorFab and its workers inventory from dictionary, this can be useful when working with NorFab Python API directly:</p> Instantiate NorFab out of Dictionary Inventory<pre><code>from norfab.core.nfapi import NorFab\n\ndata = {\n    \"broker\": {\n        \"endpoint\": \"tcp://127.0.0.1:5555\",\n        \"shared_key\": \"5z1:yW}]n?UXhGmz+5CeHN1&gt;:S9k!eCh6JyIhJqO\",\n    },\n    \"workers\": {\n        \"nornir-*\": [\n            {\n                \"service\": \"nornir\",\n                \"watchdog_interval\": 30,\n                \"runner\": {\n                    \"plugin\": \"RetryRunner\",\n                    \"options\": {\n                        \"num_workers\": 100,\n                        \"num_connectors\": 10,\n                    }\n                }\n            }\n        ],\n        \"nornir-worker-1*\": [\"nornir/nornir-worker-1.yaml\"],\n        \"nornir-worker-2\": [\n            \"nornir/nornir-worker-2.yaml\",\n            \"nornir/nornir-worker-2-extra.yaml\",\n        ],\n    },\n    \"topology\": {\n        \"broker\": True,\n        \"workers\": [\n            \"nornir-worker-1\",\n            \"nornir-worker-2\",\n        ],\n    },\n}\n\nif __name__ == \"__main__\":\n    nf = NorFab(inventory_data=data, base_dir=\"./norfab/\")\n    nf.start()\n    client = nf.make_client()\n\n    job_result = client.run_job(\"nornir\", \"get_nornir_hosts\")\n    print(job_result)\n\n    nf.destroy()\n</code></pre> <p>In above example, <code>data</code> dictionary contains complete NorFab inventory and passed onto <code>NorFab</code> object together with <code>base_dir</code> argument to inform NorFab where to search for inventory YAML files, for example <code>\"nornir/nornir-worker-2.yaml\"</code> file will be searched within this path <code>\"./norfab/nornir/nornir-worker-2.yaml\"</code> since <code>./norfab/</code> is a base directory. Base directory argument is optional and will be automatically set by NorFab to current directory.</p>"},{"location":"services_overview/","title":"Services Overview","text":"<p>Services is where NORFAB value comes from as it is capable of managing diverse set of resources through them.</p>","tags":["services"]},{"location":"tags/","title":"Tags","text":"<p>Following is a list of tags:</p>"},{"location":"tags/#tag:fastapi","title":"FastAPI","text":"<ul> <li>            Overview          </li> </ul>"},{"location":"tags/#tag:netbox","title":"Netbox","text":"<ul> <li>            Overview          </li> </ul>"},{"location":"tags/#tag:agent","title":"agent","text":"<ul> <li>            Chat          </li> <li>            Overview          </li> </ul>"},{"location":"tags/#tag:netbox","title":"netbox","text":"<ul> <li>            GET Circuits          </li> <li>            GET Connections          </li> <li>            GET Devices          </li> <li>            GET Interfaces          </li> <li>            GET Nornir Inventory          </li> <li>            GraphQL          </li> <li>            REST          </li> <li>            UPDATE Device Facts          </li> <li>            UPDATE Device Interfaces          </li> </ul>"},{"location":"tags/#tag:nfcli","title":"nfcli","text":"<ul> <li>            NFCLI Client API          </li> <li>            NFCLI Shell          </li> </ul>"},{"location":"tags/#tag:norfab","title":"norfab","text":"<ul> <li>            Docker Deployment          </li> <li>            Getting Started          </li> </ul>"},{"location":"tags/#tag:nornir","title":"nornir","text":"<ul> <li>            CFG          </li> <li>            CLI          </li> <li>            Diagram          </li> <li>            File Copy          </li> <li>            Jina2 Filters Reference          </li> <li>            Network          </li> <li>            Nornir Task          </li> <li>            Overview          </li> <li>            Parse          </li> <li>            Runtime Inventory          </li> <li>            Test          </li> </ul>"},{"location":"tags/#tag:robot","title":"robot","text":"<ul> <li>            ROBOT API          </li> <li>            ROBOT Client API          </li> </ul>"},{"location":"tags/#tag:services","title":"services","text":"<ul> <li>            Services Overview          </li> </ul>"},{"location":"customization/norfab_hooks/","title":"NORFAB Hooks System","text":""},{"location":"customization/norfab_hooks/#norfab-hooks","title":"NORFAB Hooks","text":"<p>Hooks is a set of functions to run during NorFab execution lifespan.</p> <p>NorFab supports definition of hooks inside <code>inventory.yaml</code> file within <code>hooks</code> section.</p> <p>Each hook defined as a dictionary that can contain these keys:</p> <ul> <li><code>function</code> - Python import path for hook function</li> <li><code>attachpoint</code> - one of the attach points indicating when to run hook function e.g. <code>startup</code></li> <li><code>args</code> - optional list of function positional arguments</li> <li><code>kwargs</code> - optional dictionary of function key-word arguments</li> </ul> <p>Supported attach points:</p> <ul> <li><code>startup</code> - list of functions to run right after NorFab nfapi fully initialized. Startup hook function must accept <code>norfab</code> object as a single argument.</li> <li><code>exit</code> - list of functions to run right before NorFab nfapi initiates exit sequence. Exit hook function must accept <code>norfab</code> object as a single argument.</li> </ul> <p>Sample hooks definition:</p> inventory.yaml<pre><code>hooks:\n  - attachpoint: startup\n    function: \"hooks.functions.do_on_startup\"\n    args: []\n    kwargs: {}\n    description: \"Function to run on startup\"\n  - attachpoint: exit\n    function: \"hooks.functions.do_on_exit\"\n    args: []\n    kwargs: {}\n    description: \"Function to run on startup\"\n</code></pre> <p>Where hook functions are:</p> hooks/functions.py<pre><code>def do_on_startup(norfab):\n    print(\"Startup hook executed\")\n\ndef do_on_exit(norfab):\n    print(\"Exit hook executed\")\n</code></pre> <p>Function import path is a dot separated path used to import module file that contains hook functions, where individual function name is a last item in dot separated path definition. For example <code>hooks.functions.do_on_startup</code> path is equivalent of running Python import <code>from hooks.functions import do_on_startup</code>.</p>"},{"location":"workers/agent/services_agent_service/","title":"Agent Service","text":"<p>The Agent Service is a key component of the Network Automations Fabric (NORFAB) that leverages AI-based agents to enhance network automation and management.</p> <p></p>","tags":["agent"]},{"location":"workers/agent/services_agent_service/#using-ollama","title":"Using Ollama","text":"<p>Ollama is an application designed to facilitate the use of large language models (LLMs) on your local machine. It provides a user-friendly interface and REST API for interacting with these models, enabling various AI-driven tasks such as natural language processing, text generation, and more. By running Ollama on your PC, you can leverage the power of LLMs for a wide range of applications, including network automation, data analysis, and intelligent agent services.</p> <p>In the context of the NorFab Agent Service, Ollama acts as a bridge between the AI agents and the LLMs, allowing the agents to connect to and utilize the capabilities of the models specified in the inventory. This integration enhances the functionality of the Agent Service, enabling more advanced and intelligent automation tasks.</p> <p>Follow official Guide on how to run Ollama Models - GitHub link</p> <p>Once Ollama application installed, configure NorFab Agent Worker inventory and proceed with running it by updating NorFab <code>inventory.yaml</code> file:</p> inventory.yaml<pre><code>broker:\n  endpoint: \"tcp://127.0.0.1:5555\"\n\nworkers:\n  agent-worker-1:\n    - agents/agent-worker-1.yaml\n\ntopology:\n  broker: True\n  workers:\n    - agent-worker-1\n</code></pre> <p>Where <code>agent-worker-1.yaml</code> content is:</p> <pre><code>service: agent\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\nllm_flavour: ollama\nllm_model: lama3.1:8b\nllm_temperature: 0.5\nllm_base_url: \"http://127.0.0.1:11434\"\n</code></pre>","tags":["agent"]},{"location":"workers/agent/services_agent_service_inventory/","title":"Agent Worker Inventory","text":"<p>Sample Agent Worker Inventory</p> <pre><code>service: agent\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\nllm_flavour: ollama\nllm_model: lama3.1:8b\nllm_temperature: 0.5\nllm_base_url: \"http://127.0.0.1:11434\"\n</code></pre>"},{"location":"workers/agent/services_agent_service_tasks_chat/","title":"Agent Service Chat Task","text":"","tags":["agent"]},{"location":"workers/agent/services_agent_service_tasks_chat/#agent-chat-sample-usage","title":"Agent Chat Sample Usage","text":"","tags":["agent"]},{"location":"workers/agent/services_agent_service_tasks_chat/#norfab-agent-chat-shell-reference","title":"NORFAB Agent Chat Shell Reference","text":"<p>NorFab shell supports these command options for Agent <code>chat</code> task:</p> <pre><code>nf#man tree agent\nroot\n\u2514\u2500\u2500 agent:    AI Agent service\n    \u251c\u2500\u2500 timeout:    Job timeout\n    \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n    \u251c\u2500\u2500 show:    Show Agent service parameters\n    \u2502   \u251c\u2500\u2500 inventory:    show agent inventory data\n    \u2502   \u251c\u2500\u2500 version:    show agent service version report\n    \u2502   \u2514\u2500\u2500 status:    show agent status\n    \u251c\u2500\u2500 chat:    Chat with the agent\n    \u2514\u2500\u2500 progress:    Emit execution progress, default 'True'\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["agent"]},{"location":"workers/agent/services_agent_service_tasks_chat/#python-api-reference","title":"Python API Reference","text":"<p>Handles the chat interaction with the user by processing the input through a language model.</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <p>The input provided by the user.</p> required <code>template</code> <p>A template string for formatting the prompt. Defaults to this string: 'Question: {user_input}; Answer: Let's think step by step. Provide answer in markdown format.'</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>language model's response</p> Source code in <code>norfab\\workers\\agent_worker.py</code> <pre><code>def chat(self, user_input, template=None) -&gt; str:\n    \"\"\"\n    Handles the chat interaction with the user by processing the input through a language model.\n\n    :param user_input: The input provided by the user.\n    :param template: A template string for formatting the prompt. Defaults to\n        this string: 'Question: {user_input}; Answer: Let's think step by step.\n        Provide answer in markdown format.'\n    :returns: language model's response\n    \"\"\"\n    if self.llm_flavour == \"ollama\":\n        return self._chat_ollama(user_input, template)\n    else:\n        raise Exception(f\"Unsupported llm flavour {self.llm_flavour}\")\n</code></pre>","tags":["agent"]},{"location":"workers/fastapi/services_fastapi_service/","title":"FastAPI REST API Service","text":"<p>The FastAPI Service created to serve a set of REST API endpoints to interact with NorFab to start, run, list jobs and to retrieve jobs result.</p> <p>NorFab FastAPI Service build using FastAPI library, as the name implies, a well adopted open-source library for building RESTful APIs.</p> <p></p>","tags":["FastAPI"]},{"location":"workers/fastapi/services_fastapi_service/#overview","title":"Overview","text":"<p>The FastAPI Service in Norfab provides a robust and efficient way to REST API into NorFab environment for network automation and management tasks. FastAPI is known for its high performance, ease of use, and automatic generation of interactive API documentation. By leveraging FastAPI, Norfab enables developers to utilize scalable and maintainable APIs that can handle a wide range of network automation operations.</p>","tags":["FastAPI"]},{"location":"workers/fastapi/services_fastapi_service/#norfab-fastapi-service-key-features","title":"NorFab FastAPI Service Key Features","text":"<ul> <li> <p>High Performance: FastAPI is built on top of Starlette for the web parts and Pydantic for the data parts, ensuring high performance and fast response times.</p> </li> <li> <p>Automatic Documentation: NorFab FastAPI service comes with automatically generated interactive API documentation using Swagger UI and ReDoc, making it easy to explore and test the API endpoints.</p> </li> <li> <p>Data Validation: FastAPI uses Pydantic for data validation, ensuring that the input and output data is correctly formatted and adheres to the specified schema.</p> </li> <li> <p>Security: NorFab FastAPI service includes Bearer token API authentication, ensuring that the APIs are secure and protected.</p> </li> </ul>","tags":["FastAPI"]},{"location":"workers/fastapi/services_fastapi_service/#use-cases","title":"Use Cases","text":"<ul> <li> <p>Network Device Management: Use the NorFab FastAPI Service for managing network devices, including configuration changes, state retrieval, firmware updates etc.</p> </li> <li> <p>Inventory Management: Use REST API to automate the process of updating and maintaining network inventory, ensuring that the inventory data is always accurate and up-to-date.</p> </li> <li> <p>Configuration Compliance: Utilize REST API to automate configuration compliance checks and audits, ensuring that network devices adhere to predefined standards and policies.</p> </li> <li> <p>Automation Workflows: Use the NorFab FastAPI Service APIs to orchestrate complex automation workflows, integrating with other services and tools to streamline network operations.</p> </li> </ul>","tags":["FastAPI"]},{"location":"workers/fastapi/services_fastapi_service/#getting-started","title":"Getting Started","text":"<p>To get started with the FastAPI Service, you need to define the necessary parameters in your NorFab inventory. Refer to the FastAPI Inventory section for detailed instructions on setting up your inventory and running FastAPI REST API Service with NorFab.</p>","tags":["FastAPI"]},{"location":"workers/fastapi/services_fastapi_service/#conclusion","title":"Conclusion","text":"<p>The FastAPI Service in Norfab provides a powerful and efficient RESTful APIs for network automation and management. With its high performance, automatic documentation, and robust feature set, FastAPI enables API integration that can handle a wide range of network operations. By using NorFab FastAPI REST API service, you can enhance your network automation capabilities and streamline your network management processes.</p>","tags":["FastAPI"]},{"location":"workers/fastapi/services_fastapi_service_inventory/","title":"Inventory","text":"<p>TBD</p>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/","title":"Netbox Worker","text":""},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker","title":"<code>NetboxWorker(inventory, broker, worker_name, service=b'netbox', exit_event=None, init_done_event=None, log_level=None, log_queue=None)</code>","text":"<p>               Bases: <code>NFPWorker</code></p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <p>broker URL to connect to</p> required <code>service</code> <code>str</code> <p>name of the service with worker belongs to</p> <code>b'netbox'</code> <code>worker_name</code> <p>name of this worker</p> required <code>exit_event</code> <p>if set, worker need to stop/exit</p> <code>None</code> <code>init_done_event</code> <p>event to set when worker done initializing</p> <code>None</code> <code>log_keve</code> <p>logging level of this worker</p> required Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def __init__(\n    self,\n    inventory,\n    broker,\n    worker_name,\n    service: str = b\"netbox\",\n    exit_event=None,\n    init_done_event=None,\n    log_level=None,\n    log_queue: object = None,\n):\n    super().__init__(\n        inventory, broker, service, worker_name, exit_event, log_level, log_queue\n    )\n    self.init_done_event = init_done_event\n    self.cache = None\n\n    # get inventory from broker\n    self.netbox_inventory = self.load_inventory()\n    if not self.netbox_inventory:\n        log.critical(\n            f\"{self.name} - Broker {self.broker} returned no inventory for {self.name}, killing myself...\"\n        )\n        self.destroy()\n\n    assert self.netbox_inventory.get(\n        \"instances\"\n    ), f\"{self.name} - inventory has no Netbox instances\"\n\n    # extract parameters from imvemtory\n    self.netbox_connect_timeout = self.netbox_inventory.get(\n        \"netbox_connect_timeout\", 10\n    )\n    self.netbox_read_timeout = self.netbox_inventory.get(\"netbox_read_timeout\", 300)\n    self.cache_use = self.netbox_inventory.get(\"cache_use\", True)\n    self.cache_ttl = self.netbox_inventory.get(\"cache_ttl\", 31557600)  # 1 Year\n\n    # find default instance\n    for name, params in self.netbox_inventory[\"instances\"].items():\n        if params.get(\"default\") is True:\n            self.default_instance = name\n            break\n    else:\n        self.default_instance = name\n\n    # check Netbox compatibility\n    self._verify_compatibility()\n\n    # instantiate cache\n    self.cache_dir = os.path.join(self.base_dir, \"cache\")\n    os.makedirs(self.cache_dir, exist_ok=True)\n    self.cache = self._get_diskcache()\n\n    self.init_done_event.set()\n    log.info(f\"{self.name} - Started\")\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker._get_instance_params","title":"<code>_get_instance_params(name)</code>","text":"<p>Helper function to get inventory params for Netbox instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Netbox instance name</p> required Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def _get_instance_params(self, name: str) -&gt; dict:\n    \"\"\"\n    Helper function to get inventory params for Netbox instance.\n\n    :param name: Netbox instance name\n    \"\"\"\n    if name:\n        ret = self.netbox_inventory[\"instances\"][name]\n    else:\n        ret = self.netbox_inventory[\"instances\"][self.default_instance]\n\n    # check if need to disable SSL warnings\n    if ret.get(\"ssl_verify\") == False:\n        requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n    else:\n        requests.packages.urllib3.enable_warnings(InsecureRequestWarning)\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker._get_pynetbox","title":"<code>_get_pynetbox(instance)</code>","text":"<p>Helper function to instantiate pynetbox api object</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def _get_pynetbox(self, instance):\n    \"\"\"Helper function to instantiate pynetbox api object\"\"\"\n    if not HAS_PYNETBOX:\n        msg = f\"{self.name} - failed to import pynetbox library, is it installed?\"\n        log.error(msg)\n        raise Exception(msg)\n\n    params = self._get_instance_params(instance)\n\n    if params.get(\"ssl_verify\") == False:\n        requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n        nb = pynetbox.api(url=params[\"url\"], token=params[\"token\"])\n        nb.http_session.verify = False\n    else:\n        nb = pynetbox.api(url=params[\"url\"], token=params[\"token\"])\n\n    return nb\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.cache_list","title":"<code>cache_list(keys='*', details=False)</code>","text":"<p>List cache keys.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <p>Pattern to match keys to list</p> <code>'*'</code> <code>details</code> <p>if True add key details, returns just key name otherwise</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>List of cache keys names if details False, else return list of key dictionaries with extra information like age and expire time.</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def cache_list(self, keys=\"*\", details=False) -&gt; list:\n    \"\"\"\n    List cache keys.\n\n    :param keys: Pattern to match keys to list\n    :param details: if True add key details, returns just key name otherwise\n    :returns: List of cache keys names if details False, else return list of\n        key dictionaries with extra information like age and expire time.\n    \"\"\"\n    self.cache.expire()\n    ret = Result(task=f\"{self.name}:cache_list\", result=[])\n    for cache_key in self.cache:\n        if fnmatchcase(cache_key, keys):\n            if details:\n                _, expires = self.cache.get(cache_key, expire_time=True)\n                expires = datetime.fromtimestamp(expires)\n                creation = expires - timedelta(seconds=self.cache_ttl)\n                age = datetime.now() - creation\n                ret.result.append(\n                    {\n                        \"key\": cache_key,\n                        \"age\": str(age),\n                        \"creation\": str(creation),\n                        \"expires\": str(expires),\n                    }\n                )\n            else:\n                ret.result.append(cache_key)\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.cache_clear","title":"<code>cache_clear(key=None, keys=None)</code>","text":"<p>Clears specified cache entries.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>Specific key to clear from the cache</p> <code>None</code> <code>keys</code> <p>Pattern to match multiple keys to clear from the cache</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of cleared keys.</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def cache_clear(self, key=None, keys=None) -&gt; list:\n    \"\"\"\n    Clears specified cache entries.\n\n    :param key: Specific key to clear from the cache\n    :param keys: Pattern to match multiple keys to clear from the cache\n    :returns: List of cleared keys.\n    \"\"\"\n    ret = Result(task=f\"{self.name}:cache_clear\", result=[])\n    # check if has keys to clear\n    if key == keys == None:\n        ret.result = \"Noting to clear, specify key or keys\"\n        return ret\n    # remove specific key from cache\n    if key:\n        if key in self.cache:\n            if self.cache.delete(key, retry=True):\n                ret.result.append(key)\n            else:\n                raise RuntimeError(f\"Failed to remove {key} from cache\")\n        else:\n            ret.messages.append(f\"Key {key} not in cache.\")\n    # remove all keys matching glob pattern\n    if keys:\n        for cache_key in self.cache:\n            if fnmatchcase(cache_key, keys):\n                if self.cache.delete(cache_key, retry=True):\n                    ret.result.append(cache_key)\n                else:\n                    raise RuntimeError(f\"Failed to remove {key} from cache\")\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.cache_get","title":"<code>cache_get(key=None, keys=None, raise_missing=False)</code>","text":"<p>Return data stored in specified cache entries.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>Specific key to get cached data for</p> <code>None</code> <code>keys</code> <p>Pattern to match multiple keys to return cached data</p> <code>None</code> <code>raise_missing</code> <p>if True raises KeyError for missing key</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Requested keys cached data.</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def cache_get(self, key=None, keys=None, raise_missing=False) -&gt; dict:\n    \"\"\"\n    Return data stored in specified cache entries.\n\n    :param key: Specific key to get cached data for\n    :param keys: Pattern to match multiple keys to return cached data\n    :param raise_missing: if True raises KeyError for missing key\n    :returns: Requested keys cached data.\n    \"\"\"\n    ret = Result(task=f\"{self.name}:cache_clear\", result={})\n    # get specific key from cache\n    if key:\n        if key in self.cache:\n            ret.result[key] = self.cache[key]\n        elif raise_missing:\n            raise KeyError(f\"Key {key} not in cache.\")\n    # get all keys matching glob pattern\n    if keys:\n        for cache_key in self.cache:\n            if fnmatchcase(cache_key, keys):\n                ret.result[cache_key] = self.cache[cache_key]\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.graphql","title":"<code>graphql(instance=None, dry_run=False, obj=None, filters=None, fields=None, queries=None, query_string=None)</code>","text":"<p>Function to query Netbox v4 GraphQL API</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>obj</code> <code>dict</code> <p>Object to query</p> <code>None</code> <code>filters</code> <code>dict</code> <p>Filters to apply to the query</p> <code>None</code> <code>fields</code> <code>list</code> <p>Fields to retrieve in the query</p> <code>None</code> <code>queries</code> <code>dict</code> <p>Dictionary of queries to execute</p> <code>None</code> <code>query_string</code> <code>str</code> <p>Raw query string to execute</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[dict, list]</code> <p>GraphQL request data returned by Netbox</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If required arguments are not provided</p> <code>Exception</code> <p>If GraphQL query fails</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def graphql(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    obj: dict = None,\n    filters: dict = None,\n    fields: list = None,\n    queries: dict = None,\n    query_string: str = None,\n) -&gt; Union[dict, list]:\n    \"\"\"\n    Function to query Netbox v4 GraphQL API\n\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param obj: Object to query\n    :param filters: Filters to apply to the query\n    :param fields: Fields to retrieve in the query\n    :param queries: Dictionary of queries to execute\n    :param query_string: Raw query string to execute\n    :return: GraphQL request data returned by Netbox\n    :raises RuntimeError: If required arguments are not provided\n    :raises Exception: If GraphQL query fails\n    \"\"\"\n    nb_params = self._get_instance_params(instance)\n    ret = Result(task=f\"{self.name}:graphql\")\n\n    # form graphql query(ies) payload\n    if queries:\n        queries_list = []\n        for alias, query_data in queries.items():\n            query_data[\"alias\"] = alias\n            if self.nb_version[0] == 4:\n                queries_list.append(_form_query_v4(**query_data))\n            elif self.nb_version[0] == 3:\n                queries_list.append(_form_query_v3(**query_data))\n        queries_strings = \"    \".join(queries_list)\n        query = f\"query {{{queries_strings}}}\"\n    elif obj and filters and fields:\n        if self.nb_version[0] == 4:\n            query = _form_query_v4(obj, filters, fields)\n        elif self.nb_version[0] == 3:\n            query = _form_query_v3(obj, filters, fields)\n        query = f\"query {{{query}}}\"\n    elif query_string:\n        query = query_string\n    else:\n        raise RuntimeError(\n            f\"{self.name} - graphql method expects quieries argument or obj, filters, \"\n            f\"fields arguments or query_string argument provided\"\n        )\n    payload = json.dumps({\"query\": query})\n\n    # form and return dry run response\n    if dry_run:\n        ret.result = {\n            \"url\": f\"{nb_params['url']}/graphql/\",\n            \"data\": payload,\n            \"verify\": nb_params.get(\"ssl_verify\", True),\n            \"headers\": {\n                \"Content-Type\": \"application/json\",\n                \"Accept\": \"application/json\",\n                \"Authorization\": f\"Token ...{nb_params['token'][-6:]}\",\n            },\n        }\n        return ret\n\n    # send request to Netbox GraphQL API\n    log.debug(\n        f\"{self.name} - sending GraphQL query '{payload}' to URL '{nb_params['url']}/graphql/'\"\n    )\n    req = requests.post(\n        url=f\"{nb_params['url']}/graphql/\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Token {nb_params['token']}\",\n        },\n        data=payload,\n        verify=nb_params.get(\"ssl_verify\", True),\n        timeout=(self.netbox_connect_timeout, self.netbox_read_timeout),\n    )\n    try:\n        req.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"{self.name} -  Netbox GraphQL query failed, query '{query}', \"\n            f\"URL '{req.url}', status-code '{req.status_code}', reason '{req.reason}', \"\n            f\"response content '{req.text}'\"\n        )\n\n    # return results\n    reply = req.json()\n    if reply.get(\"errors\"):\n        msg = f\"{self.name} - GrapQL query error '{reply['errors']}', query '{payload}'\"\n        log.error(msg)\n        ret.errors.append(msg)\n        if reply.get(\"data\"):\n            ret.result = reply[\"data\"]  # at least return some data\n    elif queries or query_string:\n        ret.result = reply[\"data\"]\n    else:\n        ret.result = reply[\"data\"][obj]\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.rest","title":"<code>rest(instance=None, method='get', api='', **kwargs)</code>","text":"<p>Method to query Netbox REST API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>method</code> <code>str</code> <p>requests method name e.g. get, post, put etc.</p> <code>'get'</code> <code>api</code> <code>str</code> <p>api url to query e.g. \"extras\" or \"dcim/interfaces\" etc.</p> <code>''</code> <code>kwargs</code> <p>any additional requests method's arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[dict, list]</code> <p>REST API Query result</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If REST API query fails</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def rest(\n    self, instance: str = None, method: str = \"get\", api: str = \"\", **kwargs\n) -&gt; Union[dict, list]:\n    \"\"\"\n    Method to query Netbox REST API.\n\n    :param instance: Netbox instance name\n    :param method: requests method name e.g. get, post, put etc.\n    :param api: api url to query e.g. \"extras\" or \"dcim/interfaces\" etc.\n    :param kwargs: any additional requests method's arguments\n    :return: REST API Query result\n    :raises Exception: If REST API query fails\n    \"\"\"\n    params = self._get_instance_params(instance)\n\n    # send request to Netbox REST API\n    response = getattr(requests, method)(\n        url=f\"{params['url']}/api/{api}/\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Token {params['token']}\",\n        },\n        verify=params.get(\"ssl_verify\", True),\n        **kwargs,\n    )\n\n    response.raise_for_status()\n\n    return response.json()\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_devices","title":"<code>get_devices(filters=None, instance=None, dry_run=False, devices=None, cache=None)</code>","text":"<p>Function to retrieve devices data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list</code> <p>list of filters dictionaries to filter devices</p> <code>None</code> <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>devices</code> <code>list</code> <p>list of device names to query data for</p> <code>None</code> <code>cache</code> <code>Union[bool, str]</code> <p>if <code>True</code> use data stored in cache if it is up to date refresh it otherwise, <code>False</code> do not use cache do not update cache, <code>refresh</code> ignore data in cache and replace it with data fetched from Netbox, <code>force</code> use data in cache without checking if it is up to date</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with device data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_devices(\n    self,\n    filters: list = None,\n    instance: str = None,\n    dry_run: bool = False,\n    devices: list = None,\n    cache: Union[bool, str] = None,\n) -&gt; dict:\n    \"\"\"\n    Function to retrieve devices data from Netbox using GraphQL API.\n\n    :param filters: list of filters dictionaries to filter devices\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param devices: list of device names to query data for\n    :param cache: if `True` use data stored in cache if it is up to date\n        refresh it otherwise, `False` do not use cache do not update cache,\n        `refresh` ignore data in cache and replace it with data fetched\n        from Netbox, `force` use data in cache without checking if it is up\n        to date\n    :return: dictionary keyed by device name with device data\n    \"\"\"\n    ret = Result(task=f\"{self.name}:get_devices\", result={})\n    cache = self.cache_use if cache is None else cache\n    instance = instance or self.default_instance\n    filters = filters or []\n    devices = devices or []\n    queries = {}  # devices queries\n    device_fields = [\n        \"name\",\n        \"last_updated\",\n        \"custom_field_data\",\n        \"tags {name}\",\n        \"device_type {model}\",\n        \"role {name}\",\n        \"config_context\",\n        \"tenant {name}\",\n        \"platform {name}\",\n        \"serial\",\n        \"asset_tag\",\n        \"site {name slug tags{name} }\",\n        \"location {name}\",\n        \"rack {name}\",\n        \"status\",\n        \"primary_ip4 {address}\",\n        \"primary_ip6 {address}\",\n        \"airflow\",\n        \"position\",\n    ]\n\n    if cache == True or cache == \"force\":\n        # retrieve last updated data from Netbox for devices\n        last_updated_query = {\n            f\"devices_by_filter_{index}\": {\n                \"obj\": \"device_list\",\n                \"filters\": filter_item,\n                \"fields\": [\"name\", \"last_updated\"],\n            }\n            for index, filter_item in enumerate(filters)\n        }\n        if devices:\n            # use cache data without checking if it is up to date for cached devices\n            if cache == \"force\":\n                for device_name in list(devices):\n                    device_cache_key = f\"get_devices::{device_name}\"\n                    if device_cache_key in self.cache:\n                        devices.remove(device_name)\n                        ret.result[device_name] = self.cache[device_cache_key]\n            # query netbox last updated data for devices\n            if self.nb_version[0] == 4:\n                dlist = '[\"{dl}\"]'.format(dl='\", \"'.join(devices))\n                filters_dict = {\"name\": f\"{{in_list: {dlist}}}\"}\n            elif self.nb_version[0] == 3:\n                filters_dict = {\"name\": devices}\n            last_updated_query[\"devices_by_devices_list\"] = {\n                \"obj\": \"device_list\",\n                \"filters\": filters_dict,\n                \"fields\": [\"name\", \"last_updated\"],\n            }\n        last_updated = self.graphql(\n            queries=last_updated_query, instance=instance, dry_run=dry_run\n        )\n        last_updated.raise_for_status(f\"{self.name} - get devices query failed\")\n\n        # return dry run result\n        if dry_run:\n            ret.result[\"get_devices_dry_run\"] = last_updated.result\n            return ret\n\n        # try to retrieve device data from cache\n        self.cache.expire()  # remove expired items from cache\n        for devices_list in last_updated.result.values():\n            for device in devices_list:\n                device_cache_key = f\"get_devices::{device['name']}\"\n                # check if cache is up to date and use it if so\n                if device_cache_key in self.cache and (\n                    self.cache[device_cache_key][\"last_updated\"]\n                    == device[\"last_updated\"]\n                    or cache == \"force\"\n                ):\n                    ret.result[device[\"name\"]] = self.cache[device_cache_key]\n                    # remove device from list of devices to retrieve\n                    if device[\"name\"] in devices:\n                        devices.remove(device[\"name\"])\n                # cache old or no cache, fetch device data\n                elif device[\"name\"] not in devices:\n                    devices.append(device[\"name\"])\n    # ignore cache data, fetch data from netbox\n    elif cache == False or cache == \"refresh\":\n        queries = {\n            f\"devices_by_filter_{index}\": {\n                \"obj\": \"device_list\",\n                \"filters\": filter_item,\n                \"fields\": device_fields,\n            }\n            for index, filter_item in enumerate(filters)\n        }\n\n    # fetch devices data from Netbox\n    if devices or queries:\n        if devices:\n            if self.nb_version[0] == 4:\n                dlist = '[\"{dl}\"]'.format(dl='\", \"'.join(devices))\n                filters_dict = {\"name\": f\"{{in_list: {dlist}}}\"}\n            elif self.nb_version[0] == 3:\n                filters_dict = {\"name\": devices}\n            queries[\"devices_by_devices_list\"] = {\n                \"obj\": \"device_list\",\n                \"filters\": filters_dict,\n                \"fields\": device_fields,\n            }\n\n        # send queries\n        query_result = self.graphql(\n            queries=queries, instance=instance, dry_run=dry_run\n        )\n\n        # check for errors\n        if query_result.errors:\n            msg = f\"{self.name} - get devices query failed with errors:\\n{query_result.errors}\"\n            raise Exception(msg)\n\n        # return dry run result\n        if dry_run:\n            ret.result[\"get_devices_dry_run\"] = query_result.result\n            return ret\n\n        # process devices data\n        devices_data = query_result.result\n        for devices_list in devices_data.values():\n            for device in devices_list:\n                if device[\"name\"] not in ret.result:\n                    device_name = device.pop(\"name\")\n                    # cache device data\n                    if cache != False:\n                        cache_key = f\"get_devices::{device_name}\"\n                        self.cache.set(cache_key, device, expire=self.cache_ttl)\n                    # add device data to return result\n                    ret.result[device_name] = device\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_interfaces","title":"<code>get_interfaces(instance=None, devices=None, ip_addresses=False, inventory_items=False, dry_run=False)</code>","text":"<p>Function to retrieve device interfaces from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>devices</code> <code>list</code> <p>list of devices to retrieve interfaces for</p> <code>None</code> <code>ip_addresses</code> <code>bool</code> <p>if True, retrieves interface IPs</p> <code>False</code> <code>inventory_items</code> <code>bool</code> <p>if True, retrieves interface inventory items</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with interface details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_interfaces(\n    self,\n    instance: str = None,\n    devices: list = None,\n    ip_addresses: bool = False,\n    inventory_items: bool = False,\n    dry_run: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Function to retrieve device interfaces from Netbox using GraphQL API.\n\n    :param instance: Netbox instance name\n    :param devices: list of devices to retrieve interfaces for\n    :param ip_addresses: if True, retrieves interface IPs\n    :param inventory_items: if True, retrieves interface inventory items\n    :param dry_run: only return query content, do not run it\n    :return: dictionary keyed by device name with interface details\n    \"\"\"\n    # form final result object\n    ret = Result(\n        task=f\"{self.name}:get_interfaces\", result={d: {} for d in devices}\n    )\n    intf_fields = [\n        \"name\",\n        \"enabled\",\n        \"description\",\n        \"mtu\",\n        \"parent {name}\",\n        \"mac_address\",\n        \"mode\",\n        \"untagged_vlan {vid name}\",\n        \"vrf {name}\",\n        \"tagged_vlans {vid name}\",\n        \"tags {name}\",\n        \"custom_fields\",\n        \"last_updated\",\n        \"bridge {name}\",\n        \"child_interfaces {name}\",\n        \"bridge_interfaces {name}\",\n        \"member_interfaces {name}\",\n        \"wwn\",\n        \"duplex\",\n        \"speed\",\n        \"id\",\n        \"device {name}\",\n    ]\n\n    # add IP addresses to interfaces fields\n    if ip_addresses:\n        intf_fields.append(\n            \"ip_addresses {address status role dns_name description custom_fields last_updated tenant {name} tags {name}}\"\n        )\n\n    # form interfaces query dictionary\n    queries = {\n        \"interfaces\": {\n            \"obj\": \"interface_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": intf_fields,\n        }\n    }\n\n    # add query to retrieve inventory items\n    if inventory_items:\n        inv_filters = {\"device\": devices, \"component_type\": \"dcim.interface\"}\n        inv_fields = [\n            \"name\",\n            \"component {... on InterfaceType {id}}\",\n            \"role {name}\",\n            \"manufacturer {name}\",\n            \"custom_fields\",\n            \"label\",\n            \"description\",\n            \"tags {name}\",\n            \"asset_tag\",\n            \"serial\",\n            \"part_id\",\n        ]\n        queries[\"inventor_items\"] = {\n            \"obj\": \"inventory_item_list\",\n            \"filters\": inv_filters,\n            \"fields\": inv_fields,\n        }\n\n    query_result = self.graphql(instance=instance, queries=queries, dry_run=dry_run)\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    interfaces_data = query_result.result\n\n    # exit if no Interfaces returned\n    if not interfaces_data.get(\"interfaces\"):\n        raise Exception(\n            f\"{self.name} - no interfaces data in '{interfaces_data}' returned by '{instance}' \"\n            f\"for devices {', '.join(devices)}\"\n        )\n\n    # process query results\n    interfaces = interfaces_data.pop(\"interfaces\")\n\n    # process inventory items\n    if inventory_items:\n        inventory_items_list = interfaces_data.pop(\"inventor_items\")\n        # transform inventory items list to a dictionary keyed by intf_id\n        inventory_items_dict = {}\n        while inventory_items_list:\n            inv_item = inventory_items_list.pop()\n            # skip inventory items that does not assigned to components\n            if inv_item.get(\"component\") is None:\n                continue\n            intf_id = str(inv_item.pop(\"component\").pop(\"id\"))\n            inventory_items_dict.setdefault(intf_id, [])\n            inventory_items_dict[intf_id].append(inv_item)\n        # iterate over interfaces and add inventory items\n        for intf in interfaces:\n            intf[\"inventory_items\"] = inventory_items_dict.pop(intf[\"id\"], [])\n\n    # transform interfaces list to dictionary keyed by device and interfaces names\n    while interfaces:\n        intf = interfaces.pop()\n        _ = intf.pop(\"id\")\n        device_name = intf.pop(\"device\").pop(\"name\")\n        intf_name = intf.pop(\"name\")\n        if device_name in ret.result:  # Netbox issue #16299\n            ret.result[device_name][intf_name] = intf\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_connections","title":"<code>get_connections(devices, instance=None, dry_run=False, cables=False)</code>","text":"<p>Function to retrieve device connections data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>devices</code> <code>list</code> <p>list of devices to retrieve interface for</p> required <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>cables</code> <code>bool</code> <p>if True includes interfaces' directly attached cables details</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with connections data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_connections(\n    self,\n    devices: list,\n    instance: str = None,\n    dry_run: bool = False,\n    cables: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Function to retrieve device connections data from Netbox using GraphQL API.\n\n    :param instance: Netbox instance name\n    :param devices: list of devices to retrieve interface for\n    :param dry_run: only return query content, do not run it\n    :param cables: if True includes interfaces' directly attached cables details\n    :return: dictionary keyed by device name with connections data\n    \"\"\"\n    # form final result dictionary\n    ret = Result(\n        task=f\"{self.name}:get_connections\", result={d: {} for d in devices}\n    )\n\n    # form lists of fields to request from netbox\n    cable_fields = \"\"\"\n        cable {\n            type\n            status\n            tenant {name}\n            label\n            tags {name}\n            length\n            length_unit\n            custom_fields\n        }\n    \"\"\"\n    if self.nb_version[0] == 4:\n        interfaces_fields = [\n            \"name\",\n            \"device {name}\",\n            \"\"\"connected_endpoints {\n            __typename \n            ... on InterfaceType {name device {name}}\n            ... on ProviderNetworkType {name}\n            }\"\"\",\n        ]\n    elif self.nb_version[0] == 3:\n        interfaces_fields = [\n            \"name\",\n            \"device {name}\",\n            \"\"\"connected_endpoints {\n            __typename \n            ... on InterfaceType {name device {name}}\n            }\"\"\",\n        ]\n    interfaces_fields.append(\n        \"\"\"\n        link_peers {\n            __typename\n            ... on InterfaceType {name device {name}}\n            ... on FrontPortType {name device {name}}\n            ... on RearPortType {name device {name}}\n        }\n    \"\"\"\n    )\n    console_ports_fields = [\n        \"name\",\n        \"device {name}\",\n        \"\"\"connected_endpoints {\n          __typename \n          ... on ConsoleServerPortType {name device {name}}\n        }\"\"\",\n        \"\"\"link_peers {\n          __typename\n          ... on ConsoleServerPortType {name device {name}}\n          ... on FrontPortType {name device {name}}\n          ... on RearPortType {name device {name}}\n        }\"\"\",\n    ]\n    console_server_ports_fields = [\n        \"name\",\n        \"device {name}\",\n        \"\"\"connected_endpoints {\n          __typename \n          ... on ConsolePortType {name device {name}}\n        }\"\"\",\n        \"\"\"link_peers {\n          __typename\n          ... on ConsolePortType {name device {name}}\n          ... on FrontPortType {name device {name}}\n          ... on RearPortType {name device {name}}\n        }\"\"\",\n    ]\n\n    # check if need to include cables info\n    if cables is True:\n        interfaces_fields.append(cable_fields)\n        console_ports_fields.append(cable_fields)\n        console_server_ports_fields.append(cable_fields)\n\n    # form query dictionary with aliases to get data from Netbox\n    queries = {\n        \"interface\": {\n            \"obj\": \"interface_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": interfaces_fields,\n        },\n        \"consoleport\": {\n            \"obj\": \"console_port_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": console_ports_fields,\n        },\n        \"consoleserverport\": {\n            \"obj\": \"console_server_port_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": console_server_ports_fields,\n        },\n    }\n\n    # retrieve full list of devices interface with all cables\n    query_result = self.graphql(queries=queries, instance=instance, dry_run=dry_run)\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    all_ports = query_result.result\n\n    # extract interfaces\n    for port_type, ports in all_ports.items():\n        for port in ports:\n            endpoints = port[\"connected_endpoints\"]\n            # skip ports that have no remote device connected\n            if not endpoints or not all(i for i in endpoints):\n                continue\n\n            # extract required parameters\n            cable = port.get(\"cable\", {})\n            device_name = port[\"device\"][\"name\"]\n            port_name = port[\"name\"]\n            link_peers = port[\"link_peers\"]\n            remote_termination_type = endpoints[0][\"__typename\"].lower()\n            remote_termination_type = remote_termination_type.replace(\"type\", \"\")\n\n            # form initial connection dictionary\n            connection = {\n                \"breakout\": len(endpoints) &gt; 1,\n                \"remote_termination_type\": remote_termination_type,\n                \"termination_type\": port_type,\n            }\n\n            # add remote connection details\n            if remote_termination_type == \"providernetwork\":\n                connection[\"remote_device\"] = None\n                connection[\"remote_interface\"] = None\n                connection[\"provider\"] = endpoints[0][\"name\"]\n            else:\n                remote_interface = endpoints[0][\"name\"]\n                if len(endpoints) &gt; 1:\n                    remote_interface = [i[\"name\"] for i in endpoints]\n                connection[\"remote_interface\"] = remote_interface\n                connection[\"remote_device\"] = endpoints[0][\"device\"][\"name\"]\n\n            # add cable and its peer details\n            if cables:\n                peer_termination_type = link_peers[0][\"__typename\"].lower()\n                peer_termination_type = peer_termination_type.replace(\"type\", \"\")\n                cable[\"peer_termination_type\"] = peer_termination_type\n                cable[\"peer_device\"] = link_peers[0].get(\"device\", {}).get(\"name\")\n                cable[\"peer_interface\"] = link_peers[0].get(\"name\")\n                if len(link_peers) &gt; 1:  # handle breakout cable\n                    cable[\"peer_interface\"] = [i[\"name\"] for i in link_peers]\n                connection[\"cable\"] = cable\n\n            ret.result[device_name][port_name] = connection\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker._map_circuit","title":"<code>_map_circuit(circuit, ret, instance, devices, cache)</code>","text":"<p>ThreadPoolExecutor target function to retrieve circuit details from Netbox</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>dict</code> <p>Dictionary with circuit data</p> required <code>ret</code> <code>Result</code> <p>Result object to save results into</p> required <code>instance</code> <code>str</code> <p>Netbox instance name</p> required <code>devices</code> <code>list</code> <p>list of devices to map circuits for</p> required <code>cache</code> <code>bool</code> <p>if <code>True</code> or 'refresh' update cache, <code>False</code> do not update cache</p> required Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def _map_circuit(\n    self, circuit: dict, ret: Result, instance: str, devices: list, cache: bool\n) -&gt; bool:\n    \"\"\"\n    ThreadPoolExecutor target function to retrieve circuit details from Netbox\n\n    :param circuit: Dictionary with circuit data\n    :param ret: Result object to save results into\n    :param instance: Netbox instance name\n    :param devices: list of devices to map circuits for\n    :param cache: if `True` or 'refresh' update cache, `False` do not update cache\n    \"\"\"\n    cid = circuit.pop(\"cid\")\n    ckt_cache_data = {}  # ckt data dictionary to save in cache\n    circuit[\"tags\"] = [i[\"name\"] for i in circuit[\"tags\"]]\n    circuit[\"type\"] = circuit[\"type\"][\"name\"]\n    circuit[\"provider\"] = circuit[\"provider\"][\"name\"]\n    circuit[\"tenant\"] = circuit[\"tenant\"][\"name\"] if circuit[\"tenant\"] else None\n    circuit[\"provider_account\"] = (\n        circuit[\"provider_account\"][\"name\"] if circuit[\"provider_account\"] else None\n    )\n    termination_a = circuit[\"termination_a\"]\n    termination_z = circuit[\"termination_z\"]\n    termination_a = termination_a[\"id\"] if termination_a else None\n    termination_z = termination_z[\"id\"] if termination_z else None\n\n    log.info(f\"{self.name}:get_circuits - {cid} tracing circuit terminations path\")\n\n    # retrieve A or Z termination path using Netbox REST API\n    if termination_a is not None:\n        circuit_path = self.rest(\n            instance=instance,\n            method=\"get\",\n            api=f\"/circuits/circuit-terminations/{termination_a}/paths/\",\n        )\n    elif termination_z is not None:\n        circuit_path = self.rest(\n            instance=instance,\n            method=\"get\",\n            api=f\"/circuits/circuit-terminations/{termination_z}/paths/\",\n        )\n    else:\n        return True\n\n    # check if circuit ends connect to device or provider network\n    if (\n        not circuit_path\n        or \"name\" not in circuit_path[0][\"path\"][0][0]\n        or \"name\" not in circuit_path[0][\"path\"][-1][-1]\n    ):\n        return True\n\n    # form A and Z connection endpoints\n    end_a = {\n        \"device\": circuit_path[0][\"path\"][0][0]\n        .get(\"device\", {})\n        .get(\"name\", False),\n        \"provider_network\": \"provider-network\"\n        in circuit_path[0][\"path\"][0][0][\"url\"],\n        \"name\": circuit_path[0][\"path\"][0][0][\"name\"],\n    }\n    end_z = {\n        \"device\": circuit_path[0][\"path\"][-1][-1]\n        .get(\"device\", {})\n        .get(\"name\", False),\n        \"provider_network\": \"provider-network\"\n        in circuit_path[0][\"path\"][-1][-1][\"url\"],\n        \"name\": circuit_path[0][\"path\"][-1][-1][\"name\"],\n    }\n    circuit[\"is_active\"] = circuit_path[0][\"is_active\"]\n\n    # map path ends to devices\n    if end_a[\"device\"]:\n        device_data = copy.deepcopy(circuit)\n        device_data[\"interface\"] = end_a[\"name\"]\n        if end_z[\"device\"]:\n            device_data[\"remote_device\"] = end_z[\"device\"]\n            device_data[\"remote_interface\"] = end_z[\"name\"]\n        elif end_z[\"provider_network\"]:\n            device_data[\"provider_network\"] = end_z[\"name\"]\n        # save device data in cache\n        ckt_cache_data[end_a[\"device\"]] = device_data\n        # include device data in result\n        if end_a[\"device\"] in devices:\n            ret.result[end_a[\"device\"]][cid] = device_data\n    if end_z[\"device\"]:\n        device_data = copy.deepcopy(circuit)\n        device_data[\"interface\"] = end_z[\"name\"]\n        if end_a[\"device\"]:\n            device_data[\"remote_device\"] = end_a[\"device\"]\n            device_data[\"remote_interface\"] = end_a[\"name\"]\n        elif end_a[\"provider_network\"]:\n            device_data[\"provider_network\"] = end_a[\"name\"]\n        # save device data in cache\n        ckt_cache_data[end_z[\"device\"]] = device_data\n        # include device data in result\n        if end_z[\"device\"] in devices:\n            ret.result[end_z[\"device\"]][cid] = device_data\n\n    # save data to cache\n    if cache != False:\n        ckt_cache_key = f\"get_circuits::{cid}\"\n        if ckt_cache_data:\n            self.cache.set(ckt_cache_key, ckt_cache_data, expire=self.cache_ttl)\n            log.info(\n                f\"{self.name}:get_circuits - {cid} cached circuit data for future use\"\n            )\n\n    log.info(\n        f\"{self.name}:get_circuits - {cid} circuit data mapped to devices using data from Netbox\"\n    )\n    return True\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_circuits","title":"<code>get_circuits(devices, cid=None, instance=None, dry_run=False, cache=True)</code>","text":"<p>Task to retrieve device's circuits data from Netbox.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list</code> <p>list of devices to retrieve interface for</p> required <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>cid</code> <code>list</code> <p>list of circuit identifiers to retrieve data for</p> <code>None</code> <code>cache</code> <code>Union[bool, str]</code> <p>if <code>True</code> use data stored in cache if it is up to date refresh it otherwise, <code>False</code> do not use cache do not update cache, <code>refresh</code> ignore data in cache and replace it with data fetched from Netbox, <code>force</code> use data in cache without checking if it is up to date</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device names with circuits data values</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_circuits(\n    self,\n    devices: list,\n    cid: list = None,\n    instance: str = None,\n    dry_run: bool = False,\n    cache: Union[bool, str] = True,\n) -&gt; dict:\n    \"\"\"\n    Task to retrieve device's circuits data from Netbox.\n\n    :param devices: list of devices to retrieve interface for\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param cid: list of circuit identifiers to retrieve data for\n    :param cache: if `True` use data stored in cache if it is up to date\n        refresh it otherwise, `False` do not use cache do not update cache,\n        `refresh` ignore data in cache and replace it with data fetched\n        from Netbox, `force` use data in cache without checking if it is up\n        to date\n    :return: dictionary keyed by device names with circuits data values\n    \"\"\"\n    log.info(\n        f\"{self.name}:get_circuits - {instance or self.default_instance} Netbox, \"\n        f\"devices {', '.join(devices)}, cid {cid}\"\n    )\n\n    # form final result object\n    ret = Result(task=f\"{self.name}:get_circuits\", result={d: {} for d in devices})\n    cache = self.cache_use if cache is None else cache\n    cid = cid or []\n    circuit_fields = [\n        \"cid\",\n        \"tags {name}\",\n        \"provider {name}\",\n        \"commit_rate\",\n        \"description\",\n        \"status\",\n        \"type {name}\",\n        \"provider_account {name}\",\n        \"tenant {name}\",\n        \"termination_a {id last_updated}\",\n        \"termination_z {id last_updated}\",\n        \"custom_fields\",\n        \"comments\",\n        \"last_updated\",\n    ]\n\n    # form initial circuits filters based on devices' sites and cid list\n    circuits_filters_dict = {}\n    device_data = self.get_devices(\n        devices=copy.deepcopy(devices), instance=instance, cache=cache\n    )\n    sites = list(set([i[\"site\"][\"slug\"] for i in device_data.result.values()]))\n    if self.nb_version[0] == 4:\n        circuits_filters_dict = {\"site\": sites}\n        if cid:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid))\n            circuits_filters_dict[\"cid\"] = f\"{{in_list: {cid_list}}}\"\n    elif self.nb_version[0] == 3:\n        circuits_filters_dict = {\"site\": sites}\n        if cid:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid))\n            circuits_filters_dict[\"cid\"] = cid_list\n\n    log.info(\n        f\"{self.name}:get_circuits - constructed circuits filters: {circuits_filters_dict}\"\n    )\n\n    if cache == True or cache == \"force\":\n        log.info(f\"{self.name}:get_circuits - retrieving circuits data from cache\")\n        cid_list = []  #  new cid list for follow up query\n        # retrieve last updated data from Netbox for circuits and their terminations\n        last_updated = self.graphql(\n            obj=\"circuit_list\",\n            filters=circuits_filters_dict,\n            fields=[\n                \"cid\",\n                \"last_updated\",\n                \"termination_a {id last_updated}\",\n                \"termination_z {id last_updated}\",\n            ],\n            dry_run=dry_run,\n            instance=instance,\n        )\n        last_updated.raise_for_status(f\"{self.name} - get circuits query failed\")\n\n        # return dry run result\n        if dry_run:\n            ret.result[\"get_circuits_dry_run\"] = last_updated.result\n            return ret\n\n        # retrieve circuits data from cache\n        self.cache.expire()  # remove expired items from cache\n        for device in devices:\n            for circuit in last_updated.result:\n                circuit_cache_key = f\"get_circuits::{circuit['cid']}\"\n                log.info(\n                    f\"{self.name}:get_circuits - searching cache for key {circuit_cache_key}\"\n                )\n                # check if cache is up to date and use it if so\n                if circuit_cache_key in self.cache:\n                    cache_ckt = self.cache[circuit_cache_key]\n                    # check if device uses this circuit\n                    if device not in cache_ckt:\n                        continue\n                    # use cache forcefully\n                    if cache == \"force\":\n                        ret.result[device][circuit[\"cid\"]] = cache_ckt[device]\n                    # check circuit cache is up to date\n                    if cache_ckt[device][\"last_updated\"] != circuit[\"last_updated\"]:\n                        continue\n                    if (\n                        cache_ckt[device][\"termination_a\"]\n                        and circuit[\"termination_a\"]\n                        and cache_ckt[device][\"termination_a\"][\"last_updated\"]\n                        != circuit[\"termination_a\"][\"last_updated\"]\n                    ):\n                        continue\n                    if (\n                        cache_ckt[device][\"termination_z\"]\n                        and circuit[\"termination_z\"]\n                        and cache_ckt[device][\"termination_z\"][\"last_updated\"]\n                        != circuit[\"termination_z\"][\"last_updated\"]\n                    ):\n                        continue\n                    ret.result[device][circuit[\"cid\"]] = cache_ckt[device]\n                    log.info(\n                        f\"{self.name}:get_circuits - {circuit['cid']} retrieved data from cache\"\n                    )\n                elif circuit[\"cid\"] not in cid_list:\n                    cid_list.append(circuit[\"cid\"])\n                    log.info(\n                        f\"{self.name}:get_circuits - {circuit['cid']} no cache data found, fetching from Netbox\"\n                    )\n        # form new filters dictionary to fetch remaining circuits data\n        circuits_filters_dict = {}\n        if cid_list:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid_list))\n            if self.nb_version[0] == 4:\n                circuits_filters_dict[\"cid\"] = f\"{{in_list: {cid_list}}}\"\n            elif self.nb_version[0] == 3:\n                circuits_filters_dict[\"cid\"] = cid_list\n    # ignore cache data, fetch circuits from netbox\n    elif cache == False or cache == \"refresh\":\n        pass\n\n    if circuits_filters_dict:\n        query_result = self.graphql(\n            obj=\"circuit_list\",\n            filters=circuits_filters_dict,\n            fields=circuit_fields,\n            dry_run=dry_run,\n            instance=instance,\n        )\n        query_result.raise_for_status(f\"{self.name} - get circuits query failed\")\n\n        # return dry run result\n        if dry_run is True:\n            return query_result\n\n        all_circuits = query_result.result\n\n        # iterate over circuits and map them to devices\n        log.info(\n            f\"{self.name}:get_circuits - retrieved data for {len(all_circuits)} \"\n            f\"circuits from netbox, mapping circuits to devices\"\n        )\n        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n            results = [\n                executor.submit(\n                    self._map_circuit, circuit, ret, instance, devices, cache\n                )\n                for circuit in all_circuits\n            ]\n            for _ in concurrent.futures.as_completed(results):\n                continue\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_nornir_inventory","title":"<code>get_nornir_inventory(filters=None, devices=None, instance=None, interfaces=False, connections=False, circuits=False, nbdata=True, primary_ip='ip4')</code>","text":"<p>Method to query Netbox devices data and construct Nornir inventory.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list</code> <p>List of filters to apply when querying devices.</p> <code>None</code> <code>devices</code> <code>list</code> <p>List of specific devices to query.</p> <code>None</code> <code>instance</code> <code>str</code> <p>Netbox instance name to query.</p> <code>None</code> <code>interfaces</code> <code>Union[dict, bool]</code> <p>Whether to include interfaces data. If a dict is provided, it will be used as arguments for the query.</p> <code>False</code> <code>connections</code> <code>Union[dict, bool]</code> <p>Whether to include connections data. If a dict is provided, it will be used as arguments for the query.</p> <code>False</code> <code>circuits</code> <code>Union[dict, bool]</code> <p>Whether to include circuits data. If a dict is provided, it will be used as arguments for the query.</p> <code>False</code> <code>nbdata</code> <code>bool</code> <p>Whether to include Netbox devices data in the host's data</p> <code>True</code> <code>primary_ip</code> <code>str</code> <p>Primary IP version to use for the hostname.</p> <code>'ip4'</code> <p>Returns:</p> Type Description <code>dict</code> <p>Nornir Inventory compatible dictionary</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_nornir_inventory(\n    self,\n    filters: list = None,\n    devices: list = None,\n    instance: str = None,\n    interfaces: Union[dict, bool] = False,\n    connections: Union[dict, bool] = False,\n    circuits: Union[dict, bool] = False,\n    nbdata: bool = True,\n    primary_ip: str = \"ip4\",\n) -&gt; dict:\n    \"\"\"\n    Method to query Netbox devices data and construct Nornir inventory.\n\n    :param filters: List of filters to apply when querying devices.\n    :param devices: List of specific devices to query.\n    :param instance: Netbox instance name to query.\n    :param interfaces: Whether to include interfaces data. If a dict is provided,\n        it will be used as arguments for the query.\n    :param connections: Whether to include connections data. If a dict is provided,\n        it will be used as arguments for the query.\n    :param circuits: Whether to include circuits data. If a dict is provided,\n        it will be used as arguments for the query.\n    :param nbdata: Whether to include Netbox devices data in the host's data\n    :param primary_ip: Primary IP version to use for the hostname.\n    :returns: Nornir Inventory compatible dictionary\n    \"\"\"\n    hosts = {}\n    inventory = {\"hosts\": hosts}\n    ret = Result(task=f\"{self.name}:get_nornir_inventory\", result=inventory)\n\n    # check Netbox status\n    netbox_status = self.get_netbox_status(instance=instance)\n    if netbox_status.result[instance or self.default_instance][\"status\"] is False:\n        return ret\n\n    # retrieve devices data\n    nb_devices = self.get_devices(\n        filters=filters, devices=devices, instance=instance\n    )\n\n    # form Nornir hosts inventory\n    for device_name, device in nb_devices.result.items():\n        host = device[\"config_context\"].pop(\"nornir\", {})\n        host.setdefault(\"data\", {})\n        name = host.pop(\"name\", device_name)\n        hosts[name] = host\n        # add platform if not provided in device config context\n        if not host.get(\"platform\"):\n            if device[\"platform\"]:\n                host[\"platform\"] = device[\"platform\"][\"name\"]\n            else:\n                log.warning(f\"{self.name} - no platform found for '{name}' device\")\n        # add hostname if not provided in config context\n        if not host.get(\"hostname\"):\n            if device[\"primary_ip4\"] and primary_ip in [\"ip4\", \"ipv4\"]:\n                host[\"hostname\"] = device[\"primary_ip4\"][\"address\"].split(\"/\")[0]\n            elif device[\"primary_ip6\"] and primary_ip in [\"ip6\", \"ipv6\"]:\n                host[\"hostname\"] = device[\"primary_ip6\"][\"address\"].split(\"/\")[0]\n            else:\n                host[\"hostname\"] = name\n        # add netbox data to host's data\n        if nbdata is True:\n            host[\"data\"].update(device)\n\n    # return if no hosts found for provided parameters\n    if not hosts:\n        log.warning(f\"{self.name} - no viable hosts returned by Netbox\")\n        return ret\n\n    # add interfaces data\n    if interfaces:\n        # decide on get_interfaces arguments\n        kwargs = interfaces if isinstance(interfaces, dict) else {}\n        # add 'interfaces' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"interfaces\", {})\n        # query interfaces data from netbox\n        nb_interfaces = self.get_interfaces(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save interfaces data to hosts' inventory\n        while nb_interfaces.result:\n            device, device_interfaces = nb_interfaces.result.popitem()\n            hosts[device][\"data\"][\"interfaces\"] = device_interfaces\n\n    # add connections data\n    if connections:\n        # decide on get_interfaces arguments\n        kwargs = connections if isinstance(connections, dict) else {}\n        # add 'connections' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"connections\", {})\n        # query connections data from netbox\n        nb_connections = self.get_connections(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save connections data to hosts' inventory\n        while nb_connections.result:\n            device, device_connections = nb_connections.result.popitem()\n            hosts[device][\"data\"][\"connections\"] = device_connections\n\n    # add circuits data\n    if circuits:\n        # decide on get_interfaces arguments\n        kwargs = circuits if isinstance(circuits, dict) else {}\n        # add 'circuits' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"circuits\", {})\n        # query circuits data from netbox\n        nb_circuits = self.get_circuits(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save circuits data to hosts' inventory\n        while nb_circuits.result:\n            device, device_circuits = nb_circuits.result.popitem()\n            hosts[device][\"data\"][\"circuits\"] = device_circuits\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.update_device_facts","title":"<code>update_device_facts(instance=None, dry_run=False, datasource='nornir', timeout=60, devices=None, batch_size=10, **kwargs)</code>","text":"<p>Function to update device facts in Netbox using information provided by NAPALM get_facts getter:</p> <ul> <li>serial number</li> </ul> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>datasource</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>batch_size</code> <code>int</code> <p>number of devices to process at a time</p> <code>10</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with updated details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_facts(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    datasource: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    batch_size: int = 10,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to update device facts in Netbox using information\n    provided by NAPALM get_facts getter:\n\n    - serial number\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param datasource: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param batch_size: number of devices to process at a time\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    :returns: dictionary keyed by device name with updated details\n    \"\"\"\n    result = {}\n    devices = devices or []\n    instance = instance or self.default_instance\n    ret = Result(task=f\"{self.name}:update_device_facts\", result=result)\n    nb = self._get_pynetbox(instance)\n    kwargs[\"add_details\"] = True\n\n    if datasource == \"nornir\":\n        for i in range(0, len(devices), batch_size):\n            kwargs[\"FL\"] = devices[i : i + batch_size]\n            kwargs[\"getters\"] = \"get_facts\"\n            self.event(\n                f\"retrieving facts data for devices {', '.join(kwargs['FL'])}\",\n                resource=instance,\n            )\n            data = self.client.run_job(\n                \"nornir\",\n                \"parse\",\n                kwargs=kwargs,\n                workers=\"all\",\n                timeout=timeout,\n            )\n            for worker, results in data.items():\n                if results[\"failed\"]:\n                    log.error(\n                        f\"{worker} get_facts failed, errors: {'; '.join(results['errors'])}\"\n                    )\n                    continue\n                for host, host_data in results[\"result\"].items():\n                    if host_data[\"napalm_get\"][\"failed\"]:\n                        log.error(\n                            f\"{host} facts update failed: '{host_data['napalm_get']['exception']}'\"\n                        )\n                        self.event(\n                            f\"{host} facts update failed\",\n                            resource=instance,\n                            status=\"failed\",\n                            severity=\"WARNING\",\n                        )\n                        continue\n                    nb_device = nb.dcim.devices.get(name=host)\n                    if not nb_device:\n                        raise Exception(f\"'{host}' does not exist in Netbox\")\n                    facts = host_data[\"napalm_get\"][\"result\"][\"get_facts\"]\n                    # update serial number\n                    nb_device.serial = facts[\"serial_number\"]\n                    if not dry_run:\n                        nb_device.save()\n                    result[host] = {\n                        \"update_device_facts_dry_run\"\n                        if dry_run\n                        else \"update_device_facts\": {\n                            \"serial\": facts[\"serial_number\"],\n                        }\n                    }\n                    self.event(f\"{host} facts updated\", resource=instance)\n    else:\n        raise UnsupportedServiceError(\n            f\"'{datasource}' datasource service not supported\"\n        )\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.update_device_interfaces","title":"<code>update_device_interfaces(instance=None, dry_run=False, datasource='nornir', timeout=60, devices=None, create=True, batch_size=10, **kwargs)</code>","text":"<p>Function to update device interfaces in Netbox using information provided by NAPALM <code>get_interfaces</code> getter:</p> <ul> <li>interface name</li> <li>interface description</li> <li>mtu</li> <li>mac address</li> <li>admin status</li> <li>speed</li> </ul> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>datasource</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>create</code> <code>bool</code> <p>create missing interfaces</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>number of devices to process at a time</p> <code>10</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with update details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_interfaces(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    datasource: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    create: bool = True,\n    batch_size: int = 10,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to update device interfaces in Netbox using information\n    provided by NAPALM `get_interfaces` getter:\n\n    - interface name\n    - interface description\n    - mtu\n    - mac address\n    - admin status\n    - speed\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param datasource: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param create: create missing interfaces\n    :param batch_size: number of devices to process at a time\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    :returns: dictionary keyed by device name with update details\n    \"\"\"\n    result = {}\n    instance = instance or self.default_instance\n    ret = Result(task=f\"{self.name}:update_device_interfaces\", result=result)\n    nb = self._get_pynetbox(instance)\n\n    if datasource == \"nornir\":\n        for i in range(0, len(devices), batch_size):\n            kwargs[\"FL\"] = devices[i : i + batch_size]\n            kwargs[\"getters\"] = \"get_interfaces\"\n            data = self.client.run_job(\n                \"nornir\",\n                \"parse\",\n                kwargs=kwargs,\n                workers=\"all\",\n                timeout=timeout,\n            )\n            for worker, results in data.items():\n                if results[\"failed\"]:\n                    log.error(\n                        f\"{worker} get_interfaces failed, errors: {'; '.join(results['errors'])}\"\n                    )\n                    continue\n                for host, host_data in results[\"result\"].items():\n                    updated, created = {}, {}\n                    result[host] = {\n                        \"update_device_interfaces_dry_run\"\n                        if dry_run\n                        else \"update_device_interfaces\": updated,\n                        \"created_device_interfaces_dry_run\"\n                        if dry_run\n                        else \"created_device_interfaces\": created,\n                    }\n                    interfaces = host_data[\"napalm_get\"][\"get_interfaces\"]\n                    nb_device = nb.dcim.devices.get(name=host)\n                    if not nb_device:\n                        raise Exception(f\"'{host}' does not exist in Netbox\")\n                    nb_interfaces = nb.dcim.interfaces.filter(\n                        device_id=nb_device.id\n                    )\n                    # update existing interfaces\n                    for nb_interface in nb_interfaces:\n                        if nb_interface.name not in interfaces:\n                            continue\n                        interface = interfaces.pop(nb_interface.name)\n                        nb_interface.description = interface[\"description\"]\n                        nb_interface.mtu = interface[\"mtu\"]\n                        nb_interface.speed = interface[\"speed\"] * 1000\n                        nb_interface.mac_address = interface[\"mac_address\"]\n                        nb_interface.enabled = interface[\"is_enabled\"]\n                        if dry_run is not True:\n                            nb_interface.save()\n                        updated[nb_interface.name] = interface\n                        self.event(\n                            f\"{host} updated interface {nb_interface.name}\",\n                            resource=instance,\n                        )\n                    # create new interfaces\n                    if create is not True:\n                        continue\n                    for interface_name, interface in interfaces.items():\n                        interface[\"type\"] = \"other\"\n                        nb_interface = nb.dcim.interfaces.create(\n                            name=interface_name,\n                            device={\"name\": nb_device.name},\n                            type=interface[\"type\"],\n                        )\n                        nb_interface.description = interface[\"description\"]\n                        nb_interface.mtu = interface[\"mtu\"]\n                        nb_interface.speed = interface[\"speed\"] * 1000\n                        nb_interface.mac_address = interface[\"mac_address\"]\n                        nb_interface.enabled = interface[\"is_enabled\"]\n                        if dry_run is not True:\n                            nb_interface.save()\n                        created[interface_name] = interface\n                        self.event(\n                            f\"{host} created interface {nb_interface.name}\",\n                            resource=instance,\n                        )\n    else:\n        raise UnsupportedServiceError(\n            f\"'{datasource}' datasource service not supported\"\n        )\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.update_device_ip","title":"<code>update_device_ip(instance=None, dry_run=False, datasource='nornir', timeout=60, devices=None, create=True, batch_size=10, **kwargs)</code>","text":"<p>Function to update device IP addresses in Netbox using information provided by NAPALM <code>get_interfaces_ip</code> getter.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>datasource</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>create</code> <code>bool</code> <p>create missing IP addresses</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>number of devices to process at a time</p> <code>10</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with update details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_ip(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    datasource: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    create: bool = True,\n    batch_size: int = 10,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to update device IP addresses in Netbox using information\n    provided by NAPALM `get_interfaces_ip` getter.\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param datasource: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param create: create missing IP addresses\n    :param batch_size: number of devices to process at a time\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    :returns: dictionary keyed by device name with update details\n    \"\"\"\n    result = {}\n    instance = instance or self.default_instance\n    ret = Result(task=f\"{self.name}:update_device_ip\", result=result)\n    nb = self._get_pynetbox(instance)\n\n    if datasource == \"nornir\":\n        for i in range(0, len(devices), batch_size):\n            kwargs[\"FL\"] = devices[i : i + batch_size]\n            kwargs[\"getters\"] = \"get_interfaces_ip\"\n            data = self.client.run_job(\n                \"nornir\",\n                \"parse\",\n                kwargs=kwargs,\n                workers=\"all\",\n                timeout=timeout,\n            )\n            for worker, results in data.items():\n                if results[\"failed\"]:\n                    log.error(\n                        f\"{worker} get_interfaces_ip failed, errors: {'; '.join(results['errors'])}\"\n                    )\n                    continue\n                for host, host_data in results[\"result\"].items():\n                    updated, created = {}, {}\n                    result[host] = {\n                        \"updated_ip_dry_run\" if dry_run else \"updated_ip\": updated,\n                        \"created_ip_dry_run\" if dry_run else \"created_ip\": created,\n                    }\n                    interfaces = host_data[\"napalm_get\"][\"get_interfaces_ip\"]\n                    nb_device = nb.dcim.devices.get(name=host)\n                    if not nb_device:\n                        raise Exception(f\"'{host}' does not exist in Netbox\")\n                    nb_interfaces = nb.dcim.interfaces.filter(\n                        device_id=nb_device.id\n                    )\n                    # update interface IP addresses\n                    for nb_interface in nb_interfaces:\n                        if nb_interface.name not in interfaces:\n                            continue\n                        interface = interfaces.pop(nb_interface.name)\n                        # merge v6 into v4 addresses to save code repetition\n                        interface[\"ipv4\"].update(interface.pop(\"ipv6\", {}))\n                        # update/create IP addresses\n                        for ip, ip_data in interface[\"ipv4\"].items():\n                            prefix_length = ip_data[\"prefix_length\"]\n                            # get IP address info from Netbox\n                            nb_ip = nb.ipam.ip_addresses.filter(\n                                address=f\"{ip}/{prefix_length}\"\n                            )\n                            if len(nb_ip) &gt; 1:\n                                log.warning(\n                                    f\"{host} got multiple {ip}/{prefix_length} IP addresses from Netbox, \"\n                                    f\"NorFab Netbox Service only supports handling of non-duplicate IPs.\"\n                                )\n                                continue\n                            # decide what to do\n                            if not nb_ip and create is False:\n                                continue\n                            elif not nb_ip and create is True:\n                                if dry_run is not True:\n                                    nb_ip = nb.ipam.ip_addresses.create(\n                                        address=f\"{ip}/{prefix_length}\"\n                                    )\n                                    nb_ip.assigned_object_type = \"dcim.interface\"\n                                    nb_ip.assigned_object_id = nb_interface.id\n                                    nb_ip.status = \"active\"\n                                    nb_ip.save()\n                                created[f\"{ip}/{prefix_length}\"] = nb_interface.name\n                                self.event(\n                                    f\"{host} created IP address {ip}/{prefix_length} for {nb_interface.name} interface\",\n                                    resource=instance,\n                                )\n                            elif nb_ip:\n                                nb_ip = list(nb_ip)[0]\n                                nb_ip.assigned_object_type = \"dcim.interface\"\n                                nb_ip.assigned_object_id = nb_interface.id\n                                nb_ip.status = \"active\"\n                                if dry_run is not True:\n                                    nb_ip.save()\n                                updated[nb_ip.address] = nb_interface.name\n                                self.event(\n                                    f\"{host} updated IP address {ip}/{prefix_length} for {nb_interface.name} interface\",\n                                    resource=instance,\n                                )\n\n    else:\n        raise UnsupportedServiceError(\n            f\"'{datasource}' datasource service not supported\"\n        )\n\n    return ret\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker.NetboxWorker.get_next_ip","title":"<code>get_next_ip(subnet, description=None, device=None, interface=None, vrf=None, tags=None, dns_name=None, tenant=None, comments=None, instance=None, dry_run=False)</code>","text":"<p>Method to retrieve existing or allocate new IP address in Netbox.</p> <p>Parameters:</p> Name Type Description Default <code>subnet</code> <code>str</code> <p>IPv4 or IPv6 subnet e.g. <code>10.0.0.0/24</code> to allocate next available IP Address from</p> required <code>description</code> <code>str</code> <p>IP address description to record in Netbox database</p> <code>None</code> <code>device</code> <code>str</code> <p>device name to find interface for and link IP address with</p> <code>None</code> <code>interface</code> <code>str</code> <p>interface name to link IP address with, <code>device</code> attribute also must be provided</p> <code>None</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_next_ip(\n    self,\n    subnet: str,\n    description: str = None,\n    device: str = None,\n    interface: str = None,\n    vrf: str = None,\n    tags: list = None,\n    dns_name: str = None,\n    tenant: str = None,\n    comments: str = None,\n    instance: str = None,\n    dry_run: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Method to retrieve existing or allocate new IP address in Netbox.\n\n    :param subnet: IPv4 or IPv6 subnet e.g. ``10.0.0.0/24`` to allocate next\n        available IP Address from\n    :param description: IP address description to record in Netbox database\n    :param device: device name to find interface for and link IP address with\n    :param interface: interface name to link IP address with, ``device`` attribute\n        also must be provided\n    \"\"\"\n    nb = self._get_pynetbox(instance)\n    nb_prefix = nb.ipam.prefixes.get(prefix=subnet, vrf=vrf)\n    nb_ip = nb_prefix.available_ips.create()\n    if description is not None:\n        nb_ip.description = description\n    nb_ip.save()\n\n    return Result(result=str(nb_ip))\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker._form_query_v4","title":"<code>_form_query_v4(obj, filters, fields, alias=None)</code>","text":"<p>Helper function to form graphql query</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>string, object to return data for e.g. device, interface, ip_address</p> required <code>filters</code> <p>dictionary of key-value pairs to filter by</p> required <code>fields</code> <p>list of data fields to return</p> required <code>alias</code> <p>string, alias value for requested object</p> <code>None</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def _form_query_v4(obj, filters, fields, alias=None):\n    \"\"\"\n    Helper function to form graphql query\n\n    :param obj: string, object to return data for e.g. device, interface, ip_address\n    :param filters: dictionary of key-value pairs to filter by\n    :param fields: list of data fields to return\n    :param alias: string, alias value for requested object\n    \"\"\"\n    filters_list = []\n    for k, v in filters.items():\n        if isinstance(v, (list, set, tuple)):\n            items = \", \".join(f'\"{i}\"' for i in v)\n            filters_list.append(f\"{k}: [{items}]\")\n        elif \"{\" in v and \"}\" in v:\n            filters_list.append(f\"{k}: {v}\")\n        else:\n            filters_list.append(f'{k}: \"{v}\"')\n    filters_string = \", \".join(filters_list)\n    filters_string = filters_string.replace(\"'\", '\"')  # swap quotes\n    fields = \" \".join(fields)\n    if alias:\n        query = f\"{alias}: {obj}(filters: {{{filters_string}}}) {{{fields}}}\"\n    else:\n        query = f\"{obj}(filters: {{{filters_string}}}) {{{fields}}}\"\n\n    return query\n</code></pre>"},{"location":"workers/netbox/api_reference_workers_netbox_worker/#norfab.workers.netbox_worker._form_query_v3","title":"<code>_form_query_v3(obj, filters, fields, alias=None)</code>","text":"<p>Helper function to form graphql query</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>string, obj to return data for e.g. device, interface, ip_address</p> required <code>filters</code> <p>dictionary of key-value pairs to filter by</p> required <code>fields</code> <p>list of data fields to return</p> required <code>alias</code> <p>string, alias value for requested obj</p> <code>None</code> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def _form_query_v3(obj, filters, fields, alias=None):\n    \"\"\"\n    Helper function to form graphql query\n\n    :param obj: string, obj to return data for e.g. device, interface, ip_address\n    :param filters: dictionary of key-value pairs to filter by\n    :param fields: list of data fields to return\n    :param alias: string, alias value for requested obj\n    \"\"\"\n    filters_list = []\n    for k, v in filters.items():\n        if isinstance(v, (list, set, tuple)):\n            items = \", \".join(f'\"{i}\"' for i in v)\n            filters_list.append(f\"{k}: [{items}]\")\n        else:\n            filters_list.append(f'{k}: \"{v}\"')\n    filters_string = \", \".join(filters_list)\n    fields = \" \".join(fields)\n    if alias:\n        query = f\"{alias}: {obj}({filters_string}) {{{fields}}}\"\n    else:\n        query = f\"{obj}({filters_string}) {{{fields}}}\"\n\n    return query\n</code></pre>"},{"location":"workers/netbox/services_netbox_service/","title":"Netbox Service","text":"<p>The Netbox Service allows NorFab to integrate with Netbox - a well-adopted open-source tool for documenting networks. This integration provides network engineers and administrators with powerful capabilities to manage and automate their network infrastructure using the rich data stored in Netbox.</p> <p></p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#overview","title":"Overview","text":"<p>Netbox is a comprehensive network documentation and management tool that includes features for IP address management (IPAM), data center infrastructure management (DCIM), and more. By integrating Netbox with NorFab, you can leverage the detailed network data stored in Netbox to automate various network tasks, ensuring consistency and accuracy across your network operations.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#norfab-netbox-service-key-features","title":"NorFab Netbox Service Key Features","text":"","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#multi-instance-support","title":"Multi-Instance Support","text":"<p>With each NorFab Netbox worker capable of working with multiple Netbox instances, NorFab Netbox Service offers high flexibility. This allows you to manage and automate tasks across different Netbox instances, making it ideal for large-scale environments with multiple data centers or network segments.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#device-and-interface-management","title":"Device and Interface Management","text":"<p>The Netbox Service enables you to retrieve and manage detailed information about network devices and interfaces. This includes device configuration contexts, interface statuses, IP addresses, and more. By using this data you can  ensure that your network state is always up-to-date and accurate.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#graphql-and-rest-api-integration","title":"GraphQL and REST API Integration","text":"<p>The Netbox Service leverages both REST and GraphQL API provided by Netbox to perform complex queries and retrieve specific data sets. This allows for efficient data retrieval and manipulation, enabling you to automate tasks such as inventory updates, configuration audits, and compliance checks.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#customizable-filters-and-queries","title":"Customizable Filters and Queries","text":"<p>You can define custom filters and queries to retrieve specific data from Netbox. This flexibility allows you to tailor the data retrieval process to meet your specific needs, ensuring that you get the exact information required for your automation tasks.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#caching-and-performance-optimization","title":"Caching and Performance Optimization","text":"<p>The Netbox Service includes caching mechanisms to optimize performance and reduce the load on your Netbox instances. By caching frequently accessed data, you can improve the efficiency of your automation workflows and ensure faster response times.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#use-cases","title":"Use Cases","text":"","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#automated-inventory-management","title":"Automated Inventory Management","text":"<p>By integrating Netbox with NorFab, you can automate the process of updating and maintaining your network inventory. This ensures that your inventory data is always accurate and up-to-date, reducing the risk of configuration errors and improving overall network reliability.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#configuration-compliance-and-auditing","title":"Configuration, Compliance and Auditing","text":"<p>The Netbox Service allows you to automate configuration compliance checks and audits through integration with other services such as Nornir. By retrieving inventory data from Netbox and comparing it against network state, you can quickly identify and remediate any deviations, ensuring that your network remains compliant.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#getting-started","title":"Getting Started","text":"<p>To get started with the Netbox Service, you need to configure your Netbox instances and define the necessary connection parameters in your NorFab inventory. Refer to the Netbox Inventory section for detailed instructions on setting up your inventory and integrating Netbox with NorFab.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service/#conclusion","title":"Conclusion","text":"<p>The Netbox Service is a powerful addition to NorFab, providing seamless integration with Netbox and enabling advanced network automation capabilities. By leveraging the rich data stored in Netbox, you can enhance your network management processes, improve accuracy, and ensure consistency across your network operations.</p>","tags":["Netbox"]},{"location":"workers/netbox/services_netbox_service_inventory/","title":"Netbox Worker Inventory","text":"<p>Sample Netbox Worker Inventory</p> <pre><code>service: netbox\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\ncache_use: True # or False, refresh, force\ncache_ttl: 31557600\nnetbox_connect_timeout: 10\nnetbox_read_timeout: 300\ninstances:\n  prod:\n    default: True\n    url: \"http://192.168.4.130:8000/\"\n    token: \"0123456789abcdef0123456789abcdef01234567\"\n    ssl_verify: False\n  dev:\n    url: \"http://192.168.4.131:8000/\"\n    token: \"0123456789abcdef0123456789abcdef01234567\"\n    ssl_verify: False\n  preprod:\n    url: \"http://192.168.4.132:8000/\"\n    token: \"0123456789abcdef0123456789abcdef01234567\"\n    ssl_verify: False\n</code></pre>"},{"location":"workers/netbox/services_netbox_service_tasks_get_circuits/","title":"Netbox Get Circuits Task","text":"<p>task api name: <code>get_circuits</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_circuits/#get-circuits-sample-usage","title":"Get Circuits Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_circuits/#norfab-netbox-get-circuits-command-shell-reference","title":"NORFAB Netbox Get Circuits Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>get_circuits</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_circuits/#python-api-reference","title":"Python API Reference","text":"<p>Task to retrieve device's circuits data from Netbox.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list</code> <p>list of devices to retrieve interface for</p> required <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>cid</code> <code>list</code> <p>list of circuit identifiers to retrieve data for</p> <code>None</code> <code>cache</code> <code>Union[bool, str]</code> <p>if <code>True</code> use data stored in cache if it is up to date refresh it otherwise, <code>False</code> do not use cache do not update cache, <code>refresh</code> ignore data in cache and replace it with data fetched from Netbox, <code>force</code> use data in cache without checking if it is up to date</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device names with circuits data values</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_circuits(\n    self,\n    devices: list,\n    cid: list = None,\n    instance: str = None,\n    dry_run: bool = False,\n    cache: Union[bool, str] = True,\n) -&gt; dict:\n    \"\"\"\n    Task to retrieve device's circuits data from Netbox.\n\n    :param devices: list of devices to retrieve interface for\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param cid: list of circuit identifiers to retrieve data for\n    :param cache: if `True` use data stored in cache if it is up to date\n        refresh it otherwise, `False` do not use cache do not update cache,\n        `refresh` ignore data in cache and replace it with data fetched\n        from Netbox, `force` use data in cache without checking if it is up\n        to date\n    :return: dictionary keyed by device names with circuits data values\n    \"\"\"\n    log.info(\n        f\"{self.name}:get_circuits - {instance or self.default_instance} Netbox, \"\n        f\"devices {', '.join(devices)}, cid {cid}\"\n    )\n\n    # form final result object\n    ret = Result(task=f\"{self.name}:get_circuits\", result={d: {} for d in devices})\n    cache = self.cache_use if cache is None else cache\n    cid = cid or []\n    circuit_fields = [\n        \"cid\",\n        \"tags {name}\",\n        \"provider {name}\",\n        \"commit_rate\",\n        \"description\",\n        \"status\",\n        \"type {name}\",\n        \"provider_account {name}\",\n        \"tenant {name}\",\n        \"termination_a {id last_updated}\",\n        \"termination_z {id last_updated}\",\n        \"custom_fields\",\n        \"comments\",\n        \"last_updated\",\n    ]\n\n    # form initial circuits filters based on devices' sites and cid list\n    circuits_filters_dict = {}\n    device_data = self.get_devices(\n        devices=copy.deepcopy(devices), instance=instance, cache=cache\n    )\n    sites = list(set([i[\"site\"][\"slug\"] for i in device_data.result.values()]))\n    if self.nb_version[0] == 4:\n        circuits_filters_dict = {\"site\": sites}\n        if cid:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid))\n            circuits_filters_dict[\"cid\"] = f\"{{in_list: {cid_list}}}\"\n    elif self.nb_version[0] == 3:\n        circuits_filters_dict = {\"site\": sites}\n        if cid:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid))\n            circuits_filters_dict[\"cid\"] = cid_list\n\n    log.info(\n        f\"{self.name}:get_circuits - constructed circuits filters: {circuits_filters_dict}\"\n    )\n\n    if cache == True or cache == \"force\":\n        log.info(f\"{self.name}:get_circuits - retrieving circuits data from cache\")\n        cid_list = []  #  new cid list for follow up query\n        # retrieve last updated data from Netbox for circuits and their terminations\n        last_updated = self.graphql(\n            obj=\"circuit_list\",\n            filters=circuits_filters_dict,\n            fields=[\n                \"cid\",\n                \"last_updated\",\n                \"termination_a {id last_updated}\",\n                \"termination_z {id last_updated}\",\n            ],\n            dry_run=dry_run,\n            instance=instance,\n        )\n        last_updated.raise_for_status(f\"{self.name} - get circuits query failed\")\n\n        # return dry run result\n        if dry_run:\n            ret.result[\"get_circuits_dry_run\"] = last_updated.result\n            return ret\n\n        # retrieve circuits data from cache\n        self.cache.expire()  # remove expired items from cache\n        for device in devices:\n            for circuit in last_updated.result:\n                circuit_cache_key = f\"get_circuits::{circuit['cid']}\"\n                log.info(\n                    f\"{self.name}:get_circuits - searching cache for key {circuit_cache_key}\"\n                )\n                # check if cache is up to date and use it if so\n                if circuit_cache_key in self.cache:\n                    cache_ckt = self.cache[circuit_cache_key]\n                    # check if device uses this circuit\n                    if device not in cache_ckt:\n                        continue\n                    # use cache forcefully\n                    if cache == \"force\":\n                        ret.result[device][circuit[\"cid\"]] = cache_ckt[device]\n                    # check circuit cache is up to date\n                    if cache_ckt[device][\"last_updated\"] != circuit[\"last_updated\"]:\n                        continue\n                    if (\n                        cache_ckt[device][\"termination_a\"]\n                        and circuit[\"termination_a\"]\n                        and cache_ckt[device][\"termination_a\"][\"last_updated\"]\n                        != circuit[\"termination_a\"][\"last_updated\"]\n                    ):\n                        continue\n                    if (\n                        cache_ckt[device][\"termination_z\"]\n                        and circuit[\"termination_z\"]\n                        and cache_ckt[device][\"termination_z\"][\"last_updated\"]\n                        != circuit[\"termination_z\"][\"last_updated\"]\n                    ):\n                        continue\n                    ret.result[device][circuit[\"cid\"]] = cache_ckt[device]\n                    log.info(\n                        f\"{self.name}:get_circuits - {circuit['cid']} retrieved data from cache\"\n                    )\n                elif circuit[\"cid\"] not in cid_list:\n                    cid_list.append(circuit[\"cid\"])\n                    log.info(\n                        f\"{self.name}:get_circuits - {circuit['cid']} no cache data found, fetching from Netbox\"\n                    )\n        # form new filters dictionary to fetch remaining circuits data\n        circuits_filters_dict = {}\n        if cid_list:\n            cid_list = '[\"{cl}\"]'.format(cl='\", \"'.join(cid_list))\n            if self.nb_version[0] == 4:\n                circuits_filters_dict[\"cid\"] = f\"{{in_list: {cid_list}}}\"\n            elif self.nb_version[0] == 3:\n                circuits_filters_dict[\"cid\"] = cid_list\n    # ignore cache data, fetch circuits from netbox\n    elif cache == False or cache == \"refresh\":\n        pass\n\n    if circuits_filters_dict:\n        query_result = self.graphql(\n            obj=\"circuit_list\",\n            filters=circuits_filters_dict,\n            fields=circuit_fields,\n            dry_run=dry_run,\n            instance=instance,\n        )\n        query_result.raise_for_status(f\"{self.name} - get circuits query failed\")\n\n        # return dry run result\n        if dry_run is True:\n            return query_result\n\n        all_circuits = query_result.result\n\n        # iterate over circuits and map them to devices\n        log.info(\n            f\"{self.name}:get_circuits - retrieved data for {len(all_circuits)} \"\n            f\"circuits from netbox, mapping circuits to devices\"\n        )\n        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n            results = [\n                executor.submit(\n                    self._map_circuit, circuit, ret, instance, devices, cache\n                )\n                for circuit in all_circuits\n            ]\n            for _ in concurrent.futures.as_completed(results):\n                continue\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_connections/","title":"Netbox Get Connections Task","text":"<p>task api name: <code>get_connections</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_connections/#get-connections-sample-usage","title":"Get Connections Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_connections/#norfab-netbox-get-connections-command-shell-reference","title":"NORFAB Netbox Get Connections Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>get_connections</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_connections/#python-api-reference","title":"Python API Reference","text":"<p>Function to retrieve device connections data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>devices</code> <code>list</code> <p>list of devices to retrieve interface for</p> required <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>cables</code> <code>bool</code> <p>if True includes interfaces' directly attached cables details</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with connections data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_connections(\n    self,\n    devices: list,\n    instance: str = None,\n    dry_run: bool = False,\n    cables: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Function to retrieve device connections data from Netbox using GraphQL API.\n\n    :param instance: Netbox instance name\n    :param devices: list of devices to retrieve interface for\n    :param dry_run: only return query content, do not run it\n    :param cables: if True includes interfaces' directly attached cables details\n    :return: dictionary keyed by device name with connections data\n    \"\"\"\n    # form final result dictionary\n    ret = Result(\n        task=f\"{self.name}:get_connections\", result={d: {} for d in devices}\n    )\n\n    # form lists of fields to request from netbox\n    cable_fields = \"\"\"\n        cable {\n            type\n            status\n            tenant {name}\n            label\n            tags {name}\n            length\n            length_unit\n            custom_fields\n        }\n    \"\"\"\n    if self.nb_version[0] == 4:\n        interfaces_fields = [\n            \"name\",\n            \"device {name}\",\n            \"\"\"connected_endpoints {\n            __typename \n            ... on InterfaceType {name device {name}}\n            ... on ProviderNetworkType {name}\n            }\"\"\",\n        ]\n    elif self.nb_version[0] == 3:\n        interfaces_fields = [\n            \"name\",\n            \"device {name}\",\n            \"\"\"connected_endpoints {\n            __typename \n            ... on InterfaceType {name device {name}}\n            }\"\"\",\n        ]\n    interfaces_fields.append(\n        \"\"\"\n        link_peers {\n            __typename\n            ... on InterfaceType {name device {name}}\n            ... on FrontPortType {name device {name}}\n            ... on RearPortType {name device {name}}\n        }\n    \"\"\"\n    )\n    console_ports_fields = [\n        \"name\",\n        \"device {name}\",\n        \"\"\"connected_endpoints {\n          __typename \n          ... on ConsoleServerPortType {name device {name}}\n        }\"\"\",\n        \"\"\"link_peers {\n          __typename\n          ... on ConsoleServerPortType {name device {name}}\n          ... on FrontPortType {name device {name}}\n          ... on RearPortType {name device {name}}\n        }\"\"\",\n    ]\n    console_server_ports_fields = [\n        \"name\",\n        \"device {name}\",\n        \"\"\"connected_endpoints {\n          __typename \n          ... on ConsolePortType {name device {name}}\n        }\"\"\",\n        \"\"\"link_peers {\n          __typename\n          ... on ConsolePortType {name device {name}}\n          ... on FrontPortType {name device {name}}\n          ... on RearPortType {name device {name}}\n        }\"\"\",\n    ]\n\n    # check if need to include cables info\n    if cables is True:\n        interfaces_fields.append(cable_fields)\n        console_ports_fields.append(cable_fields)\n        console_server_ports_fields.append(cable_fields)\n\n    # form query dictionary with aliases to get data from Netbox\n    queries = {\n        \"interface\": {\n            \"obj\": \"interface_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": interfaces_fields,\n        },\n        \"consoleport\": {\n            \"obj\": \"console_port_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": console_ports_fields,\n        },\n        \"consoleserverport\": {\n            \"obj\": \"console_server_port_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": console_server_ports_fields,\n        },\n    }\n\n    # retrieve full list of devices interface with all cables\n    query_result = self.graphql(queries=queries, instance=instance, dry_run=dry_run)\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    all_ports = query_result.result\n\n    # extract interfaces\n    for port_type, ports in all_ports.items():\n        for port in ports:\n            endpoints = port[\"connected_endpoints\"]\n            # skip ports that have no remote device connected\n            if not endpoints or not all(i for i in endpoints):\n                continue\n\n            # extract required parameters\n            cable = port.get(\"cable\", {})\n            device_name = port[\"device\"][\"name\"]\n            port_name = port[\"name\"]\n            link_peers = port[\"link_peers\"]\n            remote_termination_type = endpoints[0][\"__typename\"].lower()\n            remote_termination_type = remote_termination_type.replace(\"type\", \"\")\n\n            # form initial connection dictionary\n            connection = {\n                \"breakout\": len(endpoints) &gt; 1,\n                \"remote_termination_type\": remote_termination_type,\n                \"termination_type\": port_type,\n            }\n\n            # add remote connection details\n            if remote_termination_type == \"providernetwork\":\n                connection[\"remote_device\"] = None\n                connection[\"remote_interface\"] = None\n                connection[\"provider\"] = endpoints[0][\"name\"]\n            else:\n                remote_interface = endpoints[0][\"name\"]\n                if len(endpoints) &gt; 1:\n                    remote_interface = [i[\"name\"] for i in endpoints]\n                connection[\"remote_interface\"] = remote_interface\n                connection[\"remote_device\"] = endpoints[0][\"device\"][\"name\"]\n\n            # add cable and its peer details\n            if cables:\n                peer_termination_type = link_peers[0][\"__typename\"].lower()\n                peer_termination_type = peer_termination_type.replace(\"type\", \"\")\n                cable[\"peer_termination_type\"] = peer_termination_type\n                cable[\"peer_device\"] = link_peers[0].get(\"device\", {}).get(\"name\")\n                cable[\"peer_interface\"] = link_peers[0].get(\"name\")\n                if len(link_peers) &gt; 1:  # handle breakout cable\n                    cable[\"peer_interface\"] = [i[\"name\"] for i in link_peers]\n                connection[\"cable\"] = cable\n\n            ret.result[device_name][port_name] = connection\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_devices/","title":"Netbox Get Devices Task","text":"<p>task api name: <code>get_devices</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_devices/#get-devices-sample-usage","title":"Get Devices Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_devices/#norfab-netbox-get-devices-command-shell-reference","title":"NORFAB Netbox Get Devices Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>get_devices</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_devices/#python-api-reference","title":"Python API Reference","text":"<p>Function to retrieve devices data from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list</code> <p>list of filters dictionaries to filter devices</p> <code>None</code> <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>devices</code> <code>list</code> <p>list of device names to query data for</p> <code>None</code> <code>cache</code> <code>Union[bool, str]</code> <p>if <code>True</code> use data stored in cache if it is up to date refresh it otherwise, <code>False</code> do not use cache do not update cache, <code>refresh</code> ignore data in cache and replace it with data fetched from Netbox, <code>force</code> use data in cache without checking if it is up to date</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with device data</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_devices(\n    self,\n    filters: list = None,\n    instance: str = None,\n    dry_run: bool = False,\n    devices: list = None,\n    cache: Union[bool, str] = None,\n) -&gt; dict:\n    \"\"\"\n    Function to retrieve devices data from Netbox using GraphQL API.\n\n    :param filters: list of filters dictionaries to filter devices\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param devices: list of device names to query data for\n    :param cache: if `True` use data stored in cache if it is up to date\n        refresh it otherwise, `False` do not use cache do not update cache,\n        `refresh` ignore data in cache and replace it with data fetched\n        from Netbox, `force` use data in cache without checking if it is up\n        to date\n    :return: dictionary keyed by device name with device data\n    \"\"\"\n    ret = Result(task=f\"{self.name}:get_devices\", result={})\n    cache = self.cache_use if cache is None else cache\n    instance = instance or self.default_instance\n    filters = filters or []\n    devices = devices or []\n    queries = {}  # devices queries\n    device_fields = [\n        \"name\",\n        \"last_updated\",\n        \"custom_field_data\",\n        \"tags {name}\",\n        \"device_type {model}\",\n        \"role {name}\",\n        \"config_context\",\n        \"tenant {name}\",\n        \"platform {name}\",\n        \"serial\",\n        \"asset_tag\",\n        \"site {name slug tags{name} }\",\n        \"location {name}\",\n        \"rack {name}\",\n        \"status\",\n        \"primary_ip4 {address}\",\n        \"primary_ip6 {address}\",\n        \"airflow\",\n        \"position\",\n    ]\n\n    if cache == True or cache == \"force\":\n        # retrieve last updated data from Netbox for devices\n        last_updated_query = {\n            f\"devices_by_filter_{index}\": {\n                \"obj\": \"device_list\",\n                \"filters\": filter_item,\n                \"fields\": [\"name\", \"last_updated\"],\n            }\n            for index, filter_item in enumerate(filters)\n        }\n        if devices:\n            # use cache data without checking if it is up to date for cached devices\n            if cache == \"force\":\n                for device_name in list(devices):\n                    device_cache_key = f\"get_devices::{device_name}\"\n                    if device_cache_key in self.cache:\n                        devices.remove(device_name)\n                        ret.result[device_name] = self.cache[device_cache_key]\n            # query netbox last updated data for devices\n            if self.nb_version[0] == 4:\n                dlist = '[\"{dl}\"]'.format(dl='\", \"'.join(devices))\n                filters_dict = {\"name\": f\"{{in_list: {dlist}}}\"}\n            elif self.nb_version[0] == 3:\n                filters_dict = {\"name\": devices}\n            last_updated_query[\"devices_by_devices_list\"] = {\n                \"obj\": \"device_list\",\n                \"filters\": filters_dict,\n                \"fields\": [\"name\", \"last_updated\"],\n            }\n        last_updated = self.graphql(\n            queries=last_updated_query, instance=instance, dry_run=dry_run\n        )\n        last_updated.raise_for_status(f\"{self.name} - get devices query failed\")\n\n        # return dry run result\n        if dry_run:\n            ret.result[\"get_devices_dry_run\"] = last_updated.result\n            return ret\n\n        # try to retrieve device data from cache\n        self.cache.expire()  # remove expired items from cache\n        for devices_list in last_updated.result.values():\n            for device in devices_list:\n                device_cache_key = f\"get_devices::{device['name']}\"\n                # check if cache is up to date and use it if so\n                if device_cache_key in self.cache and (\n                    self.cache[device_cache_key][\"last_updated\"]\n                    == device[\"last_updated\"]\n                    or cache == \"force\"\n                ):\n                    ret.result[device[\"name\"]] = self.cache[device_cache_key]\n                    # remove device from list of devices to retrieve\n                    if device[\"name\"] in devices:\n                        devices.remove(device[\"name\"])\n                # cache old or no cache, fetch device data\n                elif device[\"name\"] not in devices:\n                    devices.append(device[\"name\"])\n    # ignore cache data, fetch data from netbox\n    elif cache == False or cache == \"refresh\":\n        queries = {\n            f\"devices_by_filter_{index}\": {\n                \"obj\": \"device_list\",\n                \"filters\": filter_item,\n                \"fields\": device_fields,\n            }\n            for index, filter_item in enumerate(filters)\n        }\n\n    # fetch devices data from Netbox\n    if devices or queries:\n        if devices:\n            if self.nb_version[0] == 4:\n                dlist = '[\"{dl}\"]'.format(dl='\", \"'.join(devices))\n                filters_dict = {\"name\": f\"{{in_list: {dlist}}}\"}\n            elif self.nb_version[0] == 3:\n                filters_dict = {\"name\": devices}\n            queries[\"devices_by_devices_list\"] = {\n                \"obj\": \"device_list\",\n                \"filters\": filters_dict,\n                \"fields\": device_fields,\n            }\n\n        # send queries\n        query_result = self.graphql(\n            queries=queries, instance=instance, dry_run=dry_run\n        )\n\n        # check for errors\n        if query_result.errors:\n            msg = f\"{self.name} - get devices query failed with errors:\\n{query_result.errors}\"\n            raise Exception(msg)\n\n        # return dry run result\n        if dry_run:\n            ret.result[\"get_devices_dry_run\"] = query_result.result\n            return ret\n\n        # process devices data\n        devices_data = query_result.result\n        for devices_list in devices_data.values():\n            for device in devices_list:\n                if device[\"name\"] not in ret.result:\n                    device_name = device.pop(\"name\")\n                    # cache device data\n                    if cache != False:\n                        cache_key = f\"get_devices::{device_name}\"\n                        self.cache.set(cache_key, device, expire=self.cache_ttl)\n                    # add device data to return result\n                    ret.result[device_name] = device\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_interfaces/","title":"Netbox Get Interfaces Task","text":"<p>task api name: <code>get_interfaces</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_interfaces/#get-interfaces-sample-usage","title":"Get Interfaces Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_interfaces/#norfab-netbox-get-interfaces-command-shell-reference","title":"NORFAB Netbox Get Interfaces Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>get_interfaces</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_interfaces/#python-api-reference","title":"Python API Reference","text":"<p>Function to retrieve device interfaces from Netbox using GraphQL API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>devices</code> <code>list</code> <p>list of devices to retrieve interfaces for</p> <code>None</code> <code>ip_addresses</code> <code>bool</code> <p>if True, retrieves interface IPs</p> <code>False</code> <code>inventory_items</code> <code>bool</code> <p>if True, retrieves interface inventory items</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with interface details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_interfaces(\n    self,\n    instance: str = None,\n    devices: list = None,\n    ip_addresses: bool = False,\n    inventory_items: bool = False,\n    dry_run: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Function to retrieve device interfaces from Netbox using GraphQL API.\n\n    :param instance: Netbox instance name\n    :param devices: list of devices to retrieve interfaces for\n    :param ip_addresses: if True, retrieves interface IPs\n    :param inventory_items: if True, retrieves interface inventory items\n    :param dry_run: only return query content, do not run it\n    :return: dictionary keyed by device name with interface details\n    \"\"\"\n    # form final result object\n    ret = Result(\n        task=f\"{self.name}:get_interfaces\", result={d: {} for d in devices}\n    )\n    intf_fields = [\n        \"name\",\n        \"enabled\",\n        \"description\",\n        \"mtu\",\n        \"parent {name}\",\n        \"mac_address\",\n        \"mode\",\n        \"untagged_vlan {vid name}\",\n        \"vrf {name}\",\n        \"tagged_vlans {vid name}\",\n        \"tags {name}\",\n        \"custom_fields\",\n        \"last_updated\",\n        \"bridge {name}\",\n        \"child_interfaces {name}\",\n        \"bridge_interfaces {name}\",\n        \"member_interfaces {name}\",\n        \"wwn\",\n        \"duplex\",\n        \"speed\",\n        \"id\",\n        \"device {name}\",\n    ]\n\n    # add IP addresses to interfaces fields\n    if ip_addresses:\n        intf_fields.append(\n            \"ip_addresses {address status role dns_name description custom_fields last_updated tenant {name} tags {name}}\"\n        )\n\n    # form interfaces query dictionary\n    queries = {\n        \"interfaces\": {\n            \"obj\": \"interface_list\",\n            \"filters\": {\"device\": devices},\n            \"fields\": intf_fields,\n        }\n    }\n\n    # add query to retrieve inventory items\n    if inventory_items:\n        inv_filters = {\"device\": devices, \"component_type\": \"dcim.interface\"}\n        inv_fields = [\n            \"name\",\n            \"component {... on InterfaceType {id}}\",\n            \"role {name}\",\n            \"manufacturer {name}\",\n            \"custom_fields\",\n            \"label\",\n            \"description\",\n            \"tags {name}\",\n            \"asset_tag\",\n            \"serial\",\n            \"part_id\",\n        ]\n        queries[\"inventor_items\"] = {\n            \"obj\": \"inventory_item_list\",\n            \"filters\": inv_filters,\n            \"fields\": inv_fields,\n        }\n\n    query_result = self.graphql(instance=instance, queries=queries, dry_run=dry_run)\n\n    # return dry run result\n    if dry_run:\n        return query_result\n\n    interfaces_data = query_result.result\n\n    # exit if no Interfaces returned\n    if not interfaces_data.get(\"interfaces\"):\n        raise Exception(\n            f\"{self.name} - no interfaces data in '{interfaces_data}' returned by '{instance}' \"\n            f\"for devices {', '.join(devices)}\"\n        )\n\n    # process query results\n    interfaces = interfaces_data.pop(\"interfaces\")\n\n    # process inventory items\n    if inventory_items:\n        inventory_items_list = interfaces_data.pop(\"inventor_items\")\n        # transform inventory items list to a dictionary keyed by intf_id\n        inventory_items_dict = {}\n        while inventory_items_list:\n            inv_item = inventory_items_list.pop()\n            # skip inventory items that does not assigned to components\n            if inv_item.get(\"component\") is None:\n                continue\n            intf_id = str(inv_item.pop(\"component\").pop(\"id\"))\n            inventory_items_dict.setdefault(intf_id, [])\n            inventory_items_dict[intf_id].append(inv_item)\n        # iterate over interfaces and add inventory items\n        for intf in interfaces:\n            intf[\"inventory_items\"] = inventory_items_dict.pop(intf[\"id\"], [])\n\n    # transform interfaces list to dictionary keyed by device and interfaces names\n    while interfaces:\n        intf = interfaces.pop()\n        _ = intf.pop(\"id\")\n        device_name = intf.pop(\"device\").pop(\"name\")\n        intf_name = intf.pop(\"name\")\n        if device_name in ret.result:  # Netbox issue #16299\n            ret.result[device_name][intf_name] = intf\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_nornir_inventory/","title":"Netbox Get Nornir Inventory Task","text":"<p>task api name: <code>get_nornir_inventory</code></p> <p>This task designed to provide Nornir workers with inventory data sourced from Netbox.</p> <p>How it works</p> <p>Netbox NorFab workers able to talk with Netbox GraphQL and REST API. Nornir workers can be configured to request Nornir inventory from Netbox workers on startup. Netbox workers in response to such a request will be fetching devices data from Netbox and constructing Nornir inventory returning it to Nornir worker.</p> <p></p> <ol> <li> <p>On startup Nornir worker sends <code>get_nornir_inventory</code> request to Netbox NorFab Workers</p> </li> <li> <p>Netbox worker fetches devices data from netbox - hostnames, interfaces, ip addresses, circuits, connections, configuration contexts etc.</p> </li> <li> <p>Netbox worker constructs Nornir inventory and sends it back to Nornir worker</p> </li> </ol>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_nornir_inventory/#get-nornir-inventory-sample-usage","title":"Get Nornir Inventory Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_nornir_inventory/#norfab-netbox-get-nornir-inventory-command-shell-reference","title":"NORFAB Netbox Get Nornir Inventory Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>get_nornir_inventory</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_get_nornir_inventory/#python-api-reference","title":"Python API Reference","text":"<p>Method to query Netbox devices data and construct Nornir inventory.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list</code> <p>List of filters to apply when querying devices.</p> <code>None</code> <code>devices</code> <code>list</code> <p>List of specific devices to query.</p> <code>None</code> <code>instance</code> <code>str</code> <p>Netbox instance name to query.</p> <code>None</code> <code>interfaces</code> <code>Union[dict, bool]</code> <p>Whether to include interfaces data. If a dict is provided, it will be used as arguments for the query.</p> <code>False</code> <code>connections</code> <code>Union[dict, bool]</code> <p>Whether to include connections data. If a dict is provided, it will be used as arguments for the query.</p> <code>False</code> <code>circuits</code> <code>Union[dict, bool]</code> <p>Whether to include circuits data. If a dict is provided, it will be used as arguments for the query.</p> <code>False</code> <code>nbdata</code> <code>bool</code> <p>Whether to include Netbox devices data in the host's data</p> <code>True</code> <code>primary_ip</code> <code>str</code> <p>Primary IP version to use for the hostname.</p> <code>'ip4'</code> <p>Returns:</p> Type Description <code>dict</code> <p>Nornir Inventory compatible dictionary</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def get_nornir_inventory(\n    self,\n    filters: list = None,\n    devices: list = None,\n    instance: str = None,\n    interfaces: Union[dict, bool] = False,\n    connections: Union[dict, bool] = False,\n    circuits: Union[dict, bool] = False,\n    nbdata: bool = True,\n    primary_ip: str = \"ip4\",\n) -&gt; dict:\n    \"\"\"\n    Method to query Netbox devices data and construct Nornir inventory.\n\n    :param filters: List of filters to apply when querying devices.\n    :param devices: List of specific devices to query.\n    :param instance: Netbox instance name to query.\n    :param interfaces: Whether to include interfaces data. If a dict is provided,\n        it will be used as arguments for the query.\n    :param connections: Whether to include connections data. If a dict is provided,\n        it will be used as arguments for the query.\n    :param circuits: Whether to include circuits data. If a dict is provided,\n        it will be used as arguments for the query.\n    :param nbdata: Whether to include Netbox devices data in the host's data\n    :param primary_ip: Primary IP version to use for the hostname.\n    :returns: Nornir Inventory compatible dictionary\n    \"\"\"\n    hosts = {}\n    inventory = {\"hosts\": hosts}\n    ret = Result(task=f\"{self.name}:get_nornir_inventory\", result=inventory)\n\n    # check Netbox status\n    netbox_status = self.get_netbox_status(instance=instance)\n    if netbox_status.result[instance or self.default_instance][\"status\"] is False:\n        return ret\n\n    # retrieve devices data\n    nb_devices = self.get_devices(\n        filters=filters, devices=devices, instance=instance\n    )\n\n    # form Nornir hosts inventory\n    for device_name, device in nb_devices.result.items():\n        host = device[\"config_context\"].pop(\"nornir\", {})\n        host.setdefault(\"data\", {})\n        name = host.pop(\"name\", device_name)\n        hosts[name] = host\n        # add platform if not provided in device config context\n        if not host.get(\"platform\"):\n            if device[\"platform\"]:\n                host[\"platform\"] = device[\"platform\"][\"name\"]\n            else:\n                log.warning(f\"{self.name} - no platform found for '{name}' device\")\n        # add hostname if not provided in config context\n        if not host.get(\"hostname\"):\n            if device[\"primary_ip4\"] and primary_ip in [\"ip4\", \"ipv4\"]:\n                host[\"hostname\"] = device[\"primary_ip4\"][\"address\"].split(\"/\")[0]\n            elif device[\"primary_ip6\"] and primary_ip in [\"ip6\", \"ipv6\"]:\n                host[\"hostname\"] = device[\"primary_ip6\"][\"address\"].split(\"/\")[0]\n            else:\n                host[\"hostname\"] = name\n        # add netbox data to host's data\n        if nbdata is True:\n            host[\"data\"].update(device)\n\n    # return if no hosts found for provided parameters\n    if not hosts:\n        log.warning(f\"{self.name} - no viable hosts returned by Netbox\")\n        return ret\n\n    # add interfaces data\n    if interfaces:\n        # decide on get_interfaces arguments\n        kwargs = interfaces if isinstance(interfaces, dict) else {}\n        # add 'interfaces' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"interfaces\", {})\n        # query interfaces data from netbox\n        nb_interfaces = self.get_interfaces(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save interfaces data to hosts' inventory\n        while nb_interfaces.result:\n            device, device_interfaces = nb_interfaces.result.popitem()\n            hosts[device][\"data\"][\"interfaces\"] = device_interfaces\n\n    # add connections data\n    if connections:\n        # decide on get_interfaces arguments\n        kwargs = connections if isinstance(connections, dict) else {}\n        # add 'connections' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"connections\", {})\n        # query connections data from netbox\n        nb_connections = self.get_connections(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save connections data to hosts' inventory\n        while nb_connections.result:\n            device, device_connections = nb_connections.result.popitem()\n            hosts[device][\"data\"][\"connections\"] = device_connections\n\n    # add circuits data\n    if circuits:\n        # decide on get_interfaces arguments\n        kwargs = circuits if isinstance(circuits, dict) else {}\n        # add 'circuits' key to all hosts' data\n        for host in hosts.values():\n            host[\"data\"].setdefault(\"circuits\", {})\n        # query circuits data from netbox\n        nb_circuits = self.get_circuits(\n            devices=list(hosts), instance=instance, **kwargs\n        )\n        # save circuits data to hosts' inventory\n        while nb_circuits.result:\n            device, device_circuits = nb_circuits.result.popitem()\n            hosts[device][\"data\"][\"circuits\"] = device_circuits\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_graphql/","title":"Netbox GrapQL Inventory Task","text":"<p>task api name: <code>graphql</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_graphql/#grapql-sample-usage","title":"GrapQL Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_graphql/#norfab-netbox-grapql-command-shell-reference","title":"NORFAB Netbox GrapQL Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>graphql</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_graphql/#python-api-reference","title":"Python API Reference","text":"<p>Function to query Netbox v4 GraphQL API</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>only return query content, do not run it</p> <code>False</code> <code>obj</code> <code>dict</code> <p>Object to query</p> <code>None</code> <code>filters</code> <code>dict</code> <p>Filters to apply to the query</p> <code>None</code> <code>fields</code> <code>list</code> <p>Fields to retrieve in the query</p> <code>None</code> <code>queries</code> <code>dict</code> <p>Dictionary of queries to execute</p> <code>None</code> <code>query_string</code> <code>str</code> <p>Raw query string to execute</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[dict, list]</code> <p>GraphQL request data returned by Netbox</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If required arguments are not provided</p> <code>Exception</code> <p>If GraphQL query fails</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def graphql(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    obj: dict = None,\n    filters: dict = None,\n    fields: list = None,\n    queries: dict = None,\n    query_string: str = None,\n) -&gt; Union[dict, list]:\n    \"\"\"\n    Function to query Netbox v4 GraphQL API\n\n    :param instance: Netbox instance name\n    :param dry_run: only return query content, do not run it\n    :param obj: Object to query\n    :param filters: Filters to apply to the query\n    :param fields: Fields to retrieve in the query\n    :param queries: Dictionary of queries to execute\n    :param query_string: Raw query string to execute\n    :return: GraphQL request data returned by Netbox\n    :raises RuntimeError: If required arguments are not provided\n    :raises Exception: If GraphQL query fails\n    \"\"\"\n    nb_params = self._get_instance_params(instance)\n    ret = Result(task=f\"{self.name}:graphql\")\n\n    # form graphql query(ies) payload\n    if queries:\n        queries_list = []\n        for alias, query_data in queries.items():\n            query_data[\"alias\"] = alias\n            if self.nb_version[0] == 4:\n                queries_list.append(_form_query_v4(**query_data))\n            elif self.nb_version[0] == 3:\n                queries_list.append(_form_query_v3(**query_data))\n        queries_strings = \"    \".join(queries_list)\n        query = f\"query {{{queries_strings}}}\"\n    elif obj and filters and fields:\n        if self.nb_version[0] == 4:\n            query = _form_query_v4(obj, filters, fields)\n        elif self.nb_version[0] == 3:\n            query = _form_query_v3(obj, filters, fields)\n        query = f\"query {{{query}}}\"\n    elif query_string:\n        query = query_string\n    else:\n        raise RuntimeError(\n            f\"{self.name} - graphql method expects quieries argument or obj, filters, \"\n            f\"fields arguments or query_string argument provided\"\n        )\n    payload = json.dumps({\"query\": query})\n\n    # form and return dry run response\n    if dry_run:\n        ret.result = {\n            \"url\": f\"{nb_params['url']}/graphql/\",\n            \"data\": payload,\n            \"verify\": nb_params.get(\"ssl_verify\", True),\n            \"headers\": {\n                \"Content-Type\": \"application/json\",\n                \"Accept\": \"application/json\",\n                \"Authorization\": f\"Token ...{nb_params['token'][-6:]}\",\n            },\n        }\n        return ret\n\n    # send request to Netbox GraphQL API\n    log.debug(\n        f\"{self.name} - sending GraphQL query '{payload}' to URL '{nb_params['url']}/graphql/'\"\n    )\n    req = requests.post(\n        url=f\"{nb_params['url']}/graphql/\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Token {nb_params['token']}\",\n        },\n        data=payload,\n        verify=nb_params.get(\"ssl_verify\", True),\n        timeout=(self.netbox_connect_timeout, self.netbox_read_timeout),\n    )\n    try:\n        req.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"{self.name} -  Netbox GraphQL query failed, query '{query}', \"\n            f\"URL '{req.url}', status-code '{req.status_code}', reason '{req.reason}', \"\n            f\"response content '{req.text}'\"\n        )\n\n    # return results\n    reply = req.json()\n    if reply.get(\"errors\"):\n        msg = f\"{self.name} - GrapQL query error '{reply['errors']}', query '{payload}'\"\n        log.error(msg)\n        ret.errors.append(msg)\n        if reply.get(\"data\"):\n            ret.result = reply[\"data\"]  # at least return some data\n    elif queries or query_string:\n        ret.result = reply[\"data\"]\n    else:\n        ret.result = reply[\"data\"][obj]\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_rest/","title":"Netbox Rest Inventory Task","text":"<p>task api name: <code>rest</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_rest/#rest-task-sample-usage","title":"Rest Task Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_rest/#norfab-netbox-grapql-command-shell-reference","title":"NORFAB Netbox GrapQL Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>rest</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_rest/#python-api-reference","title":"Python API Reference","text":"<p>Method to query Netbox REST API.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>method</code> <code>str</code> <p>requests method name e.g. get, post, put etc.</p> <code>'get'</code> <code>api</code> <code>str</code> <p>api url to query e.g. \"extras\" or \"dcim/interfaces\" etc.</p> <code>''</code> <code>kwargs</code> <p>any additional requests method's arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[dict, list]</code> <p>REST API Query result</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If REST API query fails</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def rest(\n    self, instance: str = None, method: str = \"get\", api: str = \"\", **kwargs\n) -&gt; Union[dict, list]:\n    \"\"\"\n    Method to query Netbox REST API.\n\n    :param instance: Netbox instance name\n    :param method: requests method name e.g. get, post, put etc.\n    :param api: api url to query e.g. \"extras\" or \"dcim/interfaces\" etc.\n    :param kwargs: any additional requests method's arguments\n    :return: REST API Query result\n    :raises Exception: If REST API query fails\n    \"\"\"\n    params = self._get_instance_params(instance)\n\n    # send request to Netbox REST API\n    response = getattr(requests, method)(\n        url=f\"{params['url']}/api/{api}/\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Token {params['token']}\",\n        },\n        verify=params.get(\"ssl_verify\", True),\n        **kwargs,\n    )\n\n    response.raise_for_status()\n\n    return response.json()\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_facts/","title":"Netbox Update Device Facts Task","text":"<p>task api name: <code>update_device_facts</code></p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_facts/#limitations","title":"Limitations","text":"<p>Datasource <code>nornir</code> uses NAPALM <code>get_facts</code> getter and as such only supports these device platforms:</p> <ul> <li>Arista EOS</li> <li>Cisco IOS</li> <li>Cisco IOSXR</li> <li>Cisco NXOS</li> <li>Juniper JUNOS</li> </ul>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_facts/#update-device-facts-sample-usage","title":"Update Device Facts Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_facts/#norfab-netbox-update-device-facts-command-shell-reference","title":"NORFAB Netbox Update Device Facts Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>update_device_facts</code> task:</p>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_facts/#python-api-reference","title":"Python API Reference","text":"<p>Function to update device facts in Netbox using information provided by NAPALM get_facts getter:</p> <ul> <li>serial number</li> </ul> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>datasource</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>batch_size</code> <code>int</code> <p>number of devices to process at a time</p> <code>10</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with updated details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_facts(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    datasource: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    batch_size: int = 10,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to update device facts in Netbox using information\n    provided by NAPALM get_facts getter:\n\n    - serial number\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param datasource: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param batch_size: number of devices to process at a time\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    :returns: dictionary keyed by device name with updated details\n    \"\"\"\n    result = {}\n    devices = devices or []\n    instance = instance or self.default_instance\n    ret = Result(task=f\"{self.name}:update_device_facts\", result=result)\n    nb = self._get_pynetbox(instance)\n    kwargs[\"add_details\"] = True\n\n    if datasource == \"nornir\":\n        for i in range(0, len(devices), batch_size):\n            kwargs[\"FL\"] = devices[i : i + batch_size]\n            kwargs[\"getters\"] = \"get_facts\"\n            self.event(\n                f\"retrieving facts data for devices {', '.join(kwargs['FL'])}\",\n                resource=instance,\n            )\n            data = self.client.run_job(\n                \"nornir\",\n                \"parse\",\n                kwargs=kwargs,\n                workers=\"all\",\n                timeout=timeout,\n            )\n            for worker, results in data.items():\n                if results[\"failed\"]:\n                    log.error(\n                        f\"{worker} get_facts failed, errors: {'; '.join(results['errors'])}\"\n                    )\n                    continue\n                for host, host_data in results[\"result\"].items():\n                    if host_data[\"napalm_get\"][\"failed\"]:\n                        log.error(\n                            f\"{host} facts update failed: '{host_data['napalm_get']['exception']}'\"\n                        )\n                        self.event(\n                            f\"{host} facts update failed\",\n                            resource=instance,\n                            status=\"failed\",\n                            severity=\"WARNING\",\n                        )\n                        continue\n                    nb_device = nb.dcim.devices.get(name=host)\n                    if not nb_device:\n                        raise Exception(f\"'{host}' does not exist in Netbox\")\n                    facts = host_data[\"napalm_get\"][\"result\"][\"get_facts\"]\n                    # update serial number\n                    nb_device.serial = facts[\"serial_number\"]\n                    if not dry_run:\n                        nb_device.save()\n                    result[host] = {\n                        \"update_device_facts_dry_run\"\n                        if dry_run\n                        else \"update_device_facts\": {\n                            \"serial\": facts[\"serial_number\"],\n                        }\n                    }\n                    self.event(f\"{host} facts updated\", resource=instance)\n    else:\n        raise UnsupportedServiceError(\n            f\"'{datasource}' datasource service not supported\"\n        )\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_interfaces/","title":"Netbox Update Device Interfaces Task","text":"<p>task api name: <code>update_device_interfaces</code></p> <p>The Netbox Update Device Interfaces Task is a feature of the NorFab Netbox Service that allows you to synchronize and update the interface data of your network devices in Netbox. This task ensures that the interface configurations in Netbox are accurate and up-to-date, reflecting the current state of your network infrastructure.</p> <p>Keeping interface data accurate and up-to-date is crucial for effective network management. The Netbox Update Device Interfaces Task automates the process of updating interface information, such as interface names, statuses, mac addresses, and other relevant details.</p> <p>How it works - Netbox worker on a call to update interfaces task fetches live data from network devices using nominated datasource, by default it is Nornir service parse task using NAPALM <code>get_interfaces</code> getter. Once data retrieved from network, Netbox worker updates records in Netbox database for device interfaces.</p> <p></p> <ol> <li> <p>Client submits and on-demand request to NorFab Netbox worker to update device interfaces</p> </li> <li> <p>Netbox worker sends job request to nominated datasource service to fetch live data from network devices</p> </li> <li> <p>Datasource service fetches data from the network</p> </li> <li> <p>Datasource returns devices interfaces data back to Netbox Service worker</p> </li> <li> <p>Netbox worker processes device interfaces data and updates records in Netbox for requested devices</p> </li> </ol>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_interfaces/#limitations","title":"Limitations","text":"<p>Datasource <code>nornir</code> uses NAPALM <code>get_interfaces</code> getter and as such only supports these device platforms:</p> <ul> <li>Arista EOS</li> <li>Cisco IOS</li> <li>Cisco IOSXR</li> <li>Cisco NXOS</li> <li>Juniper JUNOS</li> </ul>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_interfaces/#update-device-interfaces-sample-usage","title":"Update Device Interfaces Sample Usage","text":"","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_interfaces/#norfab-netbox-update-device-interfaces-command-shell-reference","title":"NORFAB Netbox Update Device Interfaces Command Shell Reference","text":"<p>NorFab shell supports these command options for Netbox <code>update_device_interfaces</code> task:</p> <pre><code>nf# man tree netbox.update.device.interfaces\nroot\n\u2514\u2500\u2500 netbox:    Netbox service\n    \u2514\u2500\u2500 update:    Update Netbox data\n        \u2514\u2500\u2500 device:    Update device data\n            \u2514\u2500\u2500 interfaces:    Update device interfaces\n                \u251c\u2500\u2500 timeout:    Job timeout\n                \u251c\u2500\u2500 workers:    Filter workers to target, default 'any'\n                \u251c\u2500\u2500 instance:    Netbox instance name to target\n                \u251c\u2500\u2500 dry_run:    Return information that would be pushed to Netbox but do not push it\n                \u251c\u2500\u2500 devices:    Devices to update\n                \u2514\u2500\u2500 datasource:    Service to use to retrieve device data, default 'nornir'\n                    \u2514\u2500\u2500 nornir:    Use Nornir service to retrieve data from devices\n                        \u251c\u2500\u2500 add_details:    Add task details to results, default 'False'\n                        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n                        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n                        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n                        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n                        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n                        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n                        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n                        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n                        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n                        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n                        \u251c\u2500\u2500 diff:    File group name to run the diff for\n                        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n                        \u2514\u2500\u2500 progress:    Display progress events, default 'True'\nnf#\n</code></pre>","tags":["netbox"]},{"location":"workers/netbox/services_netbox_service_tasks_update_device_interfaces/#python-api-reference","title":"Python API Reference","text":"<p>Function to update device interfaces in Netbox using information provided by NAPALM <code>get_interfaces</code> getter:</p> <ul> <li>interface name</li> <li>interface description</li> <li>mtu</li> <li>mac address</li> <li>admin status</li> <li>speed</li> </ul> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>Netbox instance name</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>return information that would be pushed to Netbox but do not push it</p> <code>False</code> <code>datasource</code> <code>str</code> <p>service name to use to retrieve devices' data, default is nornir parse task</p> <code>'nornir'</code> <code>timeout</code> <code>int</code> <p>seconds to wait before timeout data retrieval job</p> <code>60</code> <code>create</code> <code>bool</code> <p>create missing interfaces</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>number of devices to process at a time</p> <code>10</code> <code>kwargs</code> <p>any additional arguments to send to service for device data retrieval</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary keyed by device name with update details</p> Source code in <code>norfab\\workers\\netbox_worker.py</code> <pre><code>def update_device_interfaces(\n    self,\n    instance: str = None,\n    dry_run: bool = False,\n    datasource: str = \"nornir\",\n    timeout: int = 60,\n    devices: list = None,\n    create: bool = True,\n    batch_size: int = 10,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to update device interfaces in Netbox using information\n    provided by NAPALM `get_interfaces` getter:\n\n    - interface name\n    - interface description\n    - mtu\n    - mac address\n    - admin status\n    - speed\n\n    :param instance: Netbox instance name\n    :param dry_run: return information that would be pushed to Netbox but do not push it\n    :param datasource: service name to use to retrieve devices' data, default is nornir parse task\n    :param timeout: seconds to wait before timeout data retrieval job\n    :param create: create missing interfaces\n    :param batch_size: number of devices to process at a time\n    :param kwargs: any additional arguments to send to service for device data retrieval\n    :returns: dictionary keyed by device name with update details\n    \"\"\"\n    result = {}\n    instance = instance or self.default_instance\n    ret = Result(task=f\"{self.name}:update_device_interfaces\", result=result)\n    nb = self._get_pynetbox(instance)\n\n    if datasource == \"nornir\":\n        for i in range(0, len(devices), batch_size):\n            kwargs[\"FL\"] = devices[i : i + batch_size]\n            kwargs[\"getters\"] = \"get_interfaces\"\n            data = self.client.run_job(\n                \"nornir\",\n                \"parse\",\n                kwargs=kwargs,\n                workers=\"all\",\n                timeout=timeout,\n            )\n            for worker, results in data.items():\n                if results[\"failed\"]:\n                    log.error(\n                        f\"{worker} get_interfaces failed, errors: {'; '.join(results['errors'])}\"\n                    )\n                    continue\n                for host, host_data in results[\"result\"].items():\n                    updated, created = {}, {}\n                    result[host] = {\n                        \"update_device_interfaces_dry_run\"\n                        if dry_run\n                        else \"update_device_interfaces\": updated,\n                        \"created_device_interfaces_dry_run\"\n                        if dry_run\n                        else \"created_device_interfaces\": created,\n                    }\n                    interfaces = host_data[\"napalm_get\"][\"get_interfaces\"]\n                    nb_device = nb.dcim.devices.get(name=host)\n                    if not nb_device:\n                        raise Exception(f\"'{host}' does not exist in Netbox\")\n                    nb_interfaces = nb.dcim.interfaces.filter(\n                        device_id=nb_device.id\n                    )\n                    # update existing interfaces\n                    for nb_interface in nb_interfaces:\n                        if nb_interface.name not in interfaces:\n                            continue\n                        interface = interfaces.pop(nb_interface.name)\n                        nb_interface.description = interface[\"description\"]\n                        nb_interface.mtu = interface[\"mtu\"]\n                        nb_interface.speed = interface[\"speed\"] * 1000\n                        nb_interface.mac_address = interface[\"mac_address\"]\n                        nb_interface.enabled = interface[\"is_enabled\"]\n                        if dry_run is not True:\n                            nb_interface.save()\n                        updated[nb_interface.name] = interface\n                        self.event(\n                            f\"{host} updated interface {nb_interface.name}\",\n                            resource=instance,\n                        )\n                    # create new interfaces\n                    if create is not True:\n                        continue\n                    for interface_name, interface in interfaces.items():\n                        interface[\"type\"] = \"other\"\n                        nb_interface = nb.dcim.interfaces.create(\n                            name=interface_name,\n                            device={\"name\": nb_device.name},\n                            type=interface[\"type\"],\n                        )\n                        nb_interface.description = interface[\"description\"]\n                        nb_interface.mtu = interface[\"mtu\"]\n                        nb_interface.speed = interface[\"speed\"] * 1000\n                        nb_interface.mac_address = interface[\"mac_address\"]\n                        nb_interface.enabled = interface[\"is_enabled\"]\n                        if dry_run is not True:\n                            nb_interface.save()\n                        created[interface_name] = interface\n                        self.event(\n                            f\"{host} created interface {nb_interface.name}\",\n                            resource=instance,\n                        )\n    else:\n        raise UnsupportedServiceError(\n            f\"'{datasource}' datasource service not supported\"\n        )\n\n    return ret\n</code></pre>","tags":["netbox"]},{"location":"workers/nornir/api_reference_workers_nornir_worker/","title":"Nornir Worker","text":""},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog","title":"<code>WatchDog(worker)</code>","text":"<p>               Bases: <code>WorkerWatchDog</code></p> <p>Class to monitor Nornir worker performance</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def __init__(self, worker):\n    super().__init__(worker)\n    self.worker = worker\n    self.connections_idle_timeout = worker.inventory.get(\n        \"connections_idle_timeout\", None\n    )\n    self.connections_data = {}  # store connections use timestamps\n    self.started_at = time.time()\n\n    # stats attributes\n    self.idle_connections_cleaned = 0\n    self.dead_connections_cleaned = 0\n\n    # list of tasks for watchdog to run in given order\n    self.watchdog_tasks = [\n        self.connections_clean,\n        self.connections_keepalive,\n    ]\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog.connections_update","title":"<code>connections_update(nr, plugin)</code>","text":"<p>Function to update connection use timestamps for each host</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <p>Nornir object</p> required <code>plugin</code> <code>str</code> <p>connection plugin name</p> required Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def connections_update(self, nr, plugin: str) -&gt; None:\n    \"\"\"\n    Function to update connection use timestamps for each host\n\n    :param nr: Nornir object\n    :param plugin: connection plugin name\n    \"\"\"\n    conn_stats = {\n        \"last_use\": None,\n        \"last_keepealive\": None,\n        \"keepalive_count\": 0,\n    }\n    for host_name in nr.inventory.hosts:\n        self.connections_data.setdefault(host_name, {})\n        self.connections_data[host_name].setdefault(plugin, conn_stats.copy())\n        self.connections_data[host_name][plugin][\"last_use\"] = time.ctime()\n    log.info(\n        f\"{self.worker.name} - updated connections use timestamps for '{plugin}'\"\n    )\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog.connections_clean","title":"<code>connections_clean()</code>","text":"<p>Check if need to tear down connections that are idle - not being used over connections_idle_timeout</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def connections_clean(self):\n    \"\"\"\n    Check if need to tear down connections that are idle -\n    not being used over connections_idle_timeout\n    \"\"\"\n    # dictionary keyed by plugin name and value as a list of hosts\n    disconnect = {}\n    if not self.worker.connections_lock.acquire(blocking=False):\n        return\n    try:\n        # if idle timeout not set, connections don't age out\n        if self.connections_idle_timeout is None:\n            disconnect = {}\n        # disconnect all connections for all hosts\n        elif self.connections_idle_timeout == 0:\n            disconnect = {\"all\": list(self.connections_data.keys())}\n        # only disconnect aged/idle connections\n        elif self.connections_idle_timeout &gt; 0:\n            for host_name, plugins in self.connections_data.items():\n                for plugin, conn_data in plugins.items():\n                    last_use = time.mktime(time.strptime(conn_data[\"last_use\"]))\n                    age = time.time() - last_use\n                    if age &gt; self.connections_idle_timeout:\n                        disconnect.setdefault(plugin, [])\n                        disconnect[plugin].append(host_name)\n        # run task to disconnect connections for aged hosts\n        for plugin, hosts in disconnect.items():\n            if not hosts:\n                continue\n            aged_hosts = FFun(self.worker.nr, FL=hosts)\n            aged_hosts.run(task=nr_connections, call=\"close\", conn_name=plugin)\n            log.debug(\n                f\"{self.worker.name} watchdog, disconnected '{plugin}' \"\n                f\"connections for '{', '.join(hosts)}'\"\n            )\n            self.idle_connections_cleaned += len(hosts)\n            # wipe out connections data if all connection closed\n            if plugin == \"all\":\n                self.connections_data = {}\n                break\n            # remove disconnected plugin from host's connections_data\n            for host in hosts:\n                self.connections_data[host].pop(plugin)\n                if not self.connections_data[host]:\n                    self.connections_data.pop(host)\n    except Exception as e:\n        msg = f\"{self.worker.name} - watchdog failed to close idle connections, error: {e}\"\n        log.error(msg)\n    finally:\n        self.worker.connections_lock.release()\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.WatchDog.connections_keepalive","title":"<code>connections_keepalive()</code>","text":"<p>Keepalive connections and clean up dead connections if any</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def connections_keepalive(self):\n    \"\"\"Keepalive connections and clean up dead connections if any\"\"\"\n    if self.connections_idle_timeout == 0:  # do not keepalive if idle is 0\n        return\n    if not self.worker.connections_lock.acquire(blocking=False):\n        return\n    try:\n        log.debug(f\"{self.worker.name} - watchdog running connections keepalive\")\n        stats = HostsKeepalive(self.worker.nr)\n        self.dead_connections_cleaned += stats[\"dead_connections_cleaned\"]\n        # remove connections that are no longer present in Nornir inventory\n        for host_name, host_connections in self.connections_data.items():\n            for connection_name in list(host_connections.keys()):\n                if not self.worker.nr.inventory.hosts[host_name].connections.get(\n                    connection_name\n                ):\n                    self.connections_data[host_name].pop(connection_name)\n        # remove host if no connections left\n        for host_name in list(self.connections_data.keys()):\n            if self.connections_data[host_name] == {}:\n                self.connections_data.pop(host_name)\n        # update connections statistics\n        for plugins in self.connections_data.values():\n            for plugin in plugins.values():\n                plugin[\"last_keepealive\"] = time.ctime()\n                plugin[\"keepalive_count\"] += 1\n    except Exception as e:\n        msg = f\"{self.worker.name} - watchdog HostsKeepalive check error: {e}\"\n        log.error(msg)\n    finally:\n        self.worker.connections_lock.release()\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker","title":"<code>NornirWorker(inventory, broker, worker_name, service=b'nornir', exit_event=None, init_done_event=None, log_level=None, log_queue=None)</code>","text":"<p>               Bases: <code>NFPWorker</code></p> <p>Nornir service worker</p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <code>str</code> <p>broker URL to connect to</p> required <code>service</code> <code>str</code> <p>name of the service with worker belongs to</p> <code>b'nornir'</code> <code>worker_name</code> <code>str</code> <p>name of this worker</p> required <code>exit_event</code> <p>if set, worker need to stop/exit</p> <code>None</code> <code>init_done_event</code> <p>event to set when worker done initializing</p> <code>None</code> <code>log_level</code> <code>str</code> <p>logging level of this worker</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def __init__(\n    self,\n    inventory: str,\n    broker: str,\n    worker_name: str,\n    service: str = b\"nornir\",\n    exit_event=None,\n    init_done_event=None,\n    log_level: str = None,\n    log_queue: object = None,\n):\n    super().__init__(\n        inventory, broker, service, worker_name, exit_event, log_level, log_queue\n    )\n    self.init_done_event = init_done_event\n    self.tf_base_path = os.path.join(self.base_dir, \"tf\")\n\n    # misc attributes\n    self.connections_lock = Lock()\n\n    # get inventory from broker\n    self.nornir_inventory = self.load_inventory()\n\n    # pull Nornir inventory from Netbox\n    self._pull_netbox_inventory()\n\n    # initiate Nornir\n    self._init_nornir()\n\n    # initiate watchdog\n    self.watchdog = WatchDog(self)\n    self.watchdog.start()\n\n    if self.init_done_event is not None:\n        self.init_done_event.set()\n\n    log.info(f\"{self.name} - Started\")\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker._pull_netbox_inventory","title":"<code>_pull_netbox_inventory()</code>","text":"<p>Function to query inventory from Netbox</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def _pull_netbox_inventory(self):\n    \"\"\"Function to query inventory from Netbox\"\"\"\n    # exit if has no Netbox data in inventory\n    if isinstance(self.nornir_inventory.get(\"netbox\"), dict):\n        kwargs = self.nornir_inventory[\"netbox\"]\n    elif self.nornir_inventory.get(\"netbox\") is True:\n        kwargs = {}\n    else:\n        return\n\n    # extract parameters from kwargs\n    retry = max(1, kwargs.pop(\"retry\", 3))\n    retry_timeout = max(10, kwargs.pop(\"retry_timeout\", 100))\n\n    # check if need to add devices list\n    if \"filters\" not in kwargs and \"devices\" not in kwargs:\n        if self.nornir_inventory.get(\"hosts\"):\n            kwargs[\"devices\"] = list(self.nornir_inventory[\"hosts\"])\n        else:\n            log.critical(\n                f\"{self.name} - inventory has no hosts, netbox \"\n                f\"filters or devices defined\"\n            )\n            return\n\n    nb_inventory_data = self.client.run_job(\n        service=\"netbox\",\n        task=\"get_nornir_inventory\",\n        workers=\"any\",\n        kwargs=kwargs,\n        timeout=retry_timeout * retry,\n        retry=retry,\n    )\n\n    if nb_inventory_data is None:\n        log.error(\n            f\"{self.name} - Netbox get_nornir_inventory no inventory returned\"\n        )\n        return\n\n    wname, wdata = nb_inventory_data.popitem()\n\n    # merge Netbox inventory into Nornir inventory\n    if wdata[\"failed\"] is False and wdata[\"result\"].get(\"hosts\"):\n        merge_recursively(self.nornir_inventory, wdata[\"result\"])\n    else:\n        log.warning(\n            f\"{self.name} - '{kwargs.get('instance', 'default')}' Netbox \"\n            f\"instance returned no hosts data, worker '{wname}'\"\n        )\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker._add_processors","title":"<code>_add_processors(nr, kwargs)</code>","text":"<p>Helper function to extract processors arguments and add processors to Nornir.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>(dict) dictionary with kwargs</p> required <code>nr</code> <p>(obj) Nornir object to add processors to</p> required <p>Returns:</p> Type Description <p>(obj) Nornir object with added processors</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def _add_processors(self, nr, kwargs: dict):\n    \"\"\"\n    Helper function to extract processors arguments and add processors\n    to Nornir.\n\n    :param kwargs: (dict) dictionary with kwargs\n    :param nr: (obj) Nornir object to add processors to\n    :return: (obj) Nornir object with added processors\n    \"\"\"\n    processors = []\n\n    # extract parameters\n    tf = kwargs.pop(\"tf\", None)  # to file\n    tf_skip_failed = kwargs.pop(\"tf_skip_failed\", False)  # to file\n    diff = kwargs.pop(\"diff\", \"\")  # diff processor\n    diff_last = kwargs.pop(\"diff_last\", 1) if diff else None  # diff processor\n    dp = kwargs.pop(\"dp\", [])  # data processor\n    xml_flake = kwargs.pop(\"xml_flake\", \"\")  # data processor xml_flake function\n    match = kwargs.pop(\"match\", \"\")  # data processor match function\n    before = kwargs.pop(\"before\", 0)  # data processor match function\n    run_ttp = kwargs.pop(\"run_ttp\", None)  # data processor run_ttp function\n    ttp_structure = kwargs.pop(\n        \"ttp_structure\", \"flat_list\"\n    )  # data processor run_ttp function\n    remove_tasks = kwargs.pop(\"remove_tasks\", True)  # tests and/or run_ttp\n    tests = kwargs.pop(\"tests\", None)  # tests\n    subset = kwargs.pop(\"subset\", [])  # tests\n    failed_only = kwargs.pop(\"failed_only\", False)  # tests\n    xpath = kwargs.pop(\"xpath\", \"\")  # xpath DataProcessor\n    jmespath = kwargs.pop(\"jmespath\", \"\")  # jmespath DataProcessor\n    iplkp = kwargs.pop(\"iplkp\", \"\")  # iplkp - ip lookup - DataProcessor\n    ntfsm = kwargs.pop(\"ntfsm\", False)  # ntfsm - ntc-templates TextFSM parsing\n    progress = kwargs.pop(\n        \"progress\", False\n    )  # Emit progress events using NorFabEventProcessor\n\n    # add processors if any\n    if dp:\n        processors.append(DataProcessor(dp))\n    if iplkp:\n        processors.append(\n            DataProcessor(\n                [\n                    {\n                        \"fun\": \"iplkp\",\n                        \"use_dns\": True if iplkp == \"dns\" else False,\n                        \"use_csv\": iplkp if iplkp else False,\n                    }\n                ]\n            )\n        )\n    if xml_flake:\n        processors.append(\n            DataProcessor([{\"fun\": \"xml_flake\", \"pattern\": xml_flake}])\n        )\n    if xpath:\n        processors.append(\n            DataProcessor(\n                [{\"fun\": \"xpath\", \"expr\": xpath, \"recover\": True, \"rm_ns\": True}]\n            )\n        )\n    if jmespath:\n        processors.append(DataProcessor([{\"fun\": \"jmespath\", \"expr\": jmespath}]))\n    if match:\n        processors.append(\n            DataProcessor([{\"fun\": \"match\", \"pattern\": match, \"before\": before}])\n        )\n    if run_ttp:\n        processors.append(\n            DataProcessor(\n                [\n                    {\n                        \"fun\": \"run_ttp\",\n                        \"template\": run_ttp,\n                        \"res_kwargs\": {\"structure\": ttp_structure},\n                        \"remove_tasks\": remove_tasks,\n                    }\n                ]\n            )\n        )\n    if ntfsm:\n        processors.append(DataProcessor([{\"fun\": \"ntfsm\"}]))\n    if tests:\n        processors.append(\n            TestsProcessor(\n                tests=tests,\n                remove_tasks=remove_tasks,\n                failed_only=failed_only,\n                build_per_host_tests=True,\n                subset=subset,\n                render_tests=False,\n            )\n        )\n    if diff:\n        processors.append(\n            DiffProcessor(\n                diff=diff,\n                last=int(diff_last),\n                base_url=self.tf_base_path,\n                index=self.name,\n            )\n        )\n    if progress:\n        processors.append(\n            NorFabEventProcessor(\n                worker=self, norfab_task_name=self.current_job[\"task\"]\n            )\n        )\n    # append ToFileProcessor as the last one in the sequence\n    if tf and isinstance(tf, str):\n        processors.append(\n            ToFileProcessor(\n                tf=tf,\n                base_url=self.tf_base_path,\n                index=self.name,\n                max_files=1000,\n                skip_failed=tf_skip_failed,\n                tf_index_lock=None,\n            )\n        )\n\n    return nr.with_processors(processors)\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.render_jinja2_templates","title":"<code>render_jinja2_templates(templates, context, filters=None)</code>","text":"<p>Helper function to render a list of Jinja2 templates and combine them in a single string.</p> <p>Parameters:</p> Name Type Description Default <code>templates</code> <code>list[str]</code> <p>list of template strings to render</p> required <code>context</code> <code>dict</code> <p>Jinja2 context dictionary</p> required <code>filter</code> <p>custom Jinja2 filters</p> required <p>Returns:</p> Type Description <code>str</code> <p>list of rendered strings</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def render_jinja2_templates(\n    self, templates: list[str], context: dict, filters: dict = None\n) -&gt; str:\n    \"\"\"\n    Helper function to render a list of Jinja2 templates and\n    combine them in a single string.\n\n    :param templates: list of template strings to render\n    :param context: Jinja2 context dictionary\n    :param filter: custom Jinja2 filters\n    :returns: list of rendered strings\n    \"\"\"\n    rendered = []\n    filters = filters or {}\n    for template in templates:\n        if template.startswith(\"nf://\"):\n            filepath = self.fetch_jinja2(template)\n            searchpath, filename = os.path.split(filepath)\n            j2env = Environment(loader=FileSystemLoader(searchpath))\n            j2env.filters.update(filters)  # add custom filters\n            renderer = j2env.get_template(filename)\n        else:\n            j2env = Environment(loader=\"BaseLoader\")\n            j2env.filters.update(filters)  # add custom filters\n            renderer = j2env.from_string(template)\n        rendered.append(renderer.render(**context))\n\n    return \"\\n\".join(rendered)\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.load_job_data","title":"<code>load_job_data(job_data)</code>","text":"<p>Helper function to download job data and load it using YAML</p> <p>Parameters:</p> Name Type Description Default <code>job_data</code> <code>str</code> <p>URL to job data</p> required Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def load_job_data(self, job_data: str):\n    \"\"\"\n    Helper function to download job data and load it using YAML\n\n    :param job_data: URL to job data\n    \"\"\"\n    if self.is_url(job_data):\n        job_data = self.fetch_file(job_data)\n        if job_data is None:\n            msg = f\"{self.name} - '{job_data}' job data file download failed\"\n            raise FileNotFoundError(msg)\n        job_data = yaml.safe_load(job_data)\n\n    return job_data\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker._jinja2_network_hosts","title":"<code>_jinja2_network_hosts(network, pfxlen=False)</code>","text":"<p>Return a list of hosts for given network</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def _jinja2_network_hosts(self, network, pfxlen=False):\n    \"\"\"Return a list of hosts for given network\"\"\"\n    ret = []\n    ip_interface = ipaddress.ip_interface(network)\n    prefixlen = ip_interface.network.prefixlen\n    for ip in ip_interface.network.hosts():\n        ret.append(f\"{ip}/{prefixlen}\" if pfxlen else str(ip))\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.get_nornir_hosts","title":"<code>get_nornir_hosts(details=False, **kwargs)</code>","text":"<p>Produce a list of hosts managed by this worker</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>dictionary of nornir-salt Fx filters</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def get_nornir_hosts(self, details: bool = False, **kwargs: dict) -&gt; list:\n    \"\"\"\n    Produce a list of hosts managed by this worker\n\n    :param kwargs: dictionary of nornir-salt Fx filters\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    filtered_nornir = FFun(self.nr, **filters)\n    if details:\n        return Result(\n            result={\n                host_name: {\n                    \"platform\": str(host.platform),\n                    \"hostname\": str(host.hostname),\n                    \"port\": str(host.port),\n                    \"groups\": [str(g) for g in host.groups],\n                    \"username\": str(host.username),\n                }\n                for host_name, host in filtered_nornir.inventory.hosts.items()\n            }\n        )\n    else:\n        return Result(result=list(filtered_nornir.inventory.hosts))\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.get_inventory","title":"<code>get_inventory(**kwargs)</code>","text":"<p>Retrieve running Nornir inventory for requested hosts</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>dictionary of nornir-salt Fx filters</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def get_inventory(self, **kwargs: dict) -&gt; dict:\n    \"\"\"\n    Retrieve running Nornir inventory for requested hosts\n\n    :param kwargs: dictionary of nornir-salt Fx filters\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    filtered_nornir = FFun(self.nr, **filters)\n    return Result(result=filtered_nornir.inventory.dict(), task=\"get_inventory\")\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.get_version","title":"<code>get_version()</code>","text":"<p>Produce Python packages version report</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def get_version(self):\n    \"\"\"\n    Produce Python packages version report\n    \"\"\"\n    libs = {\n        \"norfab\": \"\",\n        \"scrapli\": \"\",\n        \"scrapli-netconf\": \"\",\n        \"scrapli-community\": \"\",\n        \"paramiko\": \"\",\n        \"netmiko\": \"\",\n        \"napalm\": \"\",\n        \"nornir\": \"\",\n        \"ncclient\": \"\",\n        \"nornir-netmiko\": \"\",\n        \"nornir-napalm\": \"\",\n        \"nornir-scrapli\": \"\",\n        \"nornir-utils\": \"\",\n        \"tabulate\": \"\",\n        \"xmltodict\": \"\",\n        \"puresnmp\": \"\",\n        \"pygnmi\": \"\",\n        \"pyyaml\": \"\",\n        \"jmespath\": \"\",\n        \"jinja2\": \"\",\n        \"ttp\": \"\",\n        \"nornir-salt\": \"\",\n        \"lxml\": \"\",\n        \"ttp-templates\": \"\",\n        \"ntc-templates\": \"\",\n        \"cerberus\": \"\",\n        \"pydantic\": \"\",\n        \"requests\": \"\",\n        \"textfsm\": \"\",\n        \"N2G\": \"\",\n        \"dnspython\": \"\",\n        \"pythonping\": \"\",\n        \"python\": sys.version.split(\" \")[0],\n        \"platform\": sys.platform,\n    }\n    # get version of packages installed\n    for pkg in libs.keys():\n        try:\n            libs[pkg] = importlib.metadata.version(pkg)\n        except importlib.metadata.PackageNotFoundError:\n            pass\n\n    return Result(result=libs)\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.task","title":"<code>task(plugin, **kwargs)</code>","text":"<p>Task to invoke any of supported Nornir task plugins. This function performs dynamic import of requested plugin function and executes <code>nr.run</code> using supplied args and kwargs</p> <p><code>plugin</code> attribute can refer to a file to fetch from file service. File must contain function named <code>task</code> accepting Nornir task object as a first positional argument, for example:</p> <pre><code># define connection name for RetryRunner to properly detect it\nCONNECTION_NAME = \"netmiko\"\n\n# create task function\ndef task(nornir_task_object, **kwargs):\n    pass\n</code></pre> <p>CONNECTION_NAME</p> <p><code>CONNECTION_NAME</code> must be defined within custom task function file if RetryRunner in use, otherwise connection retry logic skipped and connections to all hosts initiated simultaneously up to the number of <code>num_workers</code>.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>(str) <code>path.to.plugin.task_fun</code> to import or <code>nf://path/to/task.py</code> to download custom task</p> required <code>kwargs</code> <p>(dict) arguments to use with specified task plugin</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def task(self, plugin: str, **kwargs) -&gt; Result:\n    \"\"\"\n    Task to invoke any of supported Nornir task plugins. This function\n    performs dynamic import of requested plugin function and executes\n    ``nr.run`` using supplied args and kwargs\n\n    ``plugin`` attribute can refer to a file to fetch from file service. File must contain\n    function named ``task`` accepting Nornir task object as a first positional\n    argument, for example:\n\n    ```python\n    # define connection name for RetryRunner to properly detect it\n    CONNECTION_NAME = \"netmiko\"\n\n    # create task function\n    def task(nornir_task_object, **kwargs):\n        pass\n    ```\n\n    !!! note \"CONNECTION_NAME\"\n\n        ``CONNECTION_NAME`` must be defined within custom task function file if\n        RetryRunner in use, otherwise connection retry logic skipped and connections\n        to all hosts initiated simultaneously up to the number of ``num_workers``.\n\n    :param plugin: (str) ``path.to.plugin.task_fun`` to import or ``nf://path/to/task.py``\n        to download custom task\n    :param kwargs: (dict) arguments to use with specified task plugin\n    \"\"\"\n    # extract attributes\n    add_details = kwargs.pop(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.pop(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:task\", result={} if to_dict else [])\n\n    # download task from broker and load it\n    if plugin.startswith(\"nf://\"):\n        function_text = self.fetch_file(plugin)\n        if function_text is None:\n            raise FileNotFoundError(\n                f\"{self.name} - '{plugin}' task plugin download failed\"\n            )\n\n        # load task function running exec\n        globals_dict = {}\n        exec(function_text, globals_dict, globals_dict)\n        task_function = globals_dict[\"task\"]\n    # import task function\n    else:\n        # below same as \"from nornir.plugins.tasks import task_fun as task_function\"\n        task_fun = plugin.split(\".\")[-1]\n        module = __import__(plugin, fromlist=[\"\"])\n        task_function = getattr(module, task_fun)\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(f\"{self.name} - running Nornir task '{plugin}', kwargs '{kwargs}'\")\n    with self.connections_lock:\n        result = nr.run(task=task_function, **kwargs)\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.cli","title":"<code>cli(commands=None, plugin='netmiko', cli_dry_run=False, run_ttp=None, job_data=None, to_dict=True, add_details=False, **kwargs)</code>","text":"<p>Task to collect show commands output from devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>commands</code> <code>list</code> <p>list of commands to send to devices</p> <code>None</code> <code>plugin</code> <code>str</code> <p>plugin name to use - valid options are <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cli_dry_run</code> <code>bool</code> <p>do not send commands to devices just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>run_ttp</code> <code>str</code> <p>TTP Template to run</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cli(\n    self,\n    commands: list = None,\n    plugin: str = \"netmiko\",\n    cli_dry_run: bool = False,\n    run_ttp: str = None,\n    job_data: str = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to collect show commands output from devices using\n    Command Line Interface (CLI)\n\n    :param commands: list of commands to send to devices\n    :param plugin: plugin name to use - valid options are ``netmiko``, ``scrapli``, ``napalm``\n    :param cli_dry_run: do not send commands to devices just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param run_ttp: TTP Template to run\n    \"\"\"\n    job_data = job_data or {}\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:cli\", result={} if to_dict else [])\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_commands\n        if kwargs.get(\"use_ps\"):\n            kwargs.setdefault(\"timeout\", timeout)\n        else:\n            kwargs.setdefault(\"read_timeout\", timeout)\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_commands\n        kwargs.setdefault(\"timeout_ops\", timeout)\n    elif plugin == \"napalm\":\n        task_plugin = napalm_send_commands\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    # download TTP template\n    if self.is_url(run_ttp):\n        downloaded = self.fetch_file(run_ttp)\n        kwargs[\"run_ttp\"] = downloaded\n        if downloaded is None:\n            msg = f\"{self.name} - TTP template download failed '{run_ttp}'\"\n            raise FileNotFoundError(msg)\n    # use TTP template as is - inline template or ttp://xyz path\n    elif run_ttp:\n        kwargs[\"run_ttp\"] = run_ttp\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render commands using Jinja2 on a per-host basis\n    if commands:\n        commands = commands if isinstance(commands, list) else [commands]\n        for host in nr.inventory.hosts.values():\n            rendered = self.render_jinja2_templates(\n                templates=commands,\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n            host.data[\"__task__\"] = {\"commands\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - running cli commands '{commands}', kwargs '{kwargs}', is cli dry run - '{cli_dry_run}'\"\n    )\n    if cli_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"commands\", name=\"cli_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.nb_get_next_ip","title":"<code>nb_get_next_ip(*args, **kwargs)</code>","text":"<p>Task to query next available IP address from Netbox service</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def nb_get_next_ip(self, *args, **kwargs):\n    \"\"\"Task to query next available IP address from Netbox service\"\"\"\n    reply = self.client.run_job(\n        \"netbox\",\n        \"get_next_ip\",\n        args=args,\n        kwargs=kwargs,\n        workers=\"any\",\n        timeout=30,\n    )\n    # reply is a dict of {worker_name: results_dict}\n    result = list(reply.values())[0]\n\n    return result[\"result\"]\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.cfg","title":"<code>cfg(config, plugin='netmiko', cfg_dry_run=False, to_dict=True, add_details=False, job_data=None, **kwargs)</code>","text":"<p>Task to send configuration commands to devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>list</code> <p>list of commands to send to devices</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cfg_dry_run</code> <code>bool</code> <p>if True, will not send commands to devices but just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>kwargs</code> <p>additional arguments to pass to the task plugin</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the configuration task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cfg(\n    self,\n    config: list,\n    plugin: str = \"netmiko\",\n    cfg_dry_run: bool = False,\n    to_dict: bool = True,\n    add_details: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to send configuration commands to devices using\n    Command Line Interface (CLI)\n\n    :param config: list of commands to send to devices\n    :param plugin: plugin name to use - ``netmiko``, ``scrapli``, ``napalm``\n    :param cfg_dry_run: if True, will not send commands to devices but just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param kwargs: additional arguments to pass to the task plugin\n    :return: dictionary with the results of the configuration task\n    \"\"\"\n    downloaded_cfg = []\n    config = config if isinstance(config, list) else [config]\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:cfg\", result={} if to_dict else [])\n    timeout = self.current_job[\"timeout\"]\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_config\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_config\n    elif plugin == \"napalm\":\n        task_plugin = napalm_configure\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render config using Jinja2 on a per-host basis\n    for host in nr.inventory.hosts.values():\n        rendered = self.render_jinja2_templates(\n            templates=config,\n            context={\n                \"host\": host,\n                \"norfab\": self.client,\n                \"nornir\": self,\n                \"job_data\": job_data,\n            },\n            filters=self.add_jinja2_filters(),\n        )\n        host.data[\"__task__\"] = {\"config\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - sending config commands '{config}', kwargs '{kwargs}', is cfg_dry_run - '{cfg_dry_run}'\"\n    )\n    if cfg_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"config\", name=\"cfg_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n        ret.changed = True\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.test","title":"<code>test(suite, subset=None, dry_run=False, remove_tasks=True, failed_only=False, return_tests_suite=False, job_data=None, **kwargs)</code>","text":"<p>Function to tests data obtained from devices.</p> <p>Parameters:</p> Name Type Description Default <code>suite</code> <code>Union[list, str]</code> <p>path to YAML file with tests</p> required <code>dry_run</code> <code>bool</code> <p>if True, returns produced per-host tests suite content only</p> <code>False</code> <code>subset</code> <code>str</code> <p>list or string with comma separated non case sensitive glob patterns to filter tests' by name, subset argument ignored by dry run</p> <code>None</code> <code>failed_only</code> <code>bool</code> <p>if True returns test results for failed tests only</p> <code>False</code> <code>remove_tasks</code> <code>bool</code> <p>if False results will include other tasks output</p> <code>True</code> <code>return_tests_suite</code> <code>bool</code> <p>if True returns rendered per-host tests suite content in addition to test results using dictionary with <code>results</code> and <code>suite</code> keys</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>kwargs</code> <p>any additional arguments to pass on to Nornir service task</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def test(\n    self,\n    suite: Union[list, str],\n    subset: str = None,\n    dry_run: bool = False,\n    remove_tasks: bool = True,\n    failed_only: bool = False,\n    return_tests_suite: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to tests data obtained from devices.\n\n    :param suite: path to YAML file with tests\n    :param dry_run: if True, returns produced per-host tests suite content only\n    :param subset: list or string with comma separated non case sensitive glob\n        patterns to filter tests' by name, subset argument ignored by dry run\n    :param failed_only: if True returns test results for failed tests only\n    :param remove_tasks: if False results will include other tasks output\n    :param return_tests_suite: if True returns rendered per-host tests suite\n        content in addition to test results using dictionary with ``results``\n        and ``suite`` keys\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param kwargs: any additional arguments to pass on to Nornir service task\n    \"\"\"\n    tests = {}  # dictionary to hold per-host test suites\n    add_details = kwargs.get(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.get(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:test\", result={} if to_dict else [])\n    suites = {}  # dictionary to hold combined test suites\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        if return_tests_suite is True:\n            ret.result = {\"test_results\": [], \"suite\": {}}\n        return ret\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    # generate per-host test suites\n    for host_name, host in filtered_nornir.inventory.hosts.items():\n        # render suite using Jinja2\n        try:\n            rendered_suite = self.render_jinja2_templates(\n                templates=[suite],\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' Jinja2 rendering failed: '{e}'\"\n            raise RuntimeError(msg)\n        # load suit using YAML\n        try:\n            tests[host_name] = yaml.safe_load(rendered_suite)\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' YAML load failed: '{e}'\"\n            raise RuntimeError(msg)\n\n    # validate tests suite\n    try:\n        _ = modelTestsProcessorSuite(tests=tests)\n    except Exception as e:\n        msg = f\"{self.name} - '{suite}' suite validation failed: '{e}'\"\n        raise RuntimeError(msg)\n\n    # download pattern, schema and custom function files\n    for host_name in tests.keys():\n        for index, item in enumerate(tests[host_name]):\n            for k in [\"pattern\", \"schema\", \"function_file\"]:\n                if self.is_url(item.get(k)):\n                    item[k] = self.fetch_file(\n                        item[k], raise_on_fail=True, read=True\n                    )\n                    if k == \"function_file\":\n                        item[\"function_text\"] = item.pop(k)\n            tests[host_name][index] = item\n\n    # save per-host tests suite content before mutating it\n    if return_tests_suite is True:\n        return_suite = copy.deepcopy(tests)\n\n    log.debug(f\"{self.name} - running test '{suite}', is dry run - '{dry_run}'\")\n    # run dry run task\n    if dry_run is True:\n        result = filtered_nornir.run(\n            task=nr_test, name=\"tests_dry_run\", ret_data_per_host=tests\n        )\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    # combine per-host tests in suites based on task and arguments\n    # Why - to run tests using any nornir service tasks with various arguments\n    else:\n        for host_name, host_tests in tests.items():\n            for test in host_tests:\n                dhash = hashlib.md5()\n                test_args = test.pop(\"norfab\", {})\n                nrtask = test_args.get(\"nrtask\", \"cli\")\n                assert nrtask in [\n                    \"cli\",\n                    \"network\",\n                    \"cfg\",\n                    \"task\",\n                ], f\"{self.name} - unsupported NorFab Nornir Service task '{nrtask}'\"\n                test_json = json.dumps(test_args, sort_keys=True).encode()\n                dhash.update(test_json)\n                test_hash = dhash.hexdigest()\n                suites.setdefault(test_hash, {\"params\": test_args, \"tests\": {}})\n                suites[test_hash][\"tests\"].setdefault(host_name, [])\n                suites[test_hash][\"tests\"][host_name].append(test)\n        log.debug(\n            f\"{self.name} - combined per-host tests suites based on NorFab Nornir Service task and arguments:\\n{suites}\"\n        )\n        # run test suites collecting output from devices\n        for tests_suite in suites.values():\n            nrtask = tests_suite[\"params\"].pop(\"nrtask\", \"cli\")\n            function_kwargs = {\n                **tests_suite[\"params\"],\n                **kwargs,\n                **filters,\n                \"tests\": tests_suite[\"tests\"],\n                \"remove_tasks\": remove_tasks,\n                \"failed_only\": failed_only,\n                \"subset\": subset,\n            }\n            result = getattr(self, nrtask)(\n                **function_kwargs\n            )  # returns Result object\n            # save test results into overall results\n            if to_dict == True:\n                for host_name, host_res in result.result.items():\n                    ret.result.setdefault(host_name, {})\n                    ret.result[host_name].update(host_res)\n            else:\n                ret.result.extend(result.result)\n\n    # check if need to return tests suite content\n    if return_tests_suite is True:\n        ret.result = {\"test_results\": ret.result, \"suite\": return_suite}\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.network","title":"<code>network(fun, **kwargs)</code>","text":"<p>Task to call various network related utility functions.</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <p>(str) utility function name to call</p> required <code>kwargs</code> <p>(dict) function arguments  Available utility functions.  resolve_dns function  resolves hosts' hostname DNS returning IP addresses using <code>nornir_salt.plugins.tasks.network.resolve_dns</code> Nornir-Salt function.  ping function  Function to execute ICMP ping to host using <code>nornir_salt.plugins.tasks.network.ping</code> Nornir-Salt function.</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def network(self, fun, **kwargs) -&gt; dict:\n    \"\"\"\n    Task to call various network related utility functions.\n\n    :param fun: (str) utility function name to call\n    :param kwargs: (dict) function arguments\n\n    Available utility functions.\n\n    **resolve_dns** function\n\n    resolves hosts' hostname DNS returning IP addresses using\n    ``nornir_salt.plugins.tasks.network.resolve_dns`` Nornir-Salt\n    function.\n\n    **ping** function\n\n    Function to execute ICMP ping to host using\n    ``nornir_salt.plugins.tasks.network.ping`` Nornir-Salt\n    function.\n    \"\"\"\n    kwargs[\"call\"] = fun\n    return self.task(\n        plugin=\"nornir_salt.plugins.tasks.network\",\n        **kwargs,\n    )\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.parse","title":"<code>parse(plugin='napalm', getters='get_facts', template=None, commands=None, to_dict=True, add_details=False, **kwargs)</code>","text":"<p>Function to parse network devices show commands output</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>plugin name to use - <code>napalm</code>, <code>textfsm</code>, <code>ttp</code></p> <code>'napalm'</code> <code>getters</code> <code>str</code> <p>NAPALM getters to use</p> <code>'get_facts'</code> <code>commands</code> <code>list</code> <p>commands to send to devices for TextFSM or TTP template</p> <code>None</code> <code>template</code> <code>str</code> <p>TextFSM or TTP parsing template string or path to file  For NAPALM plugin <code>method</code> can refer to a list of getters names.</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def parse(\n    self,\n    plugin: str = \"napalm\",\n    getters: str = \"get_facts\",\n    template: str = None,\n    commands: list = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Function to parse network devices show commands output\n\n    :param plugin: plugin name to use - ``napalm``, ``textfsm``, ``ttp``\n    :param getters: NAPALM getters to use\n    :param commands: commands to send to devices for TextFSM or TTP template\n    :param template: TextFSM or TTP parsing template string or path to file\n\n    For NAPALM plugin ``method`` can refer to a list of getters names.\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:parse\", result={} if to_dict else [])\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    if plugin == \"napalm\":\n        nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n        result = nr.run(task=napalm_get, getters=getters, **kwargs)\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    elif plugin == \"ttp\":\n        result = self.cli(\n            commands=commands or [],\n            run_ttp=template,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    elif plugin == \"textfsm\":\n        result = self.cli(\n            commands=commands,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            use_textfsm=True,\n            textfsm_template=template,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.file_copy","title":"<code>file_copy(source_file, plugin='netmiko', to_dict=True, add_details=False, dry_run=False, **kwargs)</code>","text":"<p>Task to transfer files to and from hosts using SCP</p> <p>Parameters:</p> Name Type Description Default <code>source_file</code> <code>str</code> <p>path to file to copy, support <code>nf://path/to/file</code> URL to copy from broker</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code></p> <code>'netmiko'</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False produces list</p> <code>True</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>if True will not copy files just return what would be copied</p> <code>False</code> <code>kwargs</code> <p>additional arguments to pass to the plugin function</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the file copy task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def file_copy(\n    self,\n    source_file: str,\n    plugin: str = \"netmiko\",\n    to_dict: bool = True,\n    add_details: bool = False,\n    dry_run: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to transfer files to and from hosts using SCP\n\n    :param source_file: path to file to copy, support ``nf://path/to/file`` URL to copy from broker\n    :param plugin: plugin name to use - ``netmiko``\n    :param to_dict: default is True - produces dictionary results, if False produces list\n    :param add_details: if True will add task execution details to the results\n    :param dry_run: if True will not copy files just return what would be copied\n    :param kwargs: additional arguments to pass to the plugin function\n    :return: dictionary with the results of the file copy task\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:file_copy\", result={} if to_dict else [])\n\n    # download file from broker\n    if self.is_url(source_file):\n        source_file_local = self.fetch_file(\n            source_file, raise_on_fail=True, read=False\n        )\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_file_transfer\n        kwargs[\"source_file\"] = source_file_local\n        kwargs.setdefault(\"socket_timeout\", timeout / 5)\n        kwargs.setdefault(\"dest_file\", os.path.split(source_file_local)[-1])\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(\n        f\"{self.name} - running file copy with arguments '{kwargs}', is dry run - '{dry_run}'\"\n    )\n    if dry_run is True:\n        result = nr.run(task=nr_test, name=\"file_copy_dry_run\", **kwargs)\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>"},{"location":"workers/nornir/api_reference_workers_nornir_worker/#norfab.workers.nornir_worker.NornirWorker.runtime_inventory","title":"<code>runtime_inventory(action, **kwargs)</code>","text":"<p>Method to work with Nornir inventory in a runtime.</p> <p>Supported actions:</p> <ul> <li><code>create_host</code> or <code>create</code> - creates new host or replaces existing host object</li> <li><code>read_host</code> or <code>read</code> - read host inventory content</li> <li><code>update_host</code> or <code>update</code> - non recursively update host attributes if host exists     in Nornir inventory, do not create host if it does not exist</li> <li><code>delete_host</code> or <code>delete</code> - deletes host object from Nornir Inventory</li> <li><code>load</code> - to simplify calling multiple functions</li> <li><code>read_inventory</code> - read inventory content for groups, default and hosts</li> <li><code>read_host_data</code> - to return host's data under provided path keys</li> <li><code>list_hosts</code> - return a list of inventory's host names</li> <li><code>list_hosts_platforms</code> - return a dictionary of hosts' platforms</li> <li><code>update_defaults</code> - non recursively update defaults attributes</li> </ul> <p>Parameters:</p> Name Type Description Default <code>action</code> <p>action to perform on inventory</p> required <code>kwargs</code> <p>argument to use with the calling action</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def runtime_inventory(self, action, **kwargs) -&gt; dict:\n    \"\"\"\n    Method to work with Nornir inventory in a runtime.\n\n    Supported actions:\n\n    - `create_host` or `create` - creates new host or replaces existing host object\n    - `read_host` or `read` - read host inventory content\n    - `update_host` or `update` - non recursively update host attributes if host exists\n        in Nornir inventory, do not create host if it does not exist\n    - `delete_host` or `delete` - deletes host object from Nornir Inventory\n    - `load` - to simplify calling multiple functions\n    - `read_inventory` - read inventory content for groups, default and hosts\n    - `read_host_data` - to return host's data under provided path keys\n    - `list_hosts` - return a list of inventory's host names\n    - `list_hosts_platforms` - return a dictionary of hosts' platforms\n    - `update_defaults` - non recursively update defaults attributes\n\n    :param action: action to perform on inventory\n    :param kwargs: argument to use with the calling action\n    \"\"\"\n    # clean up kwargs\n    _ = kwargs.pop(\"progress\", None)\n    self.event(f\"Performing '{action}' action\")\n    return Result(result=InventoryFun(self.nr, call=action, **kwargs))\n</code></pre>"},{"location":"workers/nornir/services_nornir_service/","title":"Nornir Service","text":"<p>Nornir Service is based on Nornir library - a well adopted open-source tool for automating network devices operations.</p> <p> </p> <p>With each Nornir worker capable of handling multiple devices simultaneously,  Nornir Service offers high scalability, allowing efficient management of  large device fleets. By optimizing compute resources such as CPU, RAM, and  storage, it delivers cost-effective performance.</p> <p>Additionally, Nornir Service supports various interfaces and libraries for  seamless integration. For instance, the <code>cli</code> task can interact with devices  via the SSH Command Line Interface (CLI) using popular libraries like Netmiko,  Scrapli or NAPALM, providing flexibility for diverse network environments.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service/#nornir-service-tasks","title":"Nornir Service Tasks","text":"<p>Nornir Service supports a number of tasks to interact with network devices using  some of the most popular open source libraries such as Netmiko, NAPALM, Scrapli,  Ncclient, Scrapli NETCONF, pygnmi, puresnmp, TextFSM, TTP etc.</p> Task Description Use Cases task Run Nornir custom tasks Pure Python per device workflows, do anything you want, it is pure python cli Executes CLI commands on network devices using libraries like Netmiko, Scrapli or NAPALM. Device diagnostics, retrieving device information. cfg Manages device configurations, including pushing configurations. Automated configuration management. test Run test suites against network devices. Network testing, troubleshooting, device compliance, configuration verification. network A collection of network utilities such as ping and DNS. Check device connectivity, verify and resolve DNS records. parse Parses command outputs using TextFSM, NAPALM getters or TTP to extract structured data. Data extraction from CLI outputs, automated report generation, configuration validation. diagram Produce Network L2,  L3, OSPF or ISIS routing diagrams in DrawIO or yED formats. Automated network documentation, network validation. file_copy COpy files to network devices over SCP. Device software upgrades, certificates or license renewal.","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_inventory/","title":"Nornir Worker Inventory","text":"<p>Sample Nornir worker inventory definition</p> <pre><code>service: nornir\nbroker_endpoint: \"tcp://127.0.0.1:5555\"\nwatchdog_interval: 30\nconnections_idle_timeout: null\n\n# these parameters mapped to Nornir inventory\n# https://nornir.readthedocs.io/en/latest/tutorial/inventory.html\nrunner:\n  plugin: RetryRunner\n  options: \n    num_workers: 100\n    num_connectors: 10\n    connect_retry: 1\n    connect_backoff: 1000\n    connect_splay: 100\n    task_retry: 1\n    task_backoff: 1000\n    task_splay: 100\n    reconnect_on_fail: True\n    task_timeout: 600\nhosts: {}\ngroups: {}\ndefaults: {}\nlogging: {}\nuser_defined: {}\n</code></pre> <p>watchdog_interval</p> <p>Watchdog run interval in seconds, default is 30</p> <p>connections_idle_timeout</p> <p>Watchdog connection idle timeout, default is <code>None</code> - no timeout, connection always kept alive, if set to 0, connections disconnected imminently after task completed, if positive number, connection disconnected after not being used for over <code>connections_idle_timeout</code></p>"},{"location":"workers/nornir/services_nornir_service_inventory/#netbox-inventory-integration","title":"Netbox Inventory Integration","text":"<p>NorFab Nornir Worker supports tight integration with Netbox to fetch devices data such as device interfaces, ip addresses, circuits, configuration context. Netbox 3.7.x and 4.x.x supported. </p> <p>Sample Nornir Worker inventory parameters to fetch devices data from Netbox</p> <pre><code>netbox:\n  retry: 3\n  retry_interval: 1\n  instance: prod\n  interfaces:\n    ip_addresses: True\n    inventory_items: True\n  connections:\n    cables: True\n  nbdata: True\n  circuits: True\n  primary_ip: \"ipv4\"\n  devices:\n    - fceos4\n    - fceos5\n    - fceos8\n    - ceos1\n  filters: \n    - q: fceos3\n    - manufacturer: cisco\n      platform: cisco_xr\n</code></pre> <p>filters</p> <p>List for Netbox GraphQL filters to pull devices data. Up to 10 filters supported.</p> <p>devices</p> <p>List of exact device names to retrieve data for from Netbox, those names used as hosts' names in Nornir inventory.</p> <p>retry</p> <p>Specifies the number of Netbox data retrieval retry attempts for network operations. This parameter is useful for ensuring that transient network issues do not cause the operation to fail. </p> <p>retry_interval</p> <p>Defines the interval (in seconds) between retry attempts. This parameter works in conjunction with the <code>retry</code> parameter to control the timing of retry attempts. </p> <p>instance</p> <p>Specifies the name of the NetBox instance to be used. This parameter is useful for environments with multiple NetBox instances, allowing to target a specific instance to fetch devices data.</p> <p>interfaces</p> <p>Indicates whether to include interface data in the results.</p> <p>Extras:</p> <ul> <li>ip_addresses: When set to <code>True</code>, includes IP address information associated with the interfaces in Netbox. </li> <li>inventory_items: When set to <code>True</code>, includes inventory items associated with the interfaces in Netbox. </li> </ul> <p>connections</p> <p>Specifies whether to include connection data in the results. </p> <p>Extras:</p> <ul> <li>cables: When set to <code>True</code>, includes cable information associated with the interface connections. </li> </ul> <p>nbdata</p> <p>Specifies whether to merge NetBox devices data into Nornir hosts' <code>data</code>. This is useful when need to make Netbox device <code>config_context</code> available in Nornir hosts' <code>data</code> together with other device information such as Netbox <code>site</code>, <code>tags</code>, <code>role</code> etc.</p> <p>circuits</p> <p>Indicates whether to fetch circuit data from Netbox.</p> <p>primary_ip</p> <p>Specifies what Netbox device IP address to use for Nornir host's <code>hostname</code> parameter, supported values are <code>ipv4</code>, <code>ip4</code>, <code>ipv6</code> or <code>ip6</code>, uses Netbox device name instead if no primary IP address mapped to the device in Netbox.</p>"},{"location":"workers/nornir/services_nornir_service_jinja2_filters/","title":"Nornir Service Jinja2 Templates Filters","text":"<p>Below listed additional Jinja2 filters that supported by Nornir service for templates rendering by all service tasks such as <code>cfg</code>, <code>cli</code>, <code>tests</code> etc.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_jinja2_filters/#network_hosts","title":"network_hosts","text":"<p>Returns a list of hosts for given network.</p> <p>Arguments:</p> <ul> <li><code>pfxlen</code> - boolean, default is True, if False skips prefix length for IP addresses </li> </ul> <p>Example:</p> <pre><code>{{ '192.168.1.0/30' | network_hosts }}\n\n{{ '192.168.2.0/30' | network_hosts(pfxlen=False) }}\n</code></pre> <p>Returns:</p> <pre><code>[\"192.168.1.1/30\", \"192.168.1.2/30\"]\n\n[\"192.168.2.1\", \"192.168.2.2\"]\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/","title":"Nornir Service CFG Task","text":"<p>task api name: <code>cfg</code></p> <p>Nornir service <code>cfg</code> task designed to send configuration to devices using SSH and Telnet. Nornir <code>cfg</code> can use Netmiko, Scrapli and NAPALM libraries to configure devices.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#nornir-cfg-sample-usage","title":"Nornir CFG Sample Usage","text":"<p>Example of sending configuration commands to devices.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>Above sends configuration commands to all Nornir hosts that contain <code>spine</code> or <code>leaf</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter.</p> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"cfg\",\n        kwargs={\n            \"config\": [\"ntp server 10.0.0.1\", \"ntp server 10.0.0.2\"],\n            \"FC\": \"spine,leaf\"              \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#use-different-configuration-plugins","title":"Use Different Configuration Plugins","text":"<p>NorFab supports various configuration plugins such as <code>netmiko</code>, <code>napalm</code> and <code>scrapli</code>. These plugins enable you to push configurations to a wide range of network devices. Each plugin has its own set of capabilities and requirements, so it is essential to ensure that your Nornir inventory is properly configured for the chosen plugin. This includes specifying the necessary connection parameters and device-specific settings. By leveraging these plugins, you can standardize and automate the configuration management process across different network environments.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-dry-run","title":"Using Dry Run","text":"<p>The dry run feature in NorFab allows you to simulate the application of configurations without actually pushing them to the devices. This is particularly useful for testing and validation purposes, as it enables you to verify the correctness of your configurations before making any changes to the network. Additionally, the dry run feature can be used for generating and rendering device configurations, which is beneficial for staging environments where you need to prepare configurations in advance. By using dry run, you can ensure that your configurations are accurate and ready for deployment.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-commit-confirmed","title":"Using Commit Confirmed","text":"<p>The commit confirmed feature provides an added layer of safety when pushing configurations to network devices. With this feature, you can apply a configuration with a rollback timer. If the configuration is not explicitly confirmed within the specified time, it will be automatically rolled back to the previous state. This is particularly useful in scenarios where you need to ensure that a configuration change does not negatively impact the network. By using commit confirmed, you can mitigate the risk of configuration errors and ensure network stability.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#sourcing-configuration-from-files","title":"Sourcing Configuration From Files","text":"<p>NorFab allows you to source configurations from text files stored on the broker. This approach enables you to manage configurations as files, making it easier to version control and maintain them. By storing configurations in files, you can apply them as needed, ensuring consistency and repeatability in your configuration management process. This method is particularly useful for large-scale deployments where configurations need to be applied to multiple devices in a controlled and organized manner.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-jinja2-templates","title":"Using Jinja2 Templates","text":"<p>Jinja2 templates provide a powerful way to create dynamic configurations based on variables defined in your inventory or passed as job data. By using templates, you can generate configurations that are tailored to the specific requirements of each device. This approach allows you to automate the creation of complex configurations and ensures consistency across your network. Jinja2 templates are highly flexible and can be used to incorporate conditional logic, loops, and other advanced features, making them an essential tool for network automation.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#templating-configuration-with-inline-job-data","title":"Templating Configuration with Inline Job Data","text":"","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#parsing-and-generating-configuration-in-templates","title":"Parsing and Generating Configuration in Templates","text":"<p>NorFab supports parsing of device output and the generation of new configurations within same template using parsing results. This capability allows you to create configurations based on the current state of the device, ensuring that your changes are applied accurately and efficiently. By parsing existing configurations, you can extract relevant information and use it to generate new configurations that are consistent with the device's current setup. </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#outputting-text-tables","title":"Outputting Text Tables","text":"<p>The NorFab interactive shell supports the table command, which can be used to format output into text tables. This feature relies on the tabulate module and supports most of its functionalities. By outputting results in table format, you can easily visualize and analyze the data, making it easier to interpret and act upon. This is particularly useful for displaying configuration results in a structured, concise and readable manner.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#formatting-output-results","title":"Formatting Output Results","text":"<p>You can format the output results using various options provided by the Nornir worker. The output of the commands can be formatted using the <code>to_dict</code> parameter. When set to <code>True</code>, the results will be returned as a dictionary. When set to <code>False</code>, the results will be returned as a list. In addition <code>add_details</code> argument can be used to control the verbosity of the output and return additional Nornir result information such as:</p> <ul> <li><code>changed</code> flag</li> <li><code>diff</code> content if supported by plugin</li> <li><code>failed</code> status</li> <li><code>exception</code> details if task execution failed with error</li> <li><code>connection_retry</code> counter to show how many times RetryRunner tried to establish a connection</li> <li><code>task_retry</code> counter to show how many times RetryRunner tried to run this task</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#using-promptless-mode","title":"Using Promptless Mode","text":"<p>NorFab supports a proprietary promptless mode that can be used with Netmiko. This mode is particularly useful when dealing with devices that do not have a consistent prompt or when the default Netmiko output collection functions are not reliable enough. By enabling promptless mode, you can ensure that configurations are applied accurately and efficiently, even in challenging environments. This feature enhances the robustness of your configuration management process and ensures that your network devices are configured correctly.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#norfab-nornir-cfg-shell-reference","title":"NORFAB Nornir CFG Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>cfg</code> task:</p> <pre><code>nf#man tree nornir.cfg\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 cfg:    Configure devices over CLI interface\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results, default 'False'\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 cfg_dry_run:    Dry run cfg function\n        \u251c\u2500\u2500 *config:    List of configuration commands to send to devices\n        \u251c\u2500\u2500 plugin:    Configuration plugin parameters\n        \u2502   \u251c\u2500\u2500 netmiko:    Use Netmiko plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 enable:    Attempt to enter enable-mode\n        \u2502   \u2502   \u251c\u2500\u2500 exit_config_mode:    Determines whether or not to exit config mode after complete\n        \u2502   \u2502   \u251c\u2500\u2500 strip_prompt:    Determines whether or not to strip the prompt\n        \u2502   \u2502   \u251c\u2500\u2500 strip_command:    Determines whether or not to strip the command\n        \u2502   \u2502   \u251c\u2500\u2500 read_timeout:    Absolute timer to send to read_channel_timing\n        \u2502   \u2502   \u251c\u2500\u2500 config_mode_command:    The command to enter into config mode\n        \u2502   \u2502   \u251c\u2500\u2500 enter_config_mode:    Do you enter config mode before sending config commands\n        \u2502   \u2502   \u251c\u2500\u2500 error_pattern:    Regular expression pattern to detect config errors in the output\n        \u2502   \u2502   \u251c\u2500\u2500 terminator:    Regular expression pattern to use as an alternate terminator\n        \u2502   \u2502   \u251c\u2500\u2500 bypass_commands:    Regular expression pattern indicating configuration commands, cmd_verify is automatically disabled\n        \u2502   \u2502   \u251c\u2500\u2500 commit:    Commit configuration, default 'True'\n        \u2502   \u2502   \u251c\u2500\u2500 commit-confirm:    Perform commit confirm on supported platforms\n        \u2502   \u2502   \u251c\u2500\u2500 commit-confirm-delay:    Confirmed commit rollback timeout in minutes, used with commit-confirm\n        \u2502   \u2502   \u251c\u2500\u2500 commit-final-delay:    Time to wait in seconds before doing final commit, used with commit-confirm\n        \u2502   \u2502   \u251c\u2500\u2500 commit-comment:    Commit operation comment\n        \u2502   \u2502   \u2514\u2500\u2500 batch:    Commands count to send in batches\n        \u2502   \u251c\u2500\u2500 scrapli:    Use Scrapli plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 dry_run:    Apply changes or not, also tests if possible to enter config mode\n        \u2502   \u2502   \u251c\u2500\u2500 strip_prompt:    Strip prompt from returned output\n        \u2502   \u2502   \u251c\u2500\u2500 failed_when_contains:    String or list of strings indicating failure if found in response\n        \u2502   \u2502   \u251c\u2500\u2500 stop_on_failed:    Stop executing commands if command fails\n        \u2502   \u2502   \u251c\u2500\u2500 privilege_level:    Name of configuration privilege level to acquire\n        \u2502   \u2502   \u251c\u2500\u2500 eager:    Do not read until prompt is seen at each command sent to the channel\n        \u2502   \u2502   \u2514\u2500\u2500 timeout_ops:    Timeout ops value for this operation\n        \u2502   \u2514\u2500\u2500 napalm:    Use NAPALM plugin to configure devices\n        \u2502       \u251c\u2500\u2500 replace:    Whether to replace or merge the configuration\n        \u2502       \u251c\u2500\u2500 dry_run:    Apply changes or not, also tests if possible to enter config mode\n        \u2502       \u2514\u2500\u2500 revert_in:    Amount of time in seconds after which to revert the commit\n        \u2514\u2500\u2500 job_data:    Path to YAML file with job data\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cfg/#python-api-reference","title":"Python API Reference","text":"<p>Task to send configuration commands to devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>list</code> <p>list of commands to send to devices</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cfg_dry_run</code> <code>bool</code> <p>if True, will not send commands to devices but just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>kwargs</code> <p>additional arguments to pass to the task plugin</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the configuration task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cfg(\n    self,\n    config: list,\n    plugin: str = \"netmiko\",\n    cfg_dry_run: bool = False,\n    to_dict: bool = True,\n    add_details: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to send configuration commands to devices using\n    Command Line Interface (CLI)\n\n    :param config: list of commands to send to devices\n    :param plugin: plugin name to use - ``netmiko``, ``scrapli``, ``napalm``\n    :param cfg_dry_run: if True, will not send commands to devices but just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param kwargs: additional arguments to pass to the task plugin\n    :return: dictionary with the results of the configuration task\n    \"\"\"\n    downloaded_cfg = []\n    config = config if isinstance(config, list) else [config]\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:cfg\", result={} if to_dict else [])\n    timeout = self.current_job[\"timeout\"]\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_config\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_config\n    elif plugin == \"napalm\":\n        task_plugin = napalm_configure\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render config using Jinja2 on a per-host basis\n    for host in nr.inventory.hosts.values():\n        rendered = self.render_jinja2_templates(\n            templates=config,\n            context={\n                \"host\": host,\n                \"norfab\": self.client,\n                \"nornir\": self,\n                \"job_data\": job_data,\n            },\n            filters=self.add_jinja2_filters(),\n        )\n        host.data[\"__task__\"] = {\"config\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - sending config commands '{config}', kwargs '{kwargs}', is cfg_dry_run - '{cfg_dry_run}'\"\n    )\n    if cfg_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"config\", name=\"cfg_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n        ret.changed = True\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/","title":"Nornir Service CLI Task","text":"<p>task api name: <code>cli</code></p> <p>Nornir service <code>cli</code> task designed to retrieve show commands output  from devices using SSH and Telnet. Nornir <code>cli</code> uses Netmiko, Scrapli  and NAPALM libraries to communicate with devices.</p> <ul> <li>Netmiko: A multi-vendor library that simplifies SSH connections to network devices.</li> <li>Scrapli: A fast and flexible library for interacting with network devices.</li> <li>NAPALM: A library that provides a unified API to interact with different network device operating systems.</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#nornir-cli-sample-usage","title":"Nornir CLI Sample Usage","text":"<p>Below is an example of how to use the Nornir CLI task to retrieve command outputs from devices.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir]#cli\nnf[nornir-cli]#\nnf[nornir-cli]#commands \"show clock\" \"show hostname\" FC ceos-spine\nceos-spine-1:\n    show clock:\n        Sun Dec  1 10:49:58 2024\n        Timezone: UTC\n        Clock source: local\n    show hostname:\n        Hostname: ceos-spine-1\n        FQDN:     ceos-spine-1\nceos-spine-2:\n    show clock:\n        Sun Dec  1 10:49:58 2024\n        Timezone: UTC\n        Clock source: local\n    show hostname:\n        Hostname: ceos-spine-2\n        FQDN:     ceos-spine-2\nnf[nornir-cli]#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nfcli</code> command starts the NorFab Interactive Shell.</li> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>cli</code> command switches to the CLI task sub-shell.</li> <li><code>commands</code> command retrieves the output of \"show clock\" and \"show hostname\" from the devices  that contain <code>ceos-spine</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter.</li> </ul> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"cli\",\n        kwargs={\n            \"commands\": [\"show clock\", \"show hostname\"],\n            \"FC\": \"ceos-spine\"              \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_cli.py\n{'nornir-worker-1': {'errors': [],\n                     'failed': False,\n                     'messages': [],\n                     'result': {'ceos-spine-1': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local',\n                                                 'show hostname': 'Hostname: '\n                                                                  'ceos-spine-1\\n'\n                                                                  'FQDN:     '\n                                                                  'ceos-spine-1'},\n                                'ceos-spine-2': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local',\n                                                 'show hostname': 'Hostname: '\n                                                                  'ceos-spine-2\\n'\n                                                                  'FQDN:     '\n                                                                  'ceos-spine-2'}},\n                     'task': 'nornir-worker-1:cli'}}\nC:\\nf&gt;                   \n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#use-different-connection-plugins","title":"Use Different Connection Plugins","text":"<p>The Nornir Service CLI Task supports various connection plugins, such as <code>netmiko</code>, <code>napalm</code>, and <code>scrapli</code>, to interact with network devices. These plugins provide the flexibility to choose the most suitable method for connecting to and managing your devices, depending on your specific requirements and preferences.</p> <p>To use a specific connection plugin, ensure that your Nornir inventory is properly configured with the necessary connection parameters and device-specific settings. This includes specifying the plugin type, authentication details, and any additional options required by the plugin.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir cli\nnf[nornir-cli]#commands \"show clock\" FC spine plugin netmiko\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:37:57 5ed5775b183a404181f004753f583f0c job started\n04-Jan-2025 22:37:57.085 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.114 nornir nornir-worker-1 ceos-spine-1 task_instance started - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.114 nornir nornir-worker-1 ceos-spine-2 task_instance started - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.124 nornir nornir-worker-1 ceos-spine-1 subtask started - 'show clock'\n04-Jan-2025 22:37:57.136 nornir nornir-worker-1 ceos-spine-2 subtask started - 'show clock'\n04-Jan-2025 22:37:57.237 nornir nornir-worker-1 ceos-spine-1 subtask completed - 'show clock'\n04-Jan-2025 22:37:57.237 nornir nornir-worker-1 ceos-spine-2 subtask completed - 'show clock'\n04-Jan-2025 22:37:57.244 nornir nornir-worker-1 ceos-spine-2 task_instance completed - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.245 nornir nornir-worker-1 ceos-spine-1 task_instance completed - 'netmiko_send_commands'\n04-Jan-2025 22:37:57.425 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task completed - 'netmiko_send_commands'\n04-Jan-2025 22:37:57 5ed5775b183a404181f004753f583f0c job completed in 0.476 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\nceos-spine-1:\n    show clock:\n        Sat Jan  4 12:37:57 2025\n        Timezone: UTC\n        Clock source: local\nceos-spine-2:\n    show clock:\n        Sat Jan  4 12:37:57 2025\n        Timezone: UTC\n        Clock source: local\nnf[nornir-cli]#commands \"show clock\" FC spine plugin scrapli\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:38:01 c6bd014aac4c42249594a6197175012e job started\n04-Jan-2025 22:38:01.116 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.119 nornir nornir-worker-1 ceos-spine-2 task_instance started - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.128 nornir nornir-worker-1 ceos-spine-2 subtask started - 'show clock'\n04-Jan-2025 22:38:01.141 nornir nornir-worker-1 ceos-spine-2 subtask completed - 'show clock'\n04-Jan-2025 22:38:01.148 nornir nornir-worker-1 ceos-spine-2 task_instance completed - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.192 nornir nornir-worker-1 ceos-spine-1 task_instance started - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.202 nornir nornir-worker-1 ceos-spine-1 subtask started - 'show clock'\n04-Jan-2025 22:38:01.215 nornir nornir-worker-1 ceos-spine-1 subtask completed - 'show clock'\n04-Jan-2025 22:38:01.221 nornir nornir-worker-1 ceos-spine-1 task_instance completed - 'scrapli_send_commands'\n04-Jan-2025 22:38:01.364 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task completed - 'scrapli_send_commands'\n04-Jan-2025 22:38:01 c6bd014aac4c42249594a6197175012e job completed in 0.497 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\nceos-spine-1:\n    show clock:\n        Sat Jan  4 12:38:01 2025\n        Sat Jan  4 12:38:01 2025\n        Timezone: UTC\n        Clock source: local\nceos-spine-2:\n    show clock:\n        Sat Jan  4 12:38:01 2025\n        Timezone: UTC\n        Clock source: local\nnf[nornir-cli]#commands \"show clock\" FC spine plugin napalm\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:43:41 02eed090a7bb4652b27cccec1a49dab6 job started\n04-Jan-2025 22:43:41.360 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'napalm_send_commands'\n04-Jan-2025 22:43:41.382 nornir nornir-worker-1 ceos-spine-2 task_instance started - 'napalm_send_commands'\n04-Jan-2025 22:43:41.382 nornir nornir-worker-1 ceos-spine-1 task_instance started - 'napalm_send_commands'\n04-Jan-2025 22:43:41.388 nornir nornir-worker-1 ceos-spine-1 subtask started - 'napalm_cli'\n04-Jan-2025 22:43:41.389 nornir nornir-worker-1 ceos-spine-2 subtask started - 'napalm_cli'\n04-Jan-2025 22:43:41.419 nornir nornir-worker-1 ceos-spine-1 subtask completed - 'napalm_cli'\n04-Jan-2025 22:43:41.424 nornir nornir-worker-1 ceos-spine-2 subtask completed - 'napalm_cli'\n04-Jan-2025 22:43:41.425 nornir nornir-worker-1 ceos-spine-1 task_instance completed - 'napalm_send_commands'\n04-Jan-2025 22:43:41.432 nornir nornir-worker-1 ceos-spine-2 task_instance completed - 'napalm_send_commands'\n04-Jan-2025 22:43:41.599 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task completed - 'napalm_send_commands'\n04-Jan-2025 22:43:41 02eed090a7bb4652b27cccec1a49dab6 job completed in 0.576 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\nceos-spine-1:\n    show clock:\n        Sat Jan  4 12:43:41 2025\n        Timezone: UTC\n        Clock source: local\nceos-spine-2:\n    show clock:\n        Sat Jan  4 12:43:41 2025\n        Timezone: UTC\n        Clock source: local\nnf[nornir-cli]#\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nfcli</code> command starts the NorFab Interactive Shell.</li> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>cli</code> command switches to the CLI task sub-shell.</li> <li><code>commands</code> command retrieves the output of \"show clock\" from the devices  that contain <code>spine</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter, <code>plugin</code> argument used to inform Nornir service to use <code>netmiko</code>, <code>scrapli</code> or <code>napalm</code> modules to retrieve command output from devices.</li> </ul> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"cli\",\n        kwargs={\n            \"commands\": [\"show clock\"],\n            \"FC\": \"ceos-spine\",\n            \"plugin\": \"scrapli\"              \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_cli.py\n{'nornir-worker-1': {'errors': [],\n                     'failed': False,\n                     'messages': [],\n                     'result': {'ceos-spine-1': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local'},\n                                'ceos-spine-2': {'show clock': 'Sun Dec  1 '\n                                                               '11:10:53 2024\\n'\n                                                               'Timezone: UTC\\n'\n                                                               'Clock source: '\n                                                               'local'}},\n                     'task': 'nornir-worker-1:cli'}}\nC:\\nf&gt;                   \n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#outputting-text-tables","title":"Outputting Text Tables","text":"<p>NorFab interactive shell supports <code>table</code> argument  that can be used to format output into text tables. Internally it relies on tabulate module and most of its features are supported.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#sourcing-commands-from-file","title":"Sourcing Commands From File","text":"<p>Commands can be provided inline in the shell itself, but it is also possible to source commands from text files stored on broker.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-jinja2-templates","title":"Using Jinja2 Templates","text":"<p>Commands can be templated using Jinja2. This allows you to create dynamic commands based on variables defined in your inventory or passed as job data.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#templating-commands-with-inline-job-data","title":"Templating Commands with Inline Job Data","text":"<p>Templating commands with inline job data allows you to dynamically generate command strings based on variables defined directly within the job data. This approach provides flexibility and customization, enabling you to tailor commands to specific devices or scenarios without the need for external sourced of data.</p> <p>When defining a job, you can include variables directly within the <code>job_data</code> argument. These variables can then be referenced within the command strings using Jinja2 templating syntax. The Nornir worker will process these templates, substituting the variables with their corresponding values from the job data.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-dry-run","title":"Using Dry Run","text":"<p>The dry run feature allows you to see the commands that would be executed without actually sending them to the devices. This is useful for testing and validation. When set to <code>True</code>, the commands will not be sent to the devices, but will be returned as part of the result.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#formatting-output-results","title":"Formatting Output Results","text":"<p>You can format the output results using various options provided by the Nornir worker. The output of the commands can be formatted using the <code>to_dict</code> parameter. When set to <code>True</code>, the results will be returned as a dictionary. When set to <code>False</code>, the results will be returned as a list. In addition <code>add_details</code> argument can be used to control the verbosity of the output and return additional Nornir result information such as:</p> <ul> <li><code>changed</code> flag</li> <li><code>diff</code> content if supported by plugin</li> <li><code>failed</code> status</li> <li><code>exception</code> details if task execution failed with error</li> <li><code>connection_retry</code> counter to show how many times RetryRunner tried to establish a connection</li> <li><code>task_retry</code> counter to show how many times RetryRunner tried to run this task</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#running-show-commands-multiple-times","title":"Running Show Commands Multiple Times","text":"<p>You can run show commands multiple times using the <code>repeat</code> parameter. This is useful for monitoring changes over time. The <code>repeat</code> parameter can be used to run the same command multiple times. You can also specify the interval between each repeat using the <code>repeat_interval</code> parameter.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-netmiko-promptless-mode","title":"Using Netmiko Promptless Mode","text":"<p>NorFab support proprietary promptless mode that can be used with Netmiko, it can be useful when dealing with devices that do not have a consistent prompt, or default Netmiko output collection functions are not reliable enough. This mode can be enabled by setting the <code>use_ps</code> parameter to <code>True</code>.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#parsing-commands-output","title":"Parsing Commands Output","text":"<p>When using Netmiko plugin the output of commands can be parsed using various parsers such as <code>textfsm</code>, <code>ttp</code> and <code>genie</code>. This allows you to convert the raw output into structured data. </p> <p>Using TTP parsing templates supported by all Netmiko, Scrapli and NAPALM connection plugins, to invoke TTP can us <code>run_ttp</code> command specifying path to parsing template stored on broker. </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#filtering-commands-output","title":"Filtering Commands Output","text":"<p>The output of commands can be filtered to only include specific information. This can be done using <code>match</code> command with containment patterns.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#sending-new-line-character","title":"Sending New Line Character","text":"<p>You can send a new line character as part of the command to devices. This is useful for commands that require a new line to be executed properly. To send new-line character need to include <code>_br_</code> into command text.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#saving-task-results-to-files","title":"Saving Task Results to Files","text":"<p>The results of tasks can be saved to files for later analysis and record-keeping. This is particularly useful for maintaining logs of command outputs, configuration changes, and other important data. By saving task results to files, you can create a historical record of network operations, which can be invaluable for troubleshooting, auditing, and compliance purposes.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#using-diff-function-to-compare-results","title":"Using Diff Function to Compare Results","text":"<p>The diff function allows you to compare the results of different task results for same commands. This is useful for identifying changes in configurations or device state, detecting anomalies, and verifying the impact of network modifications. By using the diff function, you can ensure that your network remains consistent and identify any unintended changes that may have occurred.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#norfab-nornir-cli-shell-reference","title":"NORFAB Nornir CLI Shell Reference","text":"<p>The NorFab shell provides a comprehensive set of commands for the Nornir <code>cli</code> task, allowing you to perform various network utility functions. These commands include options for setting job timeouts, specifying connection parameters, and controlling the execution of CLI commands. The shell reference details the available commands and their descriptions, providing you with the flexibility to tailor the behavior of the tasks to meet your specific network management needs.</p> <pre><code>nf#man tree nornir.cli\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 cli:    Send CLI commands to devices\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress, default 'True'\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *commands:    List of commands to collect form devices, default 'PydanticUndefined'\n        \u251c\u2500\u2500 plugin:    Connection plugin parameters\n        \u2502   \u251c\u2500\u2500 netmiko:    Use Netmiko plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 enable:    Attempt to enter enable-mode\n        \u2502   \u2502   \u251c\u2500\u2500 use_timing:    switch to send command timing method\n        \u2502   \u2502   \u251c\u2500\u2500 expect_string:    Regular expression pattern to use for determining end of output\n        \u2502   \u2502   \u251c\u2500\u2500 read_timeout:    Maximum time to wait looking for pattern\n        \u2502   \u2502   \u251c\u2500\u2500 auto_find_prompt:    Use find_prompt() to override base prompt\n        \u2502   \u2502   \u251c\u2500\u2500 strip_prompt:    Remove the trailing router prompt from the output\n        \u2502   \u2502   \u251c\u2500\u2500 strip_command:    Remove the echo of the command from the output\n        \u2502   \u2502   \u251c\u2500\u2500 normalize:    Ensure the proper enter is sent at end of command\n        \u2502   \u2502   \u251c\u2500\u2500 use_textfsm:    Process command output through TextFSM template\n        \u2502   \u2502   \u251c\u2500\u2500 textfsm_template:    Name of template to parse output with\n        \u2502   \u2502   \u251c\u2500\u2500 use_ttp:    Process command output through TTP template\n        \u2502   \u2502   \u251c\u2500\u2500 ttp_template:    Name of template to parse output with\n        \u2502   \u2502   \u251c\u2500\u2500 use_genie:    Process command output through PyATS/Genie parser\n        \u2502   \u2502   \u251c\u2500\u2500 cmd_verify:    Verify command echo before proceeding\n        \u2502   \u2502   \u251c\u2500\u2500 interval:    Interval between sending commands\n        \u2502   \u2502   \u251c\u2500\u2500 use_ps:    Use send command promptless method\n        \u2502   \u2502   \u251c\u2500\u2500 use_ps_timeout:    Promptless mode absolute timeout\n        \u2502   \u2502   \u251c\u2500\u2500 new_line_char:    Character to replace with new line before sending to device, default is _br_\n        \u2502   \u2502   \u251c\u2500\u2500 repeat:    Number of times to repeat the commands\n        \u2502   \u2502   \u251c\u2500\u2500 stop_pattern:    Stop commands repeat if output matches provided glob pattern\n        \u2502   \u2502   \u251c\u2500\u2500 repeat_interval:    Time in seconds to wait between repeating commands\n        \u2502   \u2502   \u2514\u2500\u2500 return_last:    Returns requested last number of commands outputs\n        \u2502   \u251c\u2500\u2500 scrapli:    Use Scrapli plugin to configure devices\n        \u2502   \u2502   \u251c\u2500\u2500 failed_when_contains:    String or list of strings indicating failure if found in response\n        \u2502   \u2502   \u251c\u2500\u2500 timeout_ops:    Timeout ops value for this operation\n        \u2502   \u2502   \u251c\u2500\u2500 interval:    Interval between sending commands\n        \u2502   \u2502   \u251c\u2500\u2500 split_lines:    Split multiline string to individual commands\n        \u2502   \u2502   \u251c\u2500\u2500 new_line_char:    Character to replace with new line before sending to device, default is _br_\n        \u2502   \u2502   \u251c\u2500\u2500 repeat:    Number of times to repeat the commands\n        \u2502   \u2502   \u251c\u2500\u2500 stop_pattern:    Stop commands repeat if output matches provided glob pattern\n        \u2502   \u2502   \u251c\u2500\u2500 repeat_interval:    Time in seconds to wait between repeating commands\n        \u2502   \u2502   \u2514\u2500\u2500 return_last:    Returns requested last number of commands outputs\n        \u2502   \u2514\u2500\u2500 napalm:    Use NAPALM plugin to configure devices\n        \u2502       \u251c\u2500\u2500 interval:    Interval between sending commands\n        \u2502       \u251c\u2500\u2500 split_lines:    Split multiline string to individual commands\n        \u2502       \u2514\u2500\u2500 new_line_char:    Character to replace with new line before sending to device, default is _br_\n        \u251c\u2500\u2500 cli_dry_run:    Dry run the commands\n        \u251c\u2500\u2500 enable:    Enter exec mode\n        \u251c\u2500\u2500 run_ttp:    TTP Template to run\n        \u2514\u2500\u2500 job_data:    Path to YAML file with job data\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_cli/#python-api-reference","title":"Python API Reference","text":"<p>Task to collect show commands output from devices using Command Line Interface (CLI)</p> <p>Parameters:</p> Name Type Description Default <code>commands</code> <code>list</code> <p>list of commands to send to devices</p> <code>None</code> <code>plugin</code> <code>str</code> <p>plugin name to use - valid options are <code>netmiko</code>, <code>scrapli</code>, <code>napalm</code></p> <code>'netmiko'</code> <code>cli_dry_run</code> <code>bool</code> <p>do not send commands to devices just return them</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False will produce results list</p> <code>True</code> <code>run_ttp</code> <code>str</code> <p>TTP Template to run</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def cli(\n    self,\n    commands: list = None,\n    plugin: str = \"netmiko\",\n    cli_dry_run: bool = False,\n    run_ttp: str = None,\n    job_data: str = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to collect show commands output from devices using\n    Command Line Interface (CLI)\n\n    :param commands: list of commands to send to devices\n    :param plugin: plugin name to use - valid options are ``netmiko``, ``scrapli``, ``napalm``\n    :param cli_dry_run: do not send commands to devices just return them\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param add_details: if True will add task execution details to the results\n    :param to_dict: default is True - produces dictionary results, if False\n        will produce results list\n    :param run_ttp: TTP Template to run\n    \"\"\"\n    job_data = job_data or {}\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:cli\", result={} if to_dict else [])\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_send_commands\n        if kwargs.get(\"use_ps\"):\n            kwargs.setdefault(\"timeout\", timeout)\n        else:\n            kwargs.setdefault(\"read_timeout\", timeout)\n    elif plugin == \"scrapli\":\n        task_plugin = scrapli_send_commands\n        kwargs.setdefault(\"timeout_ops\", timeout)\n    elif plugin == \"napalm\":\n        task_plugin = napalm_send_commands\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    # download TTP template\n    if self.is_url(run_ttp):\n        downloaded = self.fetch_file(run_ttp)\n        kwargs[\"run_ttp\"] = downloaded\n        if downloaded is None:\n            msg = f\"{self.name} - TTP template download failed '{run_ttp}'\"\n            raise FileNotFoundError(msg)\n    # use TTP template as is - inline template or ttp://xyz path\n    elif run_ttp:\n        kwargs[\"run_ttp\"] = run_ttp\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # render commands using Jinja2 on a per-host basis\n    if commands:\n        commands = commands if isinstance(commands, list) else [commands]\n        for host in nr.inventory.hosts.values():\n            rendered = self.render_jinja2_templates(\n                templates=commands,\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n            host.data[\"__task__\"] = {\"commands\": rendered}\n\n    # run task\n    log.debug(\n        f\"{self.name} - running cli commands '{commands}', kwargs '{kwargs}', is cli dry run - '{cli_dry_run}'\"\n    )\n    if cli_dry_run is True:\n        result = nr.run(\n            task=nr_test, use_task_data=\"commands\", name=\"cli_dry_run\", **kwargs\n        )\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    # remove __task__ data\n    for host_name, host_object in nr.inventory.hosts.items():\n        _ = host_object.data.pop(\"__task__\", None)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/","title":"Nornir Service Diagram Task","text":"<p>task api name: <code>diagram</code></p> <p>The Nornir Service Diagram Task is a powerful component of NorFab's Nornir service, designed to create detailed network diagrams. By leveraging the N2G (Need to Graph) module, this task enables network engineers and architects to visualize network topologies and configurations, facilitating better network management and planning.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-layer-2-network-diagram","title":"Creating Layer-2 Network Diagram","text":"<p>Layer-2 network diagrams illustrate the data link layer of the OSI model, showing how devices are interconnected within a local area network (LAN) based on the output provided by LLDP and CDP protocols. These diagrams are essential for understanding the physical and logical connections between switches, routers, and other network devices. By creating Layer-2 network diagrams, you can identify potential bottlenecks, optimize traffic flow, and ensure efficient network design. The Nornir Service Diagram Task uses the N2G module to automatically generate these diagrams, providing a clear and accurate representation of your Layer-2 topology.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-layer-3-network-diagram","title":"Creating Layer-3 Network Diagram","text":"<p>Layer-3 network diagrams depict the network layer of the OSI model, highlighting the routing and IP addressing within a network. These diagrams are crucial for understanding how data is routed between different subnets and networks. By creating Layer-3 network diagrams, you can visualize the routing paths, identify potential routing issues, and ensure proper IP address allocation. The Nornir Service Diagram Task leverages the N2G module to construct these diagrams, offering a comprehensive view of your Layer-3 network infrastructure.</p> <p>Example</p> CLI <pre><code>nf#\nnf#\nnf#nornir\nnf[nornir]#diagram\nnf[nornir-diagram]#layer3 FC spine,leaf\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 22:59:56 85fd42146327446cae3c26ceb2077abf job started\n04-Jan-2025 22:59:56.664 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n&lt;omitted for brevity&gt;\n04-Jan-2025 22:59:58 85fd42146327446cae3c26ceb2077abf job completed in 2.117 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\ndiagram: 'layer3', format: 'yed'\nsaved at: './diagrams\\layer3_2025-01-04_22-59-56.graphml'\nhosts: ceos-leaf-1, ceos-leaf-2, ceos-leaf-3, ceos-spine-1, ceos-spine-2\nnf[nornir-diagram]#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>diagram</code> command switches to the diagram task sub-shell.</li> <li><code>layer3</code> command run commands output collection for devices that have <code>spine</code> or <code>leaf</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter, once output collected N2G parses commands output and constructs L3 Network diagram of subnets and IP addresses saving diagram in yEd compatible format at <code>./diagrams\\layer3_2025-01-04_22-59-56.graphml</code> file.</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-ospf-routing-protocol-network-diagram","title":"Creating OSPF Routing Protocol Network Diagram","text":"<p>OSPF (Open Shortest Path First) is a widely used interior gateway protocol for routing within an autonomous system. Creating OSPF routing protocol network diagrams helps you visualize the OSPF areas, router adjacencies, and link metrics. These diagrams are useful for troubleshooting OSPF-related issues, optimizing OSPF configurations, and ensuring efficient routing. The Nornir Service Diagram Task utilizes the N2G module to generate OSPF network diagrams, providing a detailed view of your OSPF topology and configurations.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-isis-routing-protocol-network-diagram","title":"Creating ISIS Routing Protocol Network Diagram","text":"<p>ISIS (Intermediate System to Intermediate System) is a popular interior gateway protocol used for routing within large networks. Creating ISIS routing protocol network diagrams allows you to visualize the ISIS areas, router adjacencies, and link metrics. These diagrams are vital for understanding the ISIS routing process, identifying potential issues and optimizing the network. The Nornir Service Diagram Task utilizes the N2G module to generate ISIS network diagrams, providing a detailed view of your ISIS topology and configurations.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#creating-drawio-diagrams","title":"Creating draw.io Diagrams","text":"<p>N2G module can produce diagrams in several formats, to create draw.io diagram need to use <code>format</code> argument with <code>drawio</code> value.</p> <p>Example</p> CLI <pre><code>nf#\nnf#\nnf#nornir\nnf[nornir]#diagram\nnf[nornir-diagram]#format drawio layer3 FC spine,leaf\n--------------------------------------------- Job Events -----------------------------------------------\n04-Jan-2025 23:16:13 a2d39b5b1268488a95805baed96699a1 job started\n04-Jan-2025 23:16:14.277 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n04-Jan-2025 23:16:14.289 nornir nornir-worker-2 ceos-leaf-1, ceos-leaf-2, ceos-leaf-3 task started - 'netmiko_send_commands'\n&lt;omitted for brevity&gt;\n04-Jan-2025 23:16:16 a2d39b5b1268488a95805baed96699a1 job completed in 2.606 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\ndiagram: 'layer3', format: 'drawio'\nsaved at: './diagrams\\layer3_2025-01-04_23-16-13.drawio'\nhosts: ceos-leaf-1, ceos-leaf-2, ceos-leaf-3, ceos-spine-1, ceos-spine-2\nnf[nornir-diagram]#\n</code></pre> <ul> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>diagram</code> command switches to the diagram task sub-shell.</li> <li><code>format</code> argument specifies what diagram format to create, draw.io in this case.</li> <li><code>layer3</code> command run commands output collection for devices that have <code>spine</code> or <code>leaf</code> in their hostname as we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter, once output collected N2G parses commands output and constructs L3 Network diagram of subnets and IP addresses saving diagram in draw.io compatible format at <code>./diagrams\\layer3_2025-01-04_23-16-13.drawio</code> file.</li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_diagram/#norfab-nornir-diagram-shell-reference","title":"NORFAB Nornir Diagram Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>diagram</code> task:</p> <pre><code>nf#man tree nornir.diagram\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 diagram:    Produce network diagrams\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 format:    Diagram application format, default 'yed'\n        \u251c\u2500\u2500 layer3:    Create L3 Network diagram using IP data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 group_links:    Group links between same nodes\n        \u2502   \u251c\u2500\u2500 add_arp:    Add IP nodes from ARP cache parsing results\n        \u2502   \u251c\u2500\u2500 label_interface:    Add interface name to the link\u2019s source and target labels\n        \u2502   \u251c\u2500\u2500 label_vrf:    Add VRF name to the link\u2019s source and target labels\n        \u2502   \u251c\u2500\u2500 collapse_ptp:    Combines links for /31 and /30 IPv4 and /127 IPv6 subnets into a single link\n        \u2502   \u251c\u2500\u2500 add_fhrp:    Add HSRP and VRRP IP addresses to the diagram\n        \u2502   \u251c\u2500\u2500 bottom_label_length:    Length of interface description to use for subnet labels, if 0, label not set\n        \u2502   \u2514\u2500\u2500 lbl_next_to_subnet:    Put link port:vrf:ip label next to subnet node\n        \u251c\u2500\u2500 layer2:    Create L2 Network diagram using CDP/LLDP data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 add_interfaces_data:    Add interfaces configuration and state data to links\n        \u2502   \u251c\u2500\u2500 group_links:    Group links between nodes\n        \u2502   \u251c\u2500\u2500 add_lag:    Add LAG/MLAG links to diagram\n        \u2502   \u251c\u2500\u2500 add_all_connected:    Add all nodes connected to devices based on interfaces state\n        \u2502   \u251c\u2500\u2500 combine_peers:    Combine CDP/LLDP peers behind same interface by adding L2 node\n        \u2502   \u2514\u2500\u2500 skip_lag:    Skip CDP peers for LAG, some platforms send CDP/LLDP PDU from LAG ports\n        \u251c\u2500\u2500 isis:    Create ISIS Network diagram using LSDB data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 ip_lookup_data:    IP Lookup dictionary or OS path to CSV file\n        \u2502   \u251c\u2500\u2500 add_connected:    Add connected subnets as nodes\n        \u2502   \u251c\u2500\u2500 ptp_filter:    List of glob patterns to filter point-to-point links based on link IP\n        \u2502   \u2514\u2500\u2500 add_data:    Add data information to nodes and links\n        \u251c\u2500\u2500 ospf:    Create OSPF Network diagram using LSDB data\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 ip_lookup_data:    IP Lookup dictionary or OS path to CSV file\n        \u2502   \u251c\u2500\u2500 add_connected:    Add connected subnets as nodes\n        \u2502   \u251c\u2500\u2500 ptp_filter:    List of glob patterns to filter point-to-point links based on link IP\n        \u2502   \u2514\u2500\u2500 add_data:    Add data information to nodes and links\n        \u2514\u2500\u2500 filename:    Name of the file to save diagram content\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/","title":"Nornir Service File Copy Task","text":"<p>task api name: <code>file_copy</code></p> <p>The Nornir Service File Copy Task is a component of NorFab's Nornir service, designed to facilitate the transfer of files to and from network devices. This task provides network engineers with a reliable and efficient method for managing device configurations, firmware updates, and other critical files. By leveraging the capabilities of the Nornir service, users can automate file transfers.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/#nornir-file-copy-sample-usage","title":"Nornir File Copy Sample Usage","text":"","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/#norfab-nornir-file-copy-shell-reference","title":"NORFAB Nornir File Copy Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>file-copy</code> task:</p> <pre><code>nf#man tree nornir.file-copy\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 file-copy:    Copy files to/from devices\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *source_file:    Source file to copy\n        \u251c\u2500\u2500 plugin:    Connection plugin parameters\n        \u2502   \u2514\u2500\u2500 netmiko:    Use Netmiko plugin to copy files\n        \u2502       \u251c\u2500\u2500 dest-file:    Destination file to copy\n        \u2502       \u251c\u2500\u2500 file-system:    Destination file system\n        \u2502       \u251c\u2500\u2500 direction:    Direction of file copy, default 'put'\n        \u2502       \u251c\u2500\u2500 inline-transfer:    Use inline transfer, supported by Cisco IOS\n        \u2502       \u251c\u2500\u2500 overwrite-file:    Overwrite destination file if it exists, default 'False'\n        \u2502       \u251c\u2500\u2500 socket-timeout:    Socket timeout in seconds, default '10.0'\n        \u2502       \u2514\u2500\u2500 verify-file:    Verify destination file hash after copy, default 'True'\n        \u2514\u2500\u2500 dry-run:    Do not copy files, just show what would be done\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_file_copy/#python-api-reference","title":"Python API Reference","text":"<p>Task to transfer files to and from hosts using SCP</p> <p>Parameters:</p> Name Type Description Default <code>source_file</code> <code>str</code> <p>path to file to copy, support <code>nf://path/to/file</code> URL to copy from broker</p> required <code>plugin</code> <code>str</code> <p>plugin name to use - <code>netmiko</code></p> <code>'netmiko'</code> <code>to_dict</code> <code>bool</code> <p>default is True - produces dictionary results, if False produces list</p> <code>True</code> <code>add_details</code> <code>bool</code> <p>if True will add task execution details to the results</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>if True will not copy files just return what would be copied</p> <code>False</code> <code>kwargs</code> <p>additional arguments to pass to the plugin function</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with the results of the file copy task</p> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def file_copy(\n    self,\n    source_file: str,\n    plugin: str = \"netmiko\",\n    to_dict: bool = True,\n    add_details: bool = False,\n    dry_run: bool = False,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Task to transfer files to and from hosts using SCP\n\n    :param source_file: path to file to copy, support ``nf://path/to/file`` URL to copy from broker\n    :param plugin: plugin name to use - ``netmiko``\n    :param to_dict: default is True - produces dictionary results, if False produces list\n    :param add_details: if True will add task execution details to the results\n    :param dry_run: if True will not copy files just return what would be copied\n    :param kwargs: additional arguments to pass to the plugin function\n    :return: dictionary with the results of the file copy task\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    timeout = self.current_job[\"timeout\"] * 0.9\n    ret = Result(task=f\"{self.name}:file_copy\", result={} if to_dict else [])\n\n    # download file from broker\n    if self.is_url(source_file):\n        source_file_local = self.fetch_file(\n            source_file, raise_on_fail=True, read=False\n        )\n\n    # decide on what send commands task plugin to use\n    if plugin == \"netmiko\":\n        task_plugin = netmiko_file_transfer\n        kwargs[\"source_file\"] = source_file_local\n        kwargs.setdefault(\"socket_timeout\", timeout / 5)\n        kwargs.setdefault(\"dest_file\", os.path.split(source_file_local)[-1])\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(\n        f\"{self.name} - running file copy with arguments '{kwargs}', is dry run - '{dry_run}'\"\n    )\n    if dry_run is True:\n        result = nr.run(task=nr_test, name=\"file_copy_dry_run\", **kwargs)\n    else:\n        with self.connections_lock:\n            result = nr.run(task=task_plugin, **kwargs)\n\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_update(nr, plugin)\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/","title":"Nornir Service Network Task","text":"<p>task api name: <code>network</code></p> <p>The Nornir Service Network Task is a component of NorFab's Nornir service designed to facilitate various network-related operations. This task suite provides network professionals with essential tools for managing, troubleshooting, and monitoring network infrastructure. By leveraging the capabilities of the Nornir service, users can perform critical network functions such as ICMP echo requests (ping) and DNS resolution checks, ensuring the reliability and performance of their network devices and services.</p> <p>Key features of the Nornir Service Network Task include:</p> <ul> <li> <p>Network Ping: This task allows you to perform ICMP echo requests to verify the reachability of network devices. </p> </li> <li> <p>DNS Testing: This task enables you to perform DNS resolution checks to ensure that domain names are correctly mapped to their respective IP addresses. </p> </li> </ul> <p>The document also includes a reference for the NorFab shell commands related to the Nornir <code>network</code> task, detailing the available options and parameters. These commands provide granular control over the execution of network tasks, enabling users to tailor the behavior of the tasks to meet specific network management needs.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#network-ping","title":"Network Ping","text":"<p>The Network Ping task in NorFab's Nornir service allows you to perform ICMP echo requests (pings) to verify the reachability of network devices. This task is essential for network troubleshooting and monitoring, as it helps you determine if a device is online and responsive. The ping task can be customized with various parameters such as timeout, number of retries, payload size and others. By using the ping task, you can quickly identify connectivity issues and ensure that your network devices are functioning correctly.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#dns-testing","title":"DNS Testing","text":"<p>The DNS Testing task in NorFab's Nornir service enables you to perform DNS resolution checks to verify that domain names are correctly mapped to their respective IP addresses. This task is crucial for ensuring that your DNS infrastructure is working as expected and that your network services are accessible via their domain names. The DNS testing task can be configured with different parameters to control the behavior of the DNS queries, such as specifying the DNS server to use, query timeout, and the type of DNS record to query. By performing DNS tests, you can proactively identify and resolve DNS-related issues, ensuring seamless network operations.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#norfab-nornir-network-shell-reference","title":"NORFAB Nornir Network Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>network</code> task:</p> <pre><code>nf#man tree nornir.network\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 network:    Network utility functions - ping, dns etc.\n        \u251c\u2500\u2500 ping:    Ping devices\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Emit execution progress\n        \u2502   \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u2502   \u251c\u2500\u2500 headers:    Table headers\n        \u2502   \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u2502   \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u2502   \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u251c\u2500\u2500 use_host_name:    Ping host's name instead of host's hostname\n        \u2502   \u251c\u2500\u2500 count:    Number of pings to run\n        \u2502   \u251c\u2500\u2500 ping_timeout:    Time in seconds before considering each non-arrived reply permanently lost\n        \u2502   \u251c\u2500\u2500 size:    Size of the entire packet to send\n        \u2502   \u251c\u2500\u2500 interval:    Interval to wait between pings\n        \u2502   \u251c\u2500\u2500 payload:    Payload content if size is not set\n        \u2502   \u251c\u2500\u2500 sweep_start:    If size is not set, initial size in a sweep of sizes\n        \u2502   \u251c\u2500\u2500 sweep_end:    If size is not set, final size in a sweep of sizes\n        \u2502   \u251c\u2500\u2500 df:    Don't Fragment flag value for IP Header\n        \u2502   \u251c\u2500\u2500 match:    Do payload matching between request and reply\n        \u2502   \u2514\u2500\u2500 source:    Source IP address\n        \u2514\u2500\u2500 dns:    Resolve DNS\n            \u251c\u2500\u2500 timeout:    Job timeout\n            \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n            \u251c\u2500\u2500 add_details:    Add task details to results\n            \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n            \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n            \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n            \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n            \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n            \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n            \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n            \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n            \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n            \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n            \u251c\u2500\u2500 diff:    File group name to run the diff for\n            \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n            \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n            \u251c\u2500\u2500 headers:    Table headers\n            \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n            \u251c\u2500\u2500 sortby:    Table header column to sort by\n            \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n            \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n            \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n            \u251c\u2500\u2500 FH:    Filter hosts by hostname\n            \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n            \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n            \u251c\u2500\u2500 FG:    Filter hosts by group\n            \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n            \u251c\u2500\u2500 FL:    Filter hosts by names list\n            \u251c\u2500\u2500 FM:    Filter hosts by platform\n            \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n            \u251c\u2500\u2500 FN:    Negate the match\n            \u251c\u2500\u2500 hosts:    Filter hosts to target\n            \u251c\u2500\u2500 use_host_name:    Ping host's name instead of host's hostname\n            \u251c\u2500\u2500 servers:    List of DNS servers to use\n            \u251c\u2500\u2500 dns_timeout:    Time in seconds before considering request lost\n            \u251c\u2500\u2500 ipv4:    Resolve 'A' record\n            \u2514\u2500\u2500 ipv6:    Resolve 'AAAA' record\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_network/#python-api-reference","title":"Python API Reference","text":"<p>Task to call various network related utility functions.</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <p>(str) utility function name to call</p> required <code>kwargs</code> <p>(dict) function arguments  Available utility functions.  resolve_dns function  resolves hosts' hostname DNS returning IP addresses using <code>nornir_salt.plugins.tasks.network.resolve_dns</code> Nornir-Salt function.  ping function  Function to execute ICMP ping to host using <code>nornir_salt.plugins.tasks.network.ping</code> Nornir-Salt function.</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def network(self, fun, **kwargs) -&gt; dict:\n    \"\"\"\n    Task to call various network related utility functions.\n\n    :param fun: (str) utility function name to call\n    :param kwargs: (dict) function arguments\n\n    Available utility functions.\n\n    **resolve_dns** function\n\n    resolves hosts' hostname DNS returning IP addresses using\n    ``nornir_salt.plugins.tasks.network.resolve_dns`` Nornir-Salt\n    function.\n\n    **ping** function\n\n    Function to execute ICMP ping to host using\n    ``nornir_salt.plugins.tasks.network.ping`` Nornir-Salt\n    function.\n    \"\"\"\n    kwargs[\"call\"] = fun\n    return self.task(\n        plugin=\"nornir_salt.plugins.tasks.network\",\n        **kwargs,\n    )\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_parse/","title":"Nornir Service Parse Task","text":"<p>task api name: <code>parse</code></p> <p>The Nornir Service Parse Task is an integral part of NorFab's Nornir service, designed to facilitate the parsing and extraction of valuable information from network device outputs. This task provides network automation and developer engineers with powerful tools to transform raw command outputs into structured data, enabling more efficient network management and automation workflows.</p> <p>Key features of the Nornir Service Parse Task include:</p> <ul> <li> <p>TextFSM Parsing: This task allows you to use TextFSM templates to parse command outputs into structured data. TextFSM is a powerful text processing tool that uses templates to define how to extract data from unstructured text. By leveraging TextFSM, you can convert complex command outputs into easily readable and processable data formats, which can then be used for further analysis or automation tasks.</p> </li> <li> <p>TTP Parsing: The Template Text Parser (TTP) is a robust parsing tool supported by the Nornir Service Parse Task. TTP allows you to define templates for parsing text data, similar to TextFSM, but with additional flexibility and features. Using TTP, you can extract specific information from command outputs and transform it into structured data, making it easier to integrate with other systems and processes.</p> </li> <li> <p>NAPALM Getters: The Nornir Service Parse Task leverages NAPALM getters to retrieve and parse structured data directly from network devices. NAPALM getters are pre-defined methods that extract specific pieces of information from devices, such as interface details, routing tables, ARP tables, and more.</p> </li> </ul> <p>The Nornir Service Parse Task is essential for network automation and developer engineers who need to process and analyze large volumes of network data. By transforming raw command outputs into structured data, you can automate complex workflows, generate insightful reports, and ensure that your network devices are configured and operating correctly.</p> <p>This document also includes a reference for the NorFab shell commands related to the Nornir <code>parse</code> task, detailing the available options and parameters. These commands provide granular control over the parsing tasks.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_parse/#norfab-nornir-parse-shell-reference","title":"NORFAB Nornir Parse Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>parse</code> task:</p> <pre><code>nf#man tree nornir.parse\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 parse:    Parse network devices output\n        \u251c\u2500\u2500 napalm:    Parse devices output using NAPALM getters\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u2502   \u251c\u2500\u2500 add_details:    Add task details to results\n        \u2502   \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u2502   \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u2502   \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u2502   \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u2502   \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u2502   \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u2502   \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u2502   \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u2502   \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u2502   \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u2502   \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u2502   \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u2502   \u251c\u2500\u2500 progress:    Emit execution progress\n        \u2502   \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u2502   \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u2502   \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u2502   \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u2502   \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u2502   \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u2502   \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u2502   \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u2502   \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u2502   \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u2502   \u251c\u2500\u2500 FN:    Negate the match\n        \u2502   \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u2502   \u2514\u2500\u2500 *getters:    Select NAPALM getters, default 'PydanticUndefined'\n        \u2514\u2500\u2500 ttp:    Parse devices output using TTP templates\n            \u251c\u2500\u2500 timeout:    Job timeout\n            \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n            \u251c\u2500\u2500 add_details:    Add task details to results\n            \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n            \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n            \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n            \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n            \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n            \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n            \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n            \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n            \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n            \u251c\u2500\u2500 diff:    File group name to run the diff for\n            \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n            \u251c\u2500\u2500 progress:    Emit execution progress\n            \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n            \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n            \u251c\u2500\u2500 FH:    Filter hosts by hostname\n            \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n            \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n            \u251c\u2500\u2500 FG:    Filter hosts by group\n            \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n            \u251c\u2500\u2500 FL:    Filter hosts by names list\n            \u251c\u2500\u2500 FM:    Filter hosts by platform\n            \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n            \u251c\u2500\u2500 FN:    Negate the match\n            \u251c\u2500\u2500 hosts:    Filter hosts to target\n            \u251c\u2500\u2500 *template:    TTP Template to parse commands output, default 'PydanticUndefined'\n            \u2514\u2500\u2500 commands:    Commands to collect form devices\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_parse/#python-api-reference","title":"Python API Reference","text":"<p>Function to parse network devices show commands output</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>plugin name to use - <code>napalm</code>, <code>textfsm</code>, <code>ttp</code></p> <code>'napalm'</code> <code>getters</code> <code>str</code> <p>NAPALM getters to use</p> <code>'get_facts'</code> <code>commands</code> <code>list</code> <p>commands to send to devices for TextFSM or TTP template</p> <code>None</code> <code>template</code> <code>str</code> <p>TextFSM or TTP parsing template string or path to file  For NAPALM plugin <code>method</code> can refer to a list of getters names.</p> <code>None</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def parse(\n    self,\n    plugin: str = \"napalm\",\n    getters: str = \"get_facts\",\n    template: str = None,\n    commands: list = None,\n    to_dict: bool = True,\n    add_details: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Function to parse network devices show commands output\n\n    :param plugin: plugin name to use - ``napalm``, ``textfsm``, ``ttp``\n    :param getters: NAPALM getters to use\n    :param commands: commands to send to devices for TextFSM or TTP template\n    :param template: TextFSM or TTP parsing template string or path to file\n\n    For NAPALM plugin ``method`` can refer to a list of getters names.\n    \"\"\"\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:parse\", result={} if to_dict else [])\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        ret.messages.append(msg)\n        log.debug(msg)\n        return ret\n\n    if plugin == \"napalm\":\n        nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n        result = nr.run(task=napalm_get, getters=getters, **kwargs)\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    elif plugin == \"ttp\":\n        result = self.cli(\n            commands=commands or [],\n            run_ttp=template,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    elif plugin == \"textfsm\":\n        result = self.cli(\n            commands=commands,\n            **filters,\n            **kwargs,\n            to_dict=to_dict,\n            add_details=add_details,\n            use_textfsm=True,\n            textfsm_template=template,\n            plugin=\"netmiko\",\n        )\n        ret.result = result.result\n    else:\n        raise UnsupportedPluginError(f\"Plugin '{plugin}' not supported\")\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_runtime_inventory/","title":"Nornir Service Runtime Inventory Task","text":"<p>task api name: <code>runtime_inventory</code></p> <p>The Nornir Service <code>runtime_inventory</code> task designed to work with Nornir inventory content at a runtime. This task uses nornir-salt <code>InventoryFun</code> functions to create, read, update or delete hosts.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_runtime_inventory/#sample-usage","title":"Sample Usage","text":"<p>Sample NorFab client call to invoke inventory host creation:</p> <pre><code>result = nfclient.run_job(\n    \"nornir\",\n    \"runtime_inventory\",\n    workers=[\"nornir-worker-1\"],\n    kwargs={\n        \"action\": \"create_host\",\n        \"name\": \"foobar\"\n    },\n)\n</code></pre> <p>Supported actions are:</p> <ul> <li><code>create_host</code> or <code>create</code> - creates new host or replaces existing host object</li> <li><code>read_host</code> or <code>read</code> - read host inventory content</li> <li><code>update_host</code> or <code>update</code> - non recursively update host attributes if host exists in Nornir inventory, do not create host if it does not exist</li> <li><code>delete_host</code> or <code>delete</code> - deletes host object from Nornir Inventory</li> <li><code>load</code> - to simplify calling multiple functions</li> <li><code>read_inventory</code> - read inventory content for groups, default and hosts</li> <li><code>read_host_data</code> - to return host's data under provided path keys</li> <li><code>list_hosts</code> - return a list of inventory's host names</li> <li><code>list_hosts_platforms</code> - return a dictionary of hosts' platforms</li> <li><code>update_defaults</code> - non recursively update defaults attributes</li> </ul> <p>Sample nfcli command to create host:</p> <pre><code>nf#nornir inventory create-host name foobar\n--------------------------------------------- Job Events -----------------------------------------------\n15-Feb-2025 11:12:38.908 d42e073070b94d408225af2a880d1d26 job started\n15-Feb-2025 11:12:38.939 INFO nornir-worker-5 running nornir.runtime_inventory  - Performing 'create_host' action\n15-Feb-2025 11:12:39.162 d42e073070b94d408225af2a880d1d26 job completed in 0.254 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\n{\n    \"nornir-worker-5\": {\n        \"foobar\": true\n    }\n}\nnf#\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_runtime_inventory/#norfab-nornir-runtime-inventory-shell-reference","title":"NORFAB Nornir Runtime Inventory Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>runtime_inventory</code> task:</p> <pre><code>nf#man tree nornir.inventory\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 inventory:    Work with Nornir inventory\n        \u251c\u2500\u2500 create-host:    Create new host\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Nornir workers to target, default 'any'\n        \u2502   \u251c\u2500\u2500 *name:    Name of the host\n        \u2502   \u251c\u2500\u2500 username:    Host connections username\n        \u2502   \u251c\u2500\u2500 password:    Host connections password\n        \u2502   \u251c\u2500\u2500 platform:    Host platform recognized by connection plugin\n        \u2502   \u251c\u2500\u2500 hostname:    Hostname of the host to initiate connection with, IP address or FQDN\n        \u2502   \u251c\u2500\u2500 port:    TCP port to initiate connection with, default '22'\n        \u2502   \u251c\u2500\u2500 connection-options:    JSON string with connection options\n        \u2502   \u251c\u2500\u2500 groups:    List of groups to associate with this host\n        \u2502   \u251c\u2500\u2500 data:    JSON string with arbitrary host data\n        \u2502   \u2514\u2500\u2500 progress:    Display progress events, default 'True'\n        \u251c\u2500\u2500 update-host:    Update existing host details\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Nornir workers to target, default 'all'\n        \u2502   \u251c\u2500\u2500 *name:    Name of the host\n        \u2502   \u251c\u2500\u2500 username:    Host connections username\n        \u2502   \u251c\u2500\u2500 password:    Host connections password\n        \u2502   \u251c\u2500\u2500 hostname:    Hostname of the host to initiate connection with, IP address or FQDN\n        \u2502   \u251c\u2500\u2500 port:    TCP port to initiate connection with, default '22'\n        \u2502   \u251c\u2500\u2500 connection-options:    JSON string with connection options\n        \u2502   \u251c\u2500\u2500 groups:    List of groups to associate with this host\n        \u2502   \u251c\u2500\u2500 groups-action:    Action to perform with groups, default 'append'\n        \u2502   \u251c\u2500\u2500 data:    JSON string with arbitrary host data\n        \u2502   \u2514\u2500\u2500 progress:    Display progress events, default 'True'\n        \u251c\u2500\u2500 delete-host:    Delete host from inventory\n        \u2502   \u251c\u2500\u2500 timeout:    Job timeout\n        \u2502   \u251c\u2500\u2500 workers:    Nornir workers to target, default 'all'\n        \u2502   \u251c\u2500\u2500 *name:    Name of the host\n        \u2502   \u2514\u2500\u2500 progress:    Display progress events, default 'True'\n        \u2514\u2500\u2500 read-host-data:    Return host data at given dor-separated key path\n            \u251c\u2500\u2500 timeout:    Job timeout\n            \u251c\u2500\u2500 workers:    Nornir workers to target, default 'all'\n            \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n            \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n            \u251c\u2500\u2500 FH:    Filter hosts by hostname\n            \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n            \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n            \u251c\u2500\u2500 FG:    Filter hosts by group\n            \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n            \u251c\u2500\u2500 FL:    Filter hosts by names list\n            \u251c\u2500\u2500 FM:    Filter hosts by platform\n            \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n            \u251c\u2500\u2500 FN:    Negate the match\n            \u251c\u2500\u2500 hosts:    Filter hosts to target\n            \u251c\u2500\u2500 *keys:    Dot separated path within host data, examples: config.interfaces.Lo0\n            \u2514\u2500\u2500 progress:    Display progress events, default 'True'\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_runtime_inventory/#python-api-reference","title":"Python API Reference","text":"<p>Method to work with Nornir inventory in a runtime.</p> <p>Supported actions:</p> <ul> <li><code>create_host</code> or <code>create</code> - creates new host or replaces existing host object</li> <li><code>read_host</code> or <code>read</code> - read host inventory content</li> <li><code>update_host</code> or <code>update</code> - non recursively update host attributes if host exists     in Nornir inventory, do not create host if it does not exist</li> <li><code>delete_host</code> or <code>delete</code> - deletes host object from Nornir Inventory</li> <li><code>load</code> - to simplify calling multiple functions</li> <li><code>read_inventory</code> - read inventory content for groups, default and hosts</li> <li><code>read_host_data</code> - to return host's data under provided path keys</li> <li><code>list_hosts</code> - return a list of inventory's host names</li> <li><code>list_hosts_platforms</code> - return a dictionary of hosts' platforms</li> <li><code>update_defaults</code> - non recursively update defaults attributes</li> </ul> <p>Parameters:</p> Name Type Description Default <code>action</code> <p>action to perform on inventory</p> required <code>kwargs</code> <p>argument to use with the calling action</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def runtime_inventory(self, action, **kwargs) -&gt; dict:\n    \"\"\"\n    Method to work with Nornir inventory in a runtime.\n\n    Supported actions:\n\n    - `create_host` or `create` - creates new host or replaces existing host object\n    - `read_host` or `read` - read host inventory content\n    - `update_host` or `update` - non recursively update host attributes if host exists\n        in Nornir inventory, do not create host if it does not exist\n    - `delete_host` or `delete` - deletes host object from Nornir Inventory\n    - `load` - to simplify calling multiple functions\n    - `read_inventory` - read inventory content for groups, default and hosts\n    - `read_host_data` - to return host's data under provided path keys\n    - `list_hosts` - return a list of inventory's host names\n    - `list_hosts_platforms` - return a dictionary of hosts' platforms\n    - `update_defaults` - non recursively update defaults attributes\n\n    :param action: action to perform on inventory\n    :param kwargs: argument to use with the calling action\n    \"\"\"\n    # clean up kwargs\n    _ = kwargs.pop(\"progress\", None)\n    self.event(f\"Performing '{action}' action\")\n    return Result(result=InventoryFun(self.nr, call=action, **kwargs))\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/","title":"Nornir Service \"Task\" Task","text":"<p>task api name: <code>task</code></p> <p>The Nornir Service \"Task\" Task is a versatile component of NorFab's Nornir service, designed to execute any arbitrary Nornir task plugin function. This task provides network automation and developer engineers with the flexibility to run custom Nornir tasks, enabling them to tailor their network automation workflows to meet specific requirements.</p> <p>Key features of the Nornir Service \"Task\" Task include:</p> <ul> <li> <p>Custom Task Execution: The \"Task\" Task allows you to run custom Nornir task functions, which can be referenced using the OS path to the custom task Python file stored on broker or using dot notation to reference an import module. </p> </li> <li> <p>Integration with Nornir Plugins: The Nornir framework supports a wide range of community-built plugins, which can be called directly or leveraged to extend the functionality of your custom tasks. By integrating these plugins, you can enhance your automation capabilities and streamline complex network operations. Reference the Nornir Plugins page for a list of available plugins.</p> </li> <li> <p>Scalability and Reusability: Custom Nornir tasks can be designed to be scalable and reusable, allowing you to apply the same task logic across different network environments and scenarios. This promotes consistency and efficiency in your network automation workflows, reducing the need for repetitive coding and manual intervention.</p> </li> </ul>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#nornir-tasks-sample-usage","title":"Nornir Tasks Sample Usage","text":"<p>Example of calling Nornir custom task function stored on NORFAB  broker under <code>nornir_tasks/echo.py</code> file path:</p> <pre><code>\u251c\u2500\u2500\u2500inventory.yaml\n\u2514\u2500\u2500\u2500nornir_tasks\n    \u2514\u2500\u2500\u2500echo.py\n</code></pre> <p>Task <code>echo.py</code> takes provided arguments and echoes them back in results:</p> <pre><code>from nornir.core.task import Result, Task\n\n\ndef task(task: Task, **kwargs) -&gt; Result:\n    task.name = \"echo\"\n    return Result(host=task.host, result=kwargs)\n</code></pre> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir]#task\nnf[nornir-task]#plugin nf://nornir_tasks/echo.py arguments {\"foo\": \"bar\"} FC spine\nceos-spine-1:\n    echo:\n        foo: bar\nceos-spine-2:\n    echo:\n        foo: bar\nnf[nornir-task]#top\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>Above runs <code>echo.py</code> custom Nornir task taking arguments <code>{\"foo\": \"bar\"}</code>  as an input and echoing them back. Task only executed for  Nornir hosts that contain <code>ceos-spine</code> in their hostname as  we use <code>FC</code> - \"Filter Contains\" Nornir hosts targeting  filter.</p> <p><code>inventory.yaml</code> should be located in same folder where we  start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag  used. Refer to Getting Started  section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"task\",\n        kwargs={\n            \"plugin\": \"nf://nornir_tasks/echo.py\",\n            \"argument\": {\"foo\": \"bar\"},\n            \"FC\": \"ceos-spine\"    \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_task_docs.py\n{'nornir-worker-1': {'errors': [],\n                    'failed': False,\n                    'messages': [],\n                    'result': {'ceos-spine-1': {'echo': {'argument': {'foo': 'bar'}}},\n                                'ceos-spine-2': {'echo': {'argument': {'foo': 'bar'}}}},\n                    'task': 'nornir-worker-1:task'}}\n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.    </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#use-community-module-task","title":"Use Community Module Task","text":"<p>It is possible to run any Nornir task plugin created by open  source community. For example, to use <code>netmiko_send_commands</code> from  <code>nornir_netmiko</code> module need to set plugin argument to  <code>nornir_netmiko.tasks.netmiko_send_commands</code> value and supply <code>arguments</code> option to provide further task parameters.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir]#task\nnf[nornir-task]#plugin \"nornir_netmiko.tasks.netmiko_send_command\" arguments {\"command_string\": \"show hostname\"} FC spine\nceos-spine-1:\n    netmiko_send_command:\n        Hostname: ceos-spine-1\n        FQDN:     ceos-spine-1\nceos-spine-2:\n    netmiko_send_command:\n        Hostname: ceos-spine-2\n        FQDN:     ceos-spine-2\nnf[nornir-task]#top\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>Above runs <code>netmiko_send_command</code> Nornir task from <code>nornir_netmiko</code> module and collects <code>show hostname</code> command output from hosts that contain <code>ceos-spine</code> in their host name  since the use of targeting filter <code>FC</code> - \"Filter Contains\".</p> <p><code>inventory.yaml</code> should be located in same folder where we  start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag  used. Refer to Getting Started  section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"task\",\n        kwargs={\n            \"plugin\": \"nornir_netmiko.tasks.netmiko_send_command\",\n            \"command_string\": \"show hostname\",\n            \"FC\": \"ceos-spine\"    \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Notice slight difference, python api does not make use of <code>arguments</code> option and need to supply task parameters as is  inside of <code>kwargs</code> dictionary.</p> <p>Once executed, above code should produce this output:</p> <pre><code>C:\\nf&gt;python nornir_task_module_docs.py\n{'nornir-worker-1': {'errors': [],\n                    'failed': False,\n                    'messages': [],\n                    'result': {'ceos-spine-1': {'netmiko_send_command': 'Hostname: '\n                                                                        'ceos-spine-1\\n'\n                                                                        'FQDN:     '\n                                                                        'ceos-spine-1'},\n                                'ceos-spine-2': {'netmiko_send_command': 'Hostname: '\n                                                                        'ceos-spine-2\\n'\n                                                                        'FQDN:     '\n                                                                        'ceos-spine-2'}}}\n</code></pre> <p>Refer to Getting Started section on  how to construct  <code>inventory.yaml</code> file.    </p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#norfab-nornir-task-shell-reference","title":"NORFAB Nornir Task Shell Reference","text":"<p>NorFab shell supports these command options for Nornir <code>task</code> task:</p> <pre><code>nf#man tree nornir.task\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 task:    Run Nornir task\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 table:    Table format (brief, terse, extend) or parameters or True\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *plugin:    Nornir task.plugin.name to import or nf://path/to/plugin/file.py\n        \u2514\u2500\u2500 arguments:    Plugin arguments JSON formatted string\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_task/#python-api-reference","title":"Python API Reference","text":"<p>Task to invoke any of supported Nornir task plugins. This function performs dynamic import of requested plugin function and executes <code>nr.run</code> using supplied args and kwargs</p> <p><code>plugin</code> attribute can refer to a file to fetch from file service. File must contain function named <code>task</code> accepting Nornir task object as a first positional argument, for example:</p> <pre><code># define connection name for RetryRunner to properly detect it\nCONNECTION_NAME = \"netmiko\"\n\n# create task function\ndef task(nornir_task_object, **kwargs):\n    pass\n</code></pre> <p>CONNECTION_NAME</p> <p><code>CONNECTION_NAME</code> must be defined within custom task function file if RetryRunner in use, otherwise connection retry logic skipped and connections to all hosts initiated simultaneously up to the number of <code>num_workers</code>.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>(str) <code>path.to.plugin.task_fun</code> to import or <code>nf://path/to/task.py</code> to download custom task</p> required <code>kwargs</code> <p>(dict) arguments to use with specified task plugin</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def task(self, plugin: str, **kwargs) -&gt; Result:\n    \"\"\"\n    Task to invoke any of supported Nornir task plugins. This function\n    performs dynamic import of requested plugin function and executes\n    ``nr.run`` using supplied args and kwargs\n\n    ``plugin`` attribute can refer to a file to fetch from file service. File must contain\n    function named ``task`` accepting Nornir task object as a first positional\n    argument, for example:\n\n    ```python\n    # define connection name for RetryRunner to properly detect it\n    CONNECTION_NAME = \"netmiko\"\n\n    # create task function\n    def task(nornir_task_object, **kwargs):\n        pass\n    ```\n\n    !!! note \"CONNECTION_NAME\"\n\n        ``CONNECTION_NAME`` must be defined within custom task function file if\n        RetryRunner in use, otherwise connection retry logic skipped and connections\n        to all hosts initiated simultaneously up to the number of ``num_workers``.\n\n    :param plugin: (str) ``path.to.plugin.task_fun`` to import or ``nf://path/to/task.py``\n        to download custom task\n    :param kwargs: (dict) arguments to use with specified task plugin\n    \"\"\"\n    # extract attributes\n    add_details = kwargs.pop(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.pop(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:task\", result={} if to_dict else [])\n\n    # download task from broker and load it\n    if plugin.startswith(\"nf://\"):\n        function_text = self.fetch_file(plugin)\n        if function_text is None:\n            raise FileNotFoundError(\n                f\"{self.name} - '{plugin}' task plugin download failed\"\n            )\n\n        # load task function running exec\n        globals_dict = {}\n        exec(function_text, globals_dict, globals_dict)\n        task_function = globals_dict[\"task\"]\n    # import task function\n    else:\n        # below same as \"from nornir.plugins.tasks import task_fun as task_function\"\n        task_fun = plugin.split(\".\")[-1]\n        module = __import__(plugin, fromlist=[\"\"])\n        task_function = getattr(module, task_fun)\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        return ret\n\n    nr = self._add_processors(filtered_nornir, kwargs)  # add processors\n\n    # run task\n    log.debug(f\"{self.name} - running Nornir task '{plugin}', kwargs '{kwargs}'\")\n    with self.connections_lock:\n        result = nr.run(task=task_function, **kwargs)\n    ret.result = ResultSerializer(result, to_dict=to_dict, add_details=add_details)\n\n    self.watchdog.connections_clean()\n\n    return ret\n</code></pre>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/","title":"Nornir Service Test Task","text":"<p>task api name: <code>test</code></p> <p>The Nornir Service <code>test</code> task designed to facilitate the execution of network tests. This task provides network operations engineers and network automation developers with tools to validate network configurations, ensure compliance, and monitor network performance. By leveraging the capabilities of the Nornir service, users can automate testing process, identify issues proactively, and maintain a robust network infrastructure.</p> <p>Nornir service <code>test</code> task uses Nornir TestsProcessor to run the tests and support test suites definition in YAML format, where test suite YAML files can be stored on and sourced from broker.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#nornir-test-sample-usage","title":"Nornir Test Sample Usage","text":"<p>Nornir service <code>test</code> task uses suites in YAML format to define tests, sample tests suite:</p> suite_3.txt<pre><code>- name: Check ceos version\n  task: \"show version\"\n  test: contains\n  pattern: \"4.30.0F\"\n- name: Check NTP status\n  test: ncontains\n  pattern: \"unsynchronised\"\n  task: \"show ntp status\"\n- name: Check Mgmt Interface Status\n  test: contains\n  pattern: \"is up, line protocol is up\"\n  task: \"show interface management0\" \n</code></pre> <p>File <code>suite_3.txt</code> stored on broker and downloaded by Nornir service prior to running tests, below is an example of how to run the tests suite.</p> <p>Example</p> CLIPython <pre><code>C:\\nf&gt;nfcli\nWelcome to NorFab Interactive Shell.\nnf#\nnf#nornir\nnf[nornir-test]#\nnf[nornir-test]#suite nf://nornir_test_suites/suite_3.txt FC spine,leaf\n--------------------------------------------- Job Events -----------------------------------------------\n07-Jan-2025 18:44:35 0c3309c54ee44397b055257a0d442e62 job started\n07-Jan-2025 18:44:35.207 nornir nornir-worker-1 ceos-spine-1, ceos-spine-2 task started - 'netmiko_send_commands'\n07-Jan-2025 18:44:35.211 nornir nornir-worker-2 ceos-leaf-1, ceos-leaf-2, ceos-leaf-3 task started - 'netmiko_send_commands'\n&lt;omitted for brevity&gt;\n07-Jan-2025 18:44:36 0c3309c54ee44397b055257a0d442e62 job completed in 1.391 seconds\n\n--------------------------------------------- Job Results --------------------------------------------\n\n+----+--------------+-----------------------------+----------+-------------------+\n|    | host         | name                        | result   | exception         |\n+====+==============+=============================+==========+===================+\n|  0 | ceos-leaf-1  | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n|  1 | ceos-leaf-1  | Check NTP status            | FAIL     | Pattern in output |\n+----+--------------+-----------------------------+----------+-------------------+\n|  2 | ceos-leaf-1  | Check Mgmt Interface Status | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n|  3 | ceos-leaf-2  | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n|  4 | ceos-leaf-2  | Check NTP status            | FAIL     | Pattern in output |\n+----+--------------+-----------------------------+----------+-------------------+\n|  5 | ceos-leaf-2  | Check Mgmt Interface Status | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n|  6 | ceos-leaf-3  | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n|  7 | ceos-leaf-3  | Check NTP status            | FAIL     | Pattern in output |\n+----+--------------+-----------------------------+----------+-------------------+\n|  8 | ceos-leaf-3  | Check Mgmt Interface Status | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n|  9 | ceos-spine-1 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 10 | ceos-spine-1 | Check NTP status            | FAIL     | Pattern in output |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 13 | ceos-spine-2 | Check NTP status            | FAIL     | Pattern in output |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 12 | ceos-spine-2 | Check ceos version          | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\n| 13 | ceos-spine-2 | Check NTP status            | FAIL     | Pattern in output |\n+----+--------------+-----------------------------+----------+-------------------+\n| 14 | ceos-spine-2 | Check Mgmt Interface Status | PASS     |                   |\n+----+--------------+-----------------------------+----------+-------------------+\nnf[nornir-test]#\nnf[nornir-test]#top\nnf#\n</code></pre> <p>Demo</p> <p></p> <p>In this example:</p> <ul> <li><code>nfcli</code> command starts the NorFab Interactive Shell.</li> <li><code>nornir</code> command switches to the Nornir sub-shell.</li> <li><code>test</code> command switches to the <code>test</code> task sub-shell.</li> <li><code>suite</code> argument refers to a path for <code>suite_3.txt</code> file with a set of tests to run. </li> <li>Devices filtered using <code>FC</code> - \"Filter Contains\" Nornir hosts targeting filter to only run tests on devices that contain <code>spine</code> or <code>leaf</code> in their hostname.</li> </ul> <p><code>inventory.yaml</code> should be located in same folder where we start nfcli, unless <code>nfcli -i path_to_inventory.yaml</code> flag used. Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file</p> <p>This code is complete and can run as is</p> <pre><code>import pprint\n\nfrom norfab.core.nfapi import NorFab\n\nif __name__ == '__main__':\n    nf = NorFab(inventory=\"inventory.yaml\")\n    nf.start()\n\n    client = nf.make_client()\n\n    res = client.run_job(\n        service=\"nornir\",\n        task=\"test\",\n        kwargs={\n            \"suite\": \"nf://nornir_test_suites/suite_3.txt\",\n            \"FC\": \"spine,leaf\"          \n        }\n    )\n\n    pprint.pprint(res)\n\n    nf.destroy()\n</code></pre> <p>Refer to Getting Started section on how to construct  <code>inventory.yaml</code> file.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#formatting-tests-output","title":"Formatting Tests Output","text":"<p>NorFab interactive shell allows you to format the results of network tests into text tables. This is particularly useful for presenting test results in a clear and organized manner, making it easier to analyze and interpret the data. The NorFab interactive shell supports the <code>table</code> command, which relies on the tabulate module to generate text tables. By outputting test results in table format, you can quickly identify issues and take appropriate action.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#using-jinja2-templates-to-generate-tests","title":"Using Jinja2 Templates to Generate Tests","text":"<p>Using Jinja2 Templates enables you to create dynamic test suites based on variables defined in your inventory or passed as job data. This approach allows you to tailor tests to specific devices or scenarios, ensuring that the tests are relevant and accurate. Jinja2 templates provide a powerful way to automate the creation of complex test cases, incorporating conditional logic, loops, and other advanced features to meet your testing requirements.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#templating-tests-with-inline-job-data","title":"Templating Tests with Inline Job Data","text":"<p>Inline Job Data allows you to define test parameters directly within the <code>job_data</code> argument, making it easy to customize tests on the fly. This feature is particularly useful for scenarios where test parameters need to be adjusted frequently or based on specific conditions. By templating tests with inline job data, you can ensure that your tests are always up-to-date and aligned with the current network state.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#using-dry-run","title":"Using Dry Run","text":"<p>The Using Dry Run feature allows you to generate the content of network test suites without actually performing any actions on the devices. This is useful for validation purposes, as it enables you to verify the correctness of your tests before running them. By using dry run, you can identify potential issues and make necessary adjustments, ensuring that your tests will execute successfully when run for real.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#running-a-subset-of-tests","title":"Running a Subset of Tests","text":"<p>Running a Subset of Tests allows you to execute only a specific set of tests, rather than running the entire test suite. This is useful for targeted testing, such as validating changes in a particular part of the network configuration or focusing on specific devices features. By running a subset of tests, you can save time and resources, while still ensuring that critical aspects of the network are thoroughly tested.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#returning-only-failed-tests","title":"Returning Only Failed Tests","text":"<p>Returning only failed tests enables you to filter the test results to show only the tests that have failed. This is particularly useful for quickly identifying and addressing issues, as it allows you to focus on the areas that require attention. By returning only failed tests, you can streamline the troubleshooting process and ensure that network problems are resolved efficiently.</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#norfab-nornir-test-shell-reference","title":"NORFAB Nornir Test Shell Reference","text":"<p>The NORFAB Nornir Test Shell Reference provides a comprehensive set of command options for the Nornir <code>test</code> task. These commands allow you to control various aspects of the test execution, such as setting job timeouts, filtering devices, adding task details to results, and configuring retry mechanisms. By leveraging these command options, you can tailor the behavior of the tests to meet your specific network management needs, ensuring that your network remains reliable and performant.</p> <p>NorFab shell supports these command options for Nornir <code>test</code> task:</p> <pre><code>nf#man tree nornir.test\nroot\n\u2514\u2500\u2500 nornir:    Nornir service\n    \u2514\u2500\u2500 test:    Run network tests\n        \u251c\u2500\u2500 timeout:    Job timeout\n        \u251c\u2500\u2500 workers:    Filter worker to target, default 'all'\n        \u251c\u2500\u2500 add_details:    Add task details to results\n        \u251c\u2500\u2500 run_num_workers:    RetryRunner number of threads for tasks execution\n        \u251c\u2500\u2500 run_num_connectors:    RetryRunner number of threads for device connections\n        \u251c\u2500\u2500 run_connect_retry:    RetryRunner number of connection attempts\n        \u251c\u2500\u2500 run_task_retry:    RetryRunner number of attempts to run task\n        \u251c\u2500\u2500 run_reconnect_on_fail:    RetryRunner perform reconnect to host on task failure\n        \u251c\u2500\u2500 run_connect_check:    RetryRunner test TCP connection before opening actual connection\n        \u251c\u2500\u2500 run_connect_timeout:    RetryRunner timeout in seconds to wait for test TCP connection to establish\n        \u251c\u2500\u2500 run_creds_retry:    RetryRunner list of connection credentials and parameters to retry\n        \u251c\u2500\u2500 tf:    File group name to save task results to on worker file system\n        \u251c\u2500\u2500 tf_skip_failed:    Save results to file for failed tasks\n        \u251c\u2500\u2500 diff:    File group name to run the diff for\n        \u251c\u2500\u2500 diff_last:    File version number to diff, default is 1 (last)\n        \u251c\u2500\u2500 progress:    Emit execution progress\n        \u251c\u2500\u2500 headers:    Table headers\n        \u251c\u2500\u2500 headers_exclude:    Table headers to exclude\n        \u251c\u2500\u2500 sortby:    Table header column to sort by\n        \u251c\u2500\u2500 reverse:    Table reverse the sort by order\n        \u251c\u2500\u2500 FO:    Filter hosts using Filter Object\n        \u251c\u2500\u2500 FB:    Filter hosts by name using Glob Patterns\n        \u251c\u2500\u2500 FH:    Filter hosts by hostname\n        \u251c\u2500\u2500 FC:    Filter hosts containment of pattern in name\n        \u251c\u2500\u2500 FR:    Filter hosts by name using Regular Expressions\n        \u251c\u2500\u2500 FG:    Filter hosts by group\n        \u251c\u2500\u2500 FP:    Filter hosts by hostname using IP Prefix\n        \u251c\u2500\u2500 FL:    Filter hosts by names list\n        \u251c\u2500\u2500 FM:    Filter hosts by platform\n        \u251c\u2500\u2500 FX:    Filter hosts excluding them by name\n        \u251c\u2500\u2500 FN:    Negate the match\n        \u251c\u2500\u2500 hosts:    Filter hosts to target\n        \u251c\u2500\u2500 *suite:    Nornir suite nf://path/to/file.py, default 'PydanticUndefined'\n        \u251c\u2500\u2500 dry_run:    Return produced per-host tests suite content without running tests\n        \u251c\u2500\u2500 subset:    Filter tests by name\n        \u251c\u2500\u2500 failed_only:    Return test results for failed tests only\n        \u251c\u2500\u2500 remove_tasks:    Include/Exclude tested task results\n        \u2514\u2500\u2500 job_data:    Path to YAML file with job data\nnf#\n</code></pre> <p><code>*</code> - mandatory/required command argument</p>","tags":["nornir"]},{"location":"workers/nornir/services_nornir_service_tasks_test/#python-api-reference","title":"Python API Reference","text":"<p>Function to tests data obtained from devices.</p> <p>Parameters:</p> Name Type Description Default <code>suite</code> <code>Union[list, str]</code> <p>path to YAML file with tests</p> required <code>dry_run</code> <code>bool</code> <p>if True, returns produced per-host tests suite content only</p> <code>False</code> <code>subset</code> <code>str</code> <p>list or string with comma separated non case sensitive glob patterns to filter tests' by name, subset argument ignored by dry run</p> <code>None</code> <code>failed_only</code> <code>bool</code> <p>if True returns test results for failed tests only</p> <code>False</code> <code>remove_tasks</code> <code>bool</code> <p>if False results will include other tasks output</p> <code>True</code> <code>return_tests_suite</code> <code>bool</code> <p>if True returns rendered per-host tests suite content in addition to test results using dictionary with <code>results</code> and <code>suite</code> keys</p> <code>False</code> <code>job_data</code> <code>str</code> <p>URL to YAML file with data or dictionary/list of data to pass on to Jinja2 rendering context</p> <code>None</code> <code>kwargs</code> <p>any additional arguments to pass on to Nornir service task</p> <code>{}</code> Source code in <code>norfab\\workers\\nornir_worker.py</code> <pre><code>def test(\n    self,\n    suite: Union[list, str],\n    subset: str = None,\n    dry_run: bool = False,\n    remove_tasks: bool = True,\n    failed_only: bool = False,\n    return_tests_suite: bool = False,\n    job_data: str = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Function to tests data obtained from devices.\n\n    :param suite: path to YAML file with tests\n    :param dry_run: if True, returns produced per-host tests suite content only\n    :param subset: list or string with comma separated non case sensitive glob\n        patterns to filter tests' by name, subset argument ignored by dry run\n    :param failed_only: if True returns test results for failed tests only\n    :param remove_tasks: if False results will include other tasks output\n    :param return_tests_suite: if True returns rendered per-host tests suite\n        content in addition to test results using dictionary with ``results``\n        and ``suite`` keys\n    :param job_data: URL to YAML file with data or dictionary/list of data\n        to pass on to Jinja2 rendering context\n    :param kwargs: any additional arguments to pass on to Nornir service task\n    \"\"\"\n    tests = {}  # dictionary to hold per-host test suites\n    add_details = kwargs.get(\"add_details\", False)  # ResultSerializer\n    to_dict = kwargs.get(\"to_dict\", True)  # ResultSerializer\n    filters = {k: kwargs.pop(k) for k in list(kwargs.keys()) if k in FFun_functions}\n    ret = Result(task=f\"{self.name}:test\", result={} if to_dict else [])\n    suites = {}  # dictionary to hold combined test suites\n\n    self.nr.data.reset_failed_hosts()  # reset failed hosts\n    filtered_nornir = FFun(self.nr, **filters)  # filter hosts\n\n    # check if no hosts matched\n    if not filtered_nornir.inventory.hosts:\n        msg = (\n            f\"{self.name} - nothing to do, no hosts matched by filters '{filters}'\"\n        )\n        log.debug(msg)\n        ret.messages.append(msg)\n        if return_tests_suite is True:\n            ret.result = {\"test_results\": [], \"suite\": {}}\n        return ret\n\n    # download job data\n    job_data = self.load_job_data(job_data)\n\n    # generate per-host test suites\n    for host_name, host in filtered_nornir.inventory.hosts.items():\n        # render suite using Jinja2\n        try:\n            rendered_suite = self.render_jinja2_templates(\n                templates=[suite],\n                context={\n                    \"host\": host,\n                    \"norfab\": self.client,\n                    \"nornir\": self,\n                    \"job_data\": job_data,\n                },\n                filters=self.add_jinja2_filters(),\n            )\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' Jinja2 rendering failed: '{e}'\"\n            raise RuntimeError(msg)\n        # load suit using YAML\n        try:\n            tests[host_name] = yaml.safe_load(rendered_suite)\n        except Exception as e:\n            msg = f\"{self.name} - '{suite}' YAML load failed: '{e}'\"\n            raise RuntimeError(msg)\n\n    # validate tests suite\n    try:\n        _ = modelTestsProcessorSuite(tests=tests)\n    except Exception as e:\n        msg = f\"{self.name} - '{suite}' suite validation failed: '{e}'\"\n        raise RuntimeError(msg)\n\n    # download pattern, schema and custom function files\n    for host_name in tests.keys():\n        for index, item in enumerate(tests[host_name]):\n            for k in [\"pattern\", \"schema\", \"function_file\"]:\n                if self.is_url(item.get(k)):\n                    item[k] = self.fetch_file(\n                        item[k], raise_on_fail=True, read=True\n                    )\n                    if k == \"function_file\":\n                        item[\"function_text\"] = item.pop(k)\n            tests[host_name][index] = item\n\n    # save per-host tests suite content before mutating it\n    if return_tests_suite is True:\n        return_suite = copy.deepcopy(tests)\n\n    log.debug(f\"{self.name} - running test '{suite}', is dry run - '{dry_run}'\")\n    # run dry run task\n    if dry_run is True:\n        result = filtered_nornir.run(\n            task=nr_test, name=\"tests_dry_run\", ret_data_per_host=tests\n        )\n        ret.result = ResultSerializer(\n            result, to_dict=to_dict, add_details=add_details\n        )\n    # combine per-host tests in suites based on task and arguments\n    # Why - to run tests using any nornir service tasks with various arguments\n    else:\n        for host_name, host_tests in tests.items():\n            for test in host_tests:\n                dhash = hashlib.md5()\n                test_args = test.pop(\"norfab\", {})\n                nrtask = test_args.get(\"nrtask\", \"cli\")\n                assert nrtask in [\n                    \"cli\",\n                    \"network\",\n                    \"cfg\",\n                    \"task\",\n                ], f\"{self.name} - unsupported NorFab Nornir Service task '{nrtask}'\"\n                test_json = json.dumps(test_args, sort_keys=True).encode()\n                dhash.update(test_json)\n                test_hash = dhash.hexdigest()\n                suites.setdefault(test_hash, {\"params\": test_args, \"tests\": {}})\n                suites[test_hash][\"tests\"].setdefault(host_name, [])\n                suites[test_hash][\"tests\"][host_name].append(test)\n        log.debug(\n            f\"{self.name} - combined per-host tests suites based on NorFab Nornir Service task and arguments:\\n{suites}\"\n        )\n        # run test suites collecting output from devices\n        for tests_suite in suites.values():\n            nrtask = tests_suite[\"params\"].pop(\"nrtask\", \"cli\")\n            function_kwargs = {\n                **tests_suite[\"params\"],\n                **kwargs,\n                **filters,\n                \"tests\": tests_suite[\"tests\"],\n                \"remove_tasks\": remove_tasks,\n                \"failed_only\": failed_only,\n                \"subset\": subset,\n            }\n            result = getattr(self, nrtask)(\n                **function_kwargs\n            )  # returns Result object\n            # save test results into overall results\n            if to_dict == True:\n                for host_name, host_res in result.result.items():\n                    ret.result.setdefault(host_name, {})\n                    ret.result[host_name].update(host_res)\n            else:\n                ret.result.extend(result.result)\n\n    # check if need to return tests suite content\n    if return_tests_suite is True:\n        ret.result = {\"test_results\": ret.result, \"suite\": return_suite}\n\n    return ret\n</code></pre>","tags":["nornir"]}]}